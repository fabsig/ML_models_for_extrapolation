{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions_taken       float32\n",
      "Year_of_decision    float32\n",
      "Liberal_1           float32\n",
      "Unanimous_1         float32\n",
      "dtype: object\n",
      "Task 361094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "northing       float32\n",
      "easting        float32\n",
      "resistivity    float32\n",
      "dtype: object\n",
      "Task 361096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carat        float32\n",
      "depth        float32\n",
      "table        float32\n",
      "x            float32\n",
      "y            float32\n",
      "z            float32\n",
      "color_1      float32\n",
      "color_2      float32\n",
      "color_3      float32\n",
      "color_4      float32\n",
      "color_5      float32\n",
      "color_6      float32\n",
      "clarity_1    float32\n",
      "clarity_2    float32\n",
      "clarity_3    float32\n",
      "clarity_4    float32\n",
      "clarity_5    float32\n",
      "clarity_6    float32\n",
      "clarity_7    float32\n",
      "dtype: object\n",
      "Task 361097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X3_1      float32\n",
      "X3_2      float32\n",
      "X3_3      float32\n",
      "X3_4      float32\n",
      "X3_5      float32\n",
      "           ...   \n",
      "X377_1    float32\n",
      "X378_1    float32\n",
      "X379_1    float32\n",
      "X380_1    float32\n",
      "X385_1    float32\n",
      "Length: 270, dtype: object\n",
      "Task 361098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area                  float32\n",
      "rooms                 float32\n",
      "bathroom              float32\n",
      "parking_spaces        float32\n",
      "hoa_BRL               float32\n",
      "rent_amount_BRL       float32\n",
      "property_tax_BRL      float32\n",
      "fire_insurance_BRL    float32\n",
      "city_1                float32\n",
      "city_2                float32\n",
      "city_3                float32\n",
      "city_4                float32\n",
      "animal_1              float32\n",
      "furniture_1           float32\n",
      "dtype: object\n",
      "Task 361099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month           float32\n",
      "hour            float32\n",
      "temp            float32\n",
      "feel_temp       float32\n",
      "humidity        float32\n",
      "windspeed       float32\n",
      "season_1        float32\n",
      "season_2        float32\n",
      "season_3        float32\n",
      "year_1          float32\n",
      "workingday_1    float32\n",
      "dtype: object\n",
      "Task 361101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolls_amount                    float32\n",
      "total_amount                    float32\n",
      "lpep_pickup_datetime_day        float32\n",
      "lpep_pickup_datetime_hour       float32\n",
      "lpep_pickup_datetime_minute     float32\n",
      "lpep_dropoff_datetime_day       float32\n",
      "lpep_dropoff_datetime_hour      float32\n",
      "lpep_dropoff_datetime_minute    float32\n",
      "dtype: object\n",
      "Task 361102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrooms         float32\n",
      "bathrooms        float32\n",
      "sqft_living      float32\n",
      "sqft_lot         float32\n",
      "grade            float32\n",
      "sqft_above       float32\n",
      "sqft_basement    float32\n",
      "yr_built         float32\n",
      "yr_renovated     float32\n",
      "lat              float32\n",
      "long             float32\n",
      "sqft_living15    float32\n",
      "sqft_lot15       float32\n",
      "date_month       float32\n",
      "date_day         float32\n",
      "date_year_1      float32\n",
      "dtype: object\n",
      "Task 361103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour                                         float32\n",
      "Altitudem                                    float32\n",
      "PMsub25subparticulatematterHourlymeasured    float32\n",
      "Month_1                                      float32\n",
      "Month_10                                     float32\n",
      "Month_11                                     float32\n",
      "Month_2                                      float32\n",
      "Month_3                                      float32\n",
      "Month_4                                      float32\n",
      "Month_5                                      float32\n",
      "Month_6                                      float32\n",
      "Month_7                                      float32\n",
      "Month_8                                      float32\n",
      "Month_9                                      float32\n",
      "DayofWeek_1                                  float32\n",
      "DayofWeek_2                                  float32\n",
      "DayofWeek_3                                  float32\n",
      "DayofWeek_4                                  float32\n",
      "DayofWeek_5                                  float32\n",
      "DayofWeek_6                                  float32\n",
      "dtype: object\n",
      "Task 361104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run2      float32\n",
      "Run3      float32\n",
      "Run4      float32\n",
      "KWG_1     float32\n",
      "KWI_1     float32\n",
      "STRM_1    float32\n",
      "STRN_1    float32\n",
      "SA_1      float32\n",
      "SB_1      float32\n",
      "dtype: object\n",
      "Task 361287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oz1        float32\n",
      "oz2        float32\n",
      "oz3        float32\n",
      "oz4        float32\n",
      "oz5        float32\n",
      "            ...   \n",
      "oz259      float32\n",
      "oz261      float32\n",
      "oz262      float32\n",
      "oz264      float32\n",
      "oz265_1    float32\n",
      "Length: 253, dtype: object\n",
      "Task 361288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length            float32\n",
      "Diameter          float32\n",
      "Height            float32\n",
      "Whole_weight      float32\n",
      "Shucked_weight    float32\n",
      "Viscera_weight    float32\n",
      "Shell_weight      float32\n",
      "Sex_1             float32\n",
      "Sex_2             float32\n",
      "dtype: object\n",
      "Task 361289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurred_hour    float32\n",
      "Occurred_min     float32\n",
      "dtype: object\n",
      "Task 361291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "File: C:\\Users\\dalma\\.openml\\org\\openml\\www\\datasets\\45045\\dataset_45045.pq",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\dataset.py:518\u001b[0m, in \u001b[0;36mOpenMLDataset._cache_compressed_file_from_file\u001b[1;34m(self, data_file)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 518\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\pandas\\io\\parquet.py:670\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    668\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    671\u001b[0m     path,\n\u001b[0;32m    672\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    673\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    674\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    675\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    676\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    677\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    679\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\pandas\\io\\parquet.py:279\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    273\u001b[0m     path_or_handle,\n\u001b[0;32m    274\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    278\u001b[0m )\n\u001b[1;32m--> 279\u001b[0m result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\pyarrow\\array.pxi:884\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\pyarrow\\table.pxi:4192\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\pyarrow\\pandas_compat.py:776\u001b[0m, in \u001b[0;36mtable_to_dataframe\u001b[1;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[0;32m    775\u001b[0m columns \u001b[38;5;241m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[1;32m--> 776\u001b[0m blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_table_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext_columns_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    778\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\pyarrow\\pandas_compat.py:1129\u001b[0m, in \u001b[0;36m_table_to_blocks\u001b[1;34m(options, block_table, categories, extension_columns)\u001b[0m\n\u001b[0;32m   1128\u001b[0m columns \u001b[38;5;241m=\u001b[39m block_table\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[1;32m-> 1129\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextension_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [_reconstruct_block(item, columns, extension_columns)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\pyarrow\\table.pxi:3115\u001b[0m, in \u001b[0;36mpyarrow.lib.table_to_blocks\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 306072256 failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m task \u001b[38;5;241m=\u001b[39m openml\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mget_task(task_id)  \u001b[38;5;66;03m# download the OpenML task\u001b[39;00m\n\u001b[0;32m     51\u001b[0m dataset \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mget_dataset()\n\u001b[1;32m---> 53\u001b[0m X, y, categorical_indicator, attribute_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataframe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_target_attribute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m15000\u001b[39m:\n\u001b[0;32m     57\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(X\u001b[38;5;241m.\u001b[39mindex, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15000\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\dataset.py:745\u001b[0m, in \u001b[0;36mOpenMLDataset.get_data\u001b[1;34m(self, target, include_row_id, include_ignore_attribute, dataset_format)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    737\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupport for `dataset_format=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` will be removed in 0.15,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart using `dataset_format=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to ensure your code \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    743\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    744\u001b[0m     )\n\u001b[1;32m--> 745\u001b[0m data, categorical, attribute_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m to_exclude \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m include_row_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_id_attribute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\dataset.py:558\u001b[0m, in \u001b[0;36mOpenMLDataset._load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_data()\n\u001b[0;32m    557\u001b[0m     file_to_load \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_file \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparquet_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparquet_file\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_compressed_file_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_to_load\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# helper variable to help identify where errors occur\u001b[39;00m\n\u001b[0;32m    561\u001b[0m fpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_feather_file \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeather\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_pickle_file\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\dataset.py:520\u001b[0m, in \u001b[0;36mOpenMLDataset._cache_compressed_file_from_file\u001b[1;34m(self, data_file)\u001b[0m\n\u001b[0;32m    518\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(data_file)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    522\u001b[0m categorical \u001b[38;5;241m=\u001b[39m [data[c]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[0;32m    523\u001b[0m attribute_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[1;31mException\u001b[0m: File: C:\\Users\\dalma\\.openml\\org\\openml\\www\\datasets\\45045\\dataset_45045.pq"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from engression import engression\n",
    "import torch\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from pygam import LinearGAM\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import shutil\n",
    "import gpboost as gpb\n",
    "\n",
    "task_id = 361093\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "#SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "for task_id in benchmark_suite.tasks:\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    N_TRIALS=100\n",
    "    N_SAMPLES=100\n",
    "    PATIENCE=40\n",
    "    N_EPOCHS=1000\n",
    "\n",
    "    BATCH_SIZE=1024\n",
    "    seed=10\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "    if len(X) > 15000:\n",
    "        indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "        X = X.iloc[indices,]\n",
    "        y = y[indices]\n",
    "\n",
    "    # Remove categorical columns with more than 20 unique values and non-categorical columns with less than 10 unique values\n",
    "    # Remove non-categorical columns with more than 70% of the data in one category from X_clean\n",
    "    for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "        if len(X[col].unique()) > 20:\n",
    "            X = X.drop(col, axis=1)\n",
    "\n",
    "    X_clean=X.copy()\n",
    "    for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "        if len(X[col].unique()) < 10:\n",
    "            X = X.drop(col, axis=1)\n",
    "            X_clean = X_clean.drop(col, axis=1)\n",
    "        elif X[col].value_counts(normalize=True).max() > 0.7:\n",
    "            X_clean = X_clean.drop(col, axis=1)\n",
    "\n",
    "    # Find features with absolute correlation > 0.9\n",
    "    corr_matrix = X_clean.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "    # Drop one of the highly correlated features from X_clean\n",
    "    X_clean = X_clean.drop(high_corr_features, axis=1)\n",
    "\n",
    "    # Rename columns to avoid problems with LGBM\n",
    "    X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "    # Compute Gower distance and define train and test set\n",
    "    # calculate the Gower distance matrix for the entire dataset\n",
    "    for col in X_clean.select_dtypes(['category']).columns:\n",
    "        X_clean[col] = X_clean[col].astype('object')\n",
    "\n",
    "    gower_dist_matrix = gower.gower_matrix(X_clean)\n",
    "\n",
    "    # calculate the Gower distance for each data point\n",
    "    gower_dist = np.mean(gower_dist_matrix, axis=1)\n",
    "\n",
    "    gower_dist=pd.Series(gower_dist,index=X_clean.index)\n",
    "    far_index=gower_dist.index[np.where(gower_dist>=np.quantile(gower_dist,0.8))[0]]\n",
    "    close_index=gower_dist.index[np.where(gower_dist<np.quantile(gower_dist,0.8))[0]]\n",
    "\n",
    "    X_clean_ = X_clean.loc[close_index,:]\n",
    "\n",
    "    for col in X_clean_.select_dtypes(['category']).columns:\n",
    "        X_clean_[col] = X_clean_[col].astype('object')\n",
    "\n",
    "    # calculate the Gower distance matrix for the training set\n",
    "    gower_dist_matrix_train = gower.gower_matrix(X_clean_)\n",
    "\n",
    "    # calculate the Gower distance for each data point in the training set\n",
    "    gower_dist_train = np.mean(gower_dist_matrix_train, axis=1)\n",
    "\n",
    "    gower_dist_train=pd.Series(gower_dist_train,index=X_clean_.index)\n",
    "    far_index_train=gower_dist_train.index[np.where(gower_dist_train>=np.quantile(gower_dist_train,0.8))[0]]\n",
    "    close_index_train=gower_dist_train.index[np.where(gower_dist_train<np.quantile(gower_dist_train,0.8))[0]]\n",
    "\n",
    "    # Check if categorical variables have the same cardinality in X and X_train_, and remove the ones that don't\n",
    "    dummy_cols = X.select_dtypes(['bool', 'category', 'object', 'string']).columns\n",
    "    X_train = X.loc[close_index,:]\n",
    "    X_train_ = X_train.loc[close_index_train,:]\n",
    "    for col in dummy_cols:\n",
    "        if len(X[col].unique()) != len(X_train_[col].unique()):\n",
    "            X = X.drop(col, axis=1)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    # Modify X_train_, X_val, X_train, and X_test to have dummy variables\n",
    "    non_dummy_cols = X.select_dtypes(exclude=['bool', 'category', 'object', 'string']).columns\n",
    "    X = pd.get_dummies(X, drop_first=True).astype('float32')\n",
    "\n",
    "    print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actions_taken       float32\n",
       "Year_of_decision    float32\n",
       "Liberal_1           float32\n",
       "Unanimous_1         float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "task_id = 361287\n",
    "N_TRIALS=100\n",
    "N_SAMPLES=100\n",
    "PATIENCE=40\n",
    "N_EPOCHS=1000\n",
    "\n",
    "BATCH_SIZE=1024\n",
    "seed=10\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "print(f\"Task {task_id}\")\n",
    "\n",
    "task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "dataset = task.get_dataset()\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oz1       float64\n",
       "oz2       float64\n",
       "oz3       float64\n",
       "oz4       float64\n",
       "oz5       float64\n",
       "           ...   \n",
       "oz260    category\n",
       "oz261     float64\n",
       "oz262     float64\n",
       "oz264     float64\n",
       "oz265    category\n",
       "Length: 255, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oz1</th>\n",
       "      <th>oz2</th>\n",
       "      <th>oz3</th>\n",
       "      <th>oz4</th>\n",
       "      <th>oz5</th>\n",
       "      <th>oz6</th>\n",
       "      <th>oz7</th>\n",
       "      <th>oz8</th>\n",
       "      <th>oz9</th>\n",
       "      <th>oz10</th>\n",
       "      <th>...</th>\n",
       "      <th>oz254</th>\n",
       "      <th>oz256</th>\n",
       "      <th>oz257</th>\n",
       "      <th>oz258</th>\n",
       "      <th>oz259</th>\n",
       "      <th>oz260</th>\n",
       "      <th>oz261</th>\n",
       "      <th>oz262</th>\n",
       "      <th>oz264</th>\n",
       "      <th>oz265</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106112</td>\n",
       "      <td>0.153159</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.177273</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.180812</td>\n",
       "      <td>0.188449</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.156839</td>\n",
       "      <td>0.366485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106112</td>\n",
       "      <td>0.099068</td>\n",
       "      <td>0.178231</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.145179</td>\n",
       "      <td>0.184502</td>\n",
       "      <td>0.181485</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.188336</td>\n",
       "      <td>0.620572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.106112</td>\n",
       "      <td>0.120172</td>\n",
       "      <td>0.317007</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.096524</td>\n",
       "      <td>0.110701</td>\n",
       "      <td>0.108506</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.102034</td>\n",
       "      <td>0.301090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.089232</td>\n",
       "      <td>0.087194</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.095455</td>\n",
       "      <td>0.061344</td>\n",
       "      <td>0.092251</td>\n",
       "      <td>0.081890</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.081679</td>\n",
       "      <td>0.274523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111846</td>\n",
       "      <td>0.118452</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.119729</td>\n",
       "      <td>0.143911</td>\n",
       "      <td>0.153152</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.164176</td>\n",
       "      <td>0.561308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8880</th>\n",
       "      <td>0.455253</td>\n",
       "      <td>0.394826</td>\n",
       "      <td>0.284354</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.351773</td>\n",
       "      <td>0.564576</td>\n",
       "      <td>0.442494</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.456440</td>\n",
       "      <td>0.561308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8881</th>\n",
       "      <td>0.129336</td>\n",
       "      <td>0.161179</td>\n",
       "      <td>0.425850</td>\n",
       "      <td>0.245455</td>\n",
       "      <td>0.226020</td>\n",
       "      <td>0.254613</td>\n",
       "      <td>0.281939</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.241231</td>\n",
       "      <td>0.608311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8882</th>\n",
       "      <td>0.111846</td>\n",
       "      <td>0.155457</td>\n",
       "      <td>0.505442</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.209552</td>\n",
       "      <td>0.201107</td>\n",
       "      <td>0.244162</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.205962</td>\n",
       "      <td>0.561308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8883</th>\n",
       "      <td>0.129336</td>\n",
       "      <td>0.179882</td>\n",
       "      <td>0.531973</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.223691</td>\n",
       "      <td>0.239852</td>\n",
       "      <td>0.236435</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.214358</td>\n",
       "      <td>0.437330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8884</th>\n",
       "      <td>0.655156</td>\n",
       "      <td>0.481052</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.402673</td>\n",
       "      <td>0.817343</td>\n",
       "      <td>0.579009</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.666174</td>\n",
       "      <td>0.597411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8885 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           oz1       oz2       oz3       oz4       oz5       oz6       oz7  \\\n",
       "0     0.106112  0.153159  0.533333  0.177273  0.164345  0.180812  0.188449   \n",
       "1     0.106112  0.099068  0.178231  0.181818  0.145179  0.184502  0.181485   \n",
       "2     0.106112  0.120172  0.317007  0.118182  0.096524  0.110701  0.108506   \n",
       "3     0.089232  0.087194  0.193878  0.095455  0.061344  0.092251  0.081890   \n",
       "4     0.111846  0.118452  0.271429  0.150000  0.119729  0.143911  0.153152   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8880  0.455253  0.394826  0.284354  0.527273  0.351773  0.564576  0.442494   \n",
       "8881  0.129336  0.161179  0.425850  0.245455  0.226020  0.254613  0.281939   \n",
       "8882  0.111846  0.155457  0.505442  0.204545  0.209552  0.201107  0.244162   \n",
       "8883  0.129336  0.179882  0.531973  0.236364  0.223691  0.239852  0.236435   \n",
       "8884  0.655156  0.481052  0.193878  0.763636  0.402673  0.817343  0.579009   \n",
       "\n",
       "           oz8       oz9      oz10  ...  oz254  oz256  oz257  oz258  oz259  \\\n",
       "0     0.171053  0.156839  0.366485  ...    0.0      0    0.0    0.0    0.0   \n",
       "1     0.184211  0.188336  0.620572  ...    0.0      0    0.0    0.0    0.0   \n",
       "2     0.105263  0.102034  0.301090  ...    0.0      0    0.0    0.0    0.0   \n",
       "3     0.092105  0.081679  0.274523  ...    0.0      0    0.0    0.0    0.0   \n",
       "4     0.118421  0.164176  0.561308  ...    0.0      0    0.0    0.0    0.0   \n",
       "...        ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
       "8880  0.631579  0.456440  0.561308  ...    0.0      0    0.0    0.0    0.0   \n",
       "8881  0.263158  0.241231  0.608311  ...    0.0      0    0.0    0.0    0.0   \n",
       "8882  0.197368  0.205962  0.561308  ...    0.0      0    0.0    0.0    0.0   \n",
       "8883  0.236842  0.214358  0.437330  ...    0.0      0    0.0    0.0    0.0   \n",
       "8884  0.921053  0.666174  0.597411  ...    0.0      0    0.0    0.0    0.0   \n",
       "\n",
       "      oz260  oz261  oz262  oz264  oz265  \n",
       "0         0    0.0    0.0    0.0      0  \n",
       "1         0    0.0    0.0    0.0      0  \n",
       "2         0    0.0    0.0    0.0      0  \n",
       "3         0    0.0    0.0    0.0      0  \n",
       "4         0    0.0    0.0    0.0      0  \n",
       "...     ...    ...    ...    ...    ...  \n",
       "8880      0    0.0    0.0    0.0      0  \n",
       "8881      0    0.0    0.0    0.0      0  \n",
       "8882      0    0.0    0.0    0.0      0  \n",
       "8883      0    0.0    0.0    0.0      0  \n",
       "8884      0    0.0    0.0    0.0      0  \n",
       "\n",
       "[8885 rows x 255 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'unique_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32604\\2794586648.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'oz261'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'unique_values'"
     ]
    }
   ],
   "source": [
    "X['oz261'].unique_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.      , 0.008214, 0.00616 , 0.01232 , 0.026694, 0.024641,\n",
       "       0.045175, 0.188912, 0.016427, 0.028747, 0.010267, 0.049281,\n",
       "       0.098563, 0.014374, 0.100616, 0.106776, 0.020534, 0.047228,\n",
       "       0.057495, 0.032854, 0.685832, 0.022587, 0.030801, 0.36961 ,\n",
       "       0.13963 , 0.041068, 0.104723, 0.143737, 0.078029, 0.110883,\n",
       "       0.01848 , 0.102669, 0.071869, 0.390144, 0.053388, 0.542094,\n",
       "       0.205339, 0.332649, 0.043121, 0.039014, 0.088296, 0.075975,\n",
       "       0.137577, 0.123203, 0.283368, 0.193018, 0.065708, 0.063655,\n",
       "       0.147844, 0.082136, 0.244353, 1.      , 0.184805, 0.036961,\n",
       "       0.094456, 0.059548, 0.131417, 0.151951, 0.092402, 0.229979,\n",
       "       0.201232, 0.051335, 0.11499 , 0.069815, 0.156057, 0.061602,\n",
       "       0.119097, 0.135524, 0.073922])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(X['oz261'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oz261\n",
       "0.000000    0.942375\n",
       "0.008214    0.012606\n",
       "0.006160    0.010467\n",
       "0.012320    0.005853\n",
       "0.024641    0.003376\n",
       "              ...   \n",
       "0.137577    0.000113\n",
       "0.123203    0.000113\n",
       "0.283368    0.000113\n",
       "0.063655    0.000113\n",
       "0.073922    0.000113\n",
       "Name: proportion, Length: 69, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['oz261'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
