{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ebff59564c4e818599ea0b9934c6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54e07b6528946889bf5dfeef665c836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4229a9a56004f1e84136da09f890436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7624d644a1dc47c4917eb613c33853d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8960b077e3a24e1485d670273c62eadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE GP:  tensor(0.7159)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import lightgbmlss\n",
    "import optuna\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from drf import drf\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping, train_GP\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "#SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "task_id=361093\n",
    "task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "dataset = task.get_dataset()\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "N_TRIALS=100\n",
    "N_SAMPLES=100\n",
    "PATIENCE=40\n",
    "N_EPOCHS=1000\n",
    "GP_ITERATIONS=10\n",
    "seed=10\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# Compute Gower distance and define train and test set\n",
    "# calculate the Gower distance matrix\n",
    "X_gower = X.copy()\n",
    "\n",
    "for col in X_gower.select_dtypes(['category']).columns:\n",
    "    X_gower[col] = X_gower[col].astype('object')\n",
    "\n",
    "gower_dist_matrix = gower.gower_matrix(X_gower)\n",
    "\n",
    "# calculate the Gower distance for each data point\n",
    "gower_dist = np.mean(gower_dist_matrix, axis=1)\n",
    "\n",
    "gower_dist=pd.Series(gower_dist,index=X.index)\n",
    "far_index=gower_dist.index[np.where(gower_dist>=np.quantile(gower_dist,0.8))[0]]\n",
    "close_index=gower_dist.index[np.where(gower_dist<np.quantile(gower_dist,0.8))[0]]\n",
    "\n",
    "X_train = X.loc[close_index,:]\n",
    "X_gower_ = X_train.copy()\n",
    "\n",
    "for col in X_gower_.select_dtypes(['category']).columns:\n",
    "    X_gower_[col] = X_gower_[col].astype('object')\n",
    "\n",
    "# calculate the Gower distance matrix for the training set\n",
    "gower_dist_matrix_train = gower.gower_matrix(X_gower_)\n",
    "\n",
    "# calculate the Gower distance for each data point in the training set\n",
    "gower_dist_train = np.mean(gower_dist_matrix_train, axis=1)\n",
    "\n",
    "gower_dist_train=pd.Series(gower_dist_train,index=X_train.index)\n",
    "far_index_train=gower_dist_train.index[np.where(gower_dist_train>=np.quantile(gower_dist_train,0.8))[0]]\n",
    "close_index_train=gower_dist_train.index[np.where(gower_dist_train<np.quantile(gower_dist_train,0.8))[0]]\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "# Modify X_train_, X_val, X_train, and X_test to have dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True).astype('float32')\n",
    "\n",
    "X_train = X.loc[close_index,:]\n",
    "X_test = X.loc[far_index,:]\n",
    "y_train = y.loc[close_index]\n",
    "y_test = y.loc[far_index]\n",
    "\n",
    "X_train_ = X_train.loc[close_index_train,:]\n",
    "X_val = X_train.loc[far_index_train,:]\n",
    "y_train_ = y_train.loc[close_index_train]\n",
    "y_val = y_train.loc[far_index_train]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train__tensor = torch.tensor(X_train_.values, dtype=torch.float32)\n",
    "y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Convert to use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    X_train__tensor = X_train__tensor.cuda()\n",
    "    y_train__tensor = y_train__tensor.cuda()\n",
    "    X_train_tensor = X_train_tensor.cuda()\n",
    "    y_train_tensor = y_train_tensor.cuda()\n",
    "    X_val_tensor = X_val_tensor.cuda()\n",
    "    y_val_tensor = y_val_tensor.cuda()\n",
    "    X_test_tensor = X_test_tensor.cuda()\n",
    "    y_test_tensor = y_test_tensor.cuda()\n",
    "\n",
    "# Create flattened versions of the data\n",
    "y_val_np = y_val.values.flatten()\n",
    "y_test_np = y_test.values.flatten()\n",
    "\n",
    "\n",
    "#### Gaussian process\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Define the learning params\n",
    "training_iterations = GP_ITERATIONS\n",
    "\n",
    "# Define the kernels\n",
    "kernels = [\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=0.5, ard_num_dims=X_train_.shape[1])),\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=X_train_.shape[1])),\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=X_train_.shape[1])),\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=X_train_.shape[1])),\n",
    "]\n",
    "\n",
    "best_RMSE = float('inf')\n",
    "best_kernel = None\n",
    "\n",
    "for kernel in kernels:\n",
    "    # Initialize the Gaussian Process model and likelihood\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(X_train__tensor, y_train__tensor, likelihood, kernel)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    # Train the model\n",
    "    train_GP(model,X_train__tensor,y_train__tensor,training_iterations,mll,optimizer)\n",
    "    \n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        y_pred = model(X_val_tensor)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    RMSE = torch.sqrt(torch.mean(torch.square(y_val_tensor - y_pred.mean)))\n",
    "\n",
    "    # Update the best kernel if the current kernel has a lower RMSE\n",
    "    if RMSE < best_RMSE:\n",
    "        best_RMSE = RMSE\n",
    "        best_kernel = kernel\n",
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = best_kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Define the learning params\n",
    "training_iterations = GP_ITERATIONS\n",
    "\n",
    "# Initialize the Gaussian Process model and likelihood\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(X_train_tensor, y_train_tensor, likelihood)\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "# Train the model\n",
    "train_GP(model,X_train_tensor,y_train_tensor,training_iterations,mll,optimizer)\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Make predictions on the validation set\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    y_pred = model(X_test_tensor)\n",
    "\n",
    "# Calculate RMSE\n",
    "RMSE_GP = torch.sqrt(torch.mean(torch.square(y_test_tensor - y_pred.mean)))\n",
    "print(\"RMSE GP: \", RMSE_GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361073\n",
      "Task 361073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 26)\n",
      "Task 361074\n",
      "Task 361074\n",
      "(16599, 16)\n",
      "Task 361076\n",
      "Task 361076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 11)\n",
      "Task 361077\n",
      "Task 361077\n",
      "(13750, 33)\n",
      "Task 361078\n",
      "Task 361078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "Task 361079\n",
      "Task 361079\n",
      "(22784, 16)\n",
      "Task 361080\n",
      "Task 361080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 6)\n",
      "Task 361081\n",
      "Task 361081\n",
      "(10692, 8)\n",
      "Task 361082\n",
      "Task 361082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17379, 6)\n",
      "Task 361083\n",
      "Task 361083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581835, 9)\n",
      "Task 361084\n",
      "Task 361084\n",
      "(21613, 15)\n",
      "Task 361085\n",
      "Task 361085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10081, 6)\n",
      "Task 361086\n",
      "Task 361086\n",
      "(163065, 3)\n",
      "Task 361087\n",
      "Task 361087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13932, 13)\n",
      "Task 361088\n",
      "Task 361088\n",
      "(21263, 79)\n",
      "Task 361279\n",
      "Task 361279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8885, 42)\n",
      "Task 361280\n",
      "Task 361280\n",
      "(4177, 7)\n",
      "Task 361281\n",
      "Task 361281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5465575, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import lightgbmlss\n",
    "import optuna\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from drf import drf\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "#task_id=361093\n",
    "for task_id in benchmark_suite.tasks[1:]:\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    # Create the checkpoint directory if it doesn't exist\n",
    "    os.makedirs('CHECKPOINTS/GOWER', exist_ok=True)\n",
    "    CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[361072, 361073, 361074, 361076, 361077, 361078, 361079, 361080, 361081, 361082, 361083, 361084, 361085, 361086, 361087, 361088, 361279, 361280, 361281]\n"
     ]
    }
   ],
   "source": [
    "print(benchmark_suite.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(benchmark_suite.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361093\n",
      "Task 361093\n",
      "(4052, 6)\n",
      "Task 361094\n",
      "Task 361094\n",
      "(8641, 4)\n",
      "Task 361096\n",
      "Task 361096\n",
      "(15000, 6)\n",
      "Task 361097\n",
      "Task 361097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 263)\n",
      "Task 361098\n",
      "Task 361098\n",
      "(10692, 10)\n",
      "Task 361099\n",
      "Task 361099\n",
      "(15000, 10)\n",
      "Task 361101\n",
      "Task 361101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 9)\n",
      "Task 361102\n",
      "Task 361102\n",
      "(15000, 16)\n",
      "Task 361103\n",
      "Task 361103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 6)\n",
      "Task 361104\n",
      "Task 361104\n",
      "(15000, 7)\n",
      "Task 361287\n",
      "Task 361287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8885, 57)\n",
      "Task 361288\n",
      "Task 361288\n",
      "(4177, 3)\n",
      "Task 361289\n",
      "Task 361289\n",
      "(15000, 3)\n",
      "Task 361291\n",
      "Task 361291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 9)\n",
      "Task 361292\n",
      "Task 361292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 117)\n",
      "Task 361293\n",
      "Task 361293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 5)\n",
      "Task 361294\n",
      "Task 361294\n",
      "(15000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import lightgbmlss\n",
    "import optuna\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from drf import drf\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "#SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "task_id=361093   #361096\n",
    "\n",
    "for task_id in benchmark_suite.tasks:\n",
    "        # Set the random seed for reproducibility\n",
    "        N_TRIALS=100\n",
    "        N_SAMPLES=100\n",
    "        PATIENCE=40\n",
    "        N_EPOCHS=1000\n",
    "        GP_ITERATIONS=1000\n",
    "        BATCH_SIZE=1024\n",
    "        seed=10\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        print(f\"Task {task_id}\")\n",
    "\n",
    "        # Create the checkpoint directory if it doesn't exist\n",
    "        os.makedirs('CHECKPOINTS/GOWER', exist_ok=True)\n",
    "        CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "        print(f\"Task {task_id}\")\n",
    "\n",
    "        task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "        dataset = task.get_dataset()\n",
    "\n",
    "        X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "                dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "        if len(X) > 15000:\n",
    "                indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "                X = X.iloc[indices,]\n",
    "                y = y[indices]\n",
    "\n",
    "        # Remove categorical columns with more than 20 unique values and non-categorical columns with less than 10 unique values\n",
    "        # Remove non-categorical columns with more than 70% of the data in one category\n",
    "        for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "                if len(X[col].unique()) > 20:\n",
    "                        X = X.drop(col, axis=1)\n",
    "\n",
    "        for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "                if len(X[col].unique()) < 10:\n",
    "                        X = X.drop(col, axis=1)\n",
    "                elif X[col].value_counts(normalize=True).max() > 0.7:\n",
    "                        X = X.drop(col, axis=1)\n",
    "        \n",
    "        # Find features with absolute correlation > 0.9\n",
    "        corr_matrix = X.corr().abs()\n",
    "        upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "        # Drop one of the highly correlated features\n",
    "        X = X.drop(high_corr_features, axis=1)\n",
    "        \n",
    "        print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53940"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 15000:\n",
    "    indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "    X = X.iloc[indices,]\n",
    "    y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, True, True, False, True]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Liberal1'] = X['Liberal'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actions_taken</th>\n",
       "      <th>Liberal</th>\n",
       "      <th>Unconstitutional</th>\n",
       "      <th>Precedent_alteration</th>\n",
       "      <th>Unanimous</th>\n",
       "      <th>Year_of_decision</th>\n",
       "      <th>Lower_court_disagreement</th>\n",
       "      <th>Liberal1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actions_taken</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007823</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>-0.007983</td>\n",
       "      <td>-0.025011</td>\n",
       "      <td>0.075318</td>\n",
       "      <td>-0.007765</td>\n",
       "      <td>-0.007823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal</th>\n",
       "      <td>-0.007823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259810</td>\n",
       "      <td>0.054968</td>\n",
       "      <td>0.151452</td>\n",
       "      <td>-0.184997</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unconstitutional</th>\n",
       "      <td>-0.039216</td>\n",
       "      <td>0.259810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>-0.017535</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>0.259810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precedent_alteration</th>\n",
       "      <td>-0.007983</td>\n",
       "      <td>0.054968</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022296</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>-0.039343</td>\n",
       "      <td>0.054968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unanimous</th>\n",
       "      <td>-0.025011</td>\n",
       "      <td>0.151452</td>\n",
       "      <td>-0.017535</td>\n",
       "      <td>-0.022296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>-0.046919</td>\n",
       "      <td>0.151452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year_of_decision</th>\n",
       "      <td>0.075318</td>\n",
       "      <td>-0.184997</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095766</td>\n",
       "      <td>-0.184997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lower_court_disagreement</th>\n",
       "      <td>-0.007765</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>-0.039343</td>\n",
       "      <td>-0.046919</td>\n",
       "      <td>0.095766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal1</th>\n",
       "      <td>-0.007823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259810</td>\n",
       "      <td>0.054968</td>\n",
       "      <td>0.151452</td>\n",
       "      <td>-0.184997</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Actions_taken   Liberal  Unconstitutional  \\\n",
       "Actions_taken                  1.000000 -0.007823         -0.039216   \n",
       "Liberal                       -0.007823  1.000000          0.259810   \n",
       "Unconstitutional              -0.039216  0.259810          1.000000   \n",
       "Precedent_alteration          -0.007983  0.054968          0.096501   \n",
       "Unanimous                     -0.025011  0.151452         -0.017535   \n",
       "Year_of_decision               0.075318 -0.184997          0.005088   \n",
       "Lower_court_disagreement      -0.007765 -0.015418          0.014282   \n",
       "Liberal1                      -0.007823  1.000000          0.259810   \n",
       "\n",
       "                          Precedent_alteration  Unanimous  Year_of_decision  \\\n",
       "Actions_taken                        -0.007983  -0.025011          0.075318   \n",
       "Liberal                               0.054968   0.151452         -0.184997   \n",
       "Unconstitutional                      0.096501  -0.017535          0.005088   \n",
       "Precedent_alteration                  1.000000  -0.022296         -0.019644   \n",
       "Unanimous                            -0.022296   1.000000         -0.001521   \n",
       "Year_of_decision                     -0.019644  -0.001521          1.000000   \n",
       "Lower_court_disagreement             -0.039343  -0.046919          0.095766   \n",
       "Liberal1                              0.054968   0.151452         -0.184997   \n",
       "\n",
       "                          Lower_court_disagreement  Liberal1  \n",
       "Actions_taken                            -0.007765 -0.007823  \n",
       "Liberal                                  -0.015418  1.000000  \n",
       "Unconstitutional                          0.014282  0.259810  \n",
       "Precedent_alteration                     -0.039343  0.054968  \n",
       "Unanimous                                -0.046919  0.151452  \n",
       "Year_of_decision                          0.095766 -0.184997  \n",
       "Lower_court_disagreement                  1.000000 -0.015418  \n",
       "Liberal1                                 -0.015418  1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 6], dtype=int64),)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(categorical_indicator)==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_indicator==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_elements = [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "    X[col] = X[col].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liberal',\n",
       " 'Unconstitutional',\n",
       " 'Precedent_alteration',\n",
       " 'Unanimous',\n",
       " 'Lower_court_disagreement']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "    print(len(X[col].unique()))\n",
    "    if len(X[col].unique()) < 10:\n",
    "        X = X.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9580454096742349\n",
      "0.038005923000987166\n"
     ]
    }
   ],
   "source": [
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "    if len(X[col].unique()) < 10:\n",
    "        X = X.drop(col, axis=1)\n",
    "    print(X[col].value_counts(normalize=True).max())\n",
    "    if X[col].value_counts(normalize=True).max() > 0.7:\n",
    "            X = X.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "    print(len(X[col].unique()))\n",
    "    if len(X[col].unique()) > 20:\n",
    "        X = X.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [attribute_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39marray(categorical_indicator)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [\u001b[43mattribute_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39marray(categorical_indicator)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "[attribute_names[i] for i in np.where(np.array(categorical_indicator)==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Liberal', 'Unconstitutional', 'Precedent_alteration', 'Unanimous',\n",
       "       'Lower_court_disagreement'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.select_dtypes(['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45590</th>\n",
       "      <td>0.52</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>62.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.10</td>\n",
       "      <td>5.17</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>1.01</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>61.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.45</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46038</th>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>61.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.28</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20381</th>\n",
       "      <td>0.31</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>1.20</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>61.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>6.86</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28975</th>\n",
       "      <td>0.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61.3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.37</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35857</th>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>61.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25689</th>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>63.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.17</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29814</th>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7617</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>61.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.42</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat cut color clarity  depth  table     x     y     z\n",
       "45590   0.52   4     1       5   62.3   57.0  5.10  5.17  3.20\n",
       "12110   1.01   3     4       5   61.3   59.0  6.41  6.45  3.94\n",
       "46038   0.57   2     1       2   61.8   57.0  5.33  5.28  3.28\n",
       "20381   0.31   2     2       5   62.0   56.0  4.35  4.39  2.71\n",
       "12744   1.20   2     6       5   61.8   55.0  6.84  6.86  4.23\n",
       "...      ...  ..   ...     ...    ...    ...   ...   ...   ...\n",
       "28975   0.31   2     1       3   61.3   55.0  4.34  4.37  2.67\n",
       "35857   0.40   2     0       5   61.9   58.0  4.70  4.73  2.92\n",
       "25689   0.30   4     3       5   63.5   59.0  4.22  4.17  2.66\n",
       "29814   0.30   3     0       2   62.4   60.0  4.26  4.23  2.65\n",
       "7617    1.01   1     0       3   61.5   56.0  6.36  6.42  3.93\n",
       "\n",
       "[15000 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Task 361094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Task 361096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Task 361097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m     X_clean_[col] \u001b[38;5;241m=\u001b[39m X_clean_[col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# calculate the Gower distance matrix for the training set\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m gower_dist_matrix_train \u001b[38;5;241m=\u001b[39m \u001b[43mgower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgower_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_clean_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# calculate the Gower distance for each data point in the training set\u001b[39;00m\n\u001b[0;32m    113\u001b[0m gower_dist_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(gower_dist_matrix_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\gower\\gower_dist.py:89\u001b[0m, in \u001b[0;36mgower_matrix\u001b[1;34m(data_x, data_y, weight, cat_features)\u001b[0m\n\u001b[0;32m     87\u001b[0m     j_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# call the main function\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mgower_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mX_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mY_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_n_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mY_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_n_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_max\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m#print(res)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m out[i,j_start:]\u001b[38;5;241m=\u001b[39mres\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\gower\\gower_dist.py:112\u001b[0m, in \u001b[0;36mgower_get\u001b[1;34m(xi_cat, xi_num, xj_cat, xj_num, feature_weight_cat, feature_weight_num, feature_weight_sum, categorical_features, ranges_of_numeric, max_of_numeric)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgower_get\u001b[39m(xi_cat,xi_num,xj_cat,xj_num,feature_weight_cat,\n\u001b[0;32m    107\u001b[0m               feature_weight_num,feature_weight_sum,categorical_features,\n\u001b[0;32m    108\u001b[0m               ranges_of_numeric,max_of_numeric ):\n\u001b[0;32m    109\u001b[0m     \n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# categorical columns\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     sij_cat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(xi_cat \u001b[38;5;241m==\u001b[39m xj_cat,np\u001b[38;5;241m.\u001b[39mzeros_like(xi_cat),np\u001b[38;5;241m.\u001b[39mones_like(xi_cat))\n\u001b[1;32m--> 112\u001b[0m     sum_cat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_weight_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43msij_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# numerical columns\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     abs_delta\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mabsolute(xi_num\u001b[38;5;241m-\u001b[39mxj_num)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from engression import engression\n",
    "import torch\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from pygam import LinearGAM\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import shutil\n",
    "import gpboost as gpb\n",
    "\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "#SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "#task_id=361093\n",
    "\n",
    "for task_id in benchmark_suite.tasks:\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    N_TRIALS=100\n",
    "    N_SAMPLES=100\n",
    "    PATIENCE=40\n",
    "    N_EPOCHS=1000\n",
    "    GP_ITERATIONS=1000\n",
    "    BATCH_SIZE=1024\n",
    "    seed=10\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "    if task_id==361099:\n",
    "        y=np.log(y)\n",
    "\n",
    "    if len(X) > 15000:\n",
    "        indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "        X = X.iloc[indices,]\n",
    "        y = y[indices]\n",
    "\n",
    "    # Remove categorical columns with more than 20 unique values and non-categorical columns with less than 10 unique values\n",
    "    # Remove non-categorical columns with more than 70% of the data in one category from X_clean\n",
    "    for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "        if len(X[col].unique()) > 20:\n",
    "            X = X.drop(col, axis=1)\n",
    "\n",
    "    X_clean=X.copy()\n",
    "    for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "        if len(X[col].unique()) < 10:\n",
    "            X = X.drop(col, axis=1)\n",
    "            X_clean = X_clean.drop(col, axis=1)\n",
    "        elif X[col].value_counts(normalize=True).max() > 0.7:\n",
    "            X_clean = X_clean.drop(col, axis=1)\n",
    "\n",
    "    # Find features with absolute correlation > 0.9\n",
    "    corr_matrix = X_clean.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "    # Drop one of the highly correlated features from X_clean\n",
    "    X_clean = X_clean.drop(high_corr_features, axis=1)\n",
    "\n",
    "    # Rename columns to avoid problems with LGBM\n",
    "    X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "    # Compute Gower distance and define train and test set\n",
    "    # calculate the Gower distance matrix for the entire dataset\n",
    "    for col in X_clean.select_dtypes(['category']).columns:\n",
    "        X_clean[col] = X_clean[col].astype('object')\n",
    "\n",
    "    gower_dist_matrix = gower.gower_matrix(X_clean)\n",
    "\n",
    "    # calculate the Gower distance for each data point\n",
    "    gower_dist = np.mean(gower_dist_matrix, axis=1)\n",
    "\n",
    "    gower_dist=pd.Series(gower_dist,index=X_clean.index)\n",
    "    far_index=gower_dist.index[np.where(gower_dist>=np.quantile(gower_dist,0.8))[0]]\n",
    "    close_index=gower_dist.index[np.where(gower_dist<np.quantile(gower_dist,0.8))[0]]\n",
    "\n",
    "    X_clean_ = X_clean.loc[close_index,:]\n",
    "\n",
    "    for col in X_clean_.select_dtypes(['category']).columns:\n",
    "        X_clean_[col] = X_clean_[col].astype('object')\n",
    "\n",
    "    # calculate the Gower distance matrix for the training set\n",
    "    gower_dist_matrix_train = gower.gower_matrix(X_clean_)\n",
    "\n",
    "    # calculate the Gower distance for each data point in the training set\n",
    "    gower_dist_train = np.mean(gower_dist_matrix_train, axis=1)\n",
    "\n",
    "    gower_dist_train=pd.Series(gower_dist_train,index=X_clean_.index)\n",
    "    far_index_train=gower_dist_train.index[np.where(gower_dist_train>=np.quantile(gower_dist_train,0.8))[0]]\n",
    "    close_index_train=gower_dist_train.index[np.where(gower_dist_train<np.quantile(gower_dist_train,0.8))[0]]\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    # Modify X_train_, X_val, X_train, and X_test to have dummy variables\n",
    "    X = pd.get_dummies(X, drop_first=True).astype('float32')\n",
    "    \n",
    "    print(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id=361095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "N_TRIALS=100\n",
    "N_SAMPLES=100\n",
    "PATIENCE=40\n",
    "N_EPOCHS=1000\n",
    "GP_ITERATIONS=1000\n",
    "BATCH_SIZE=1024\n",
    "seed=10\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "print(f\"Task {task_id}\")\n",
    "\n",
    "task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "dataset = task.get_dataset()\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "if task_id==361099:\n",
    "    y=np.log(y)\n",
    "\n",
    "if len(X) > 15000:\n",
    "    indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "    X = X.iloc[indices,]\n",
    "    y = y[indices]\n",
    "\n",
    "# Remove categorical columns with more than 20 unique values and non-categorical columns with less than 10 unique values\n",
    "# Remove non-categorical columns with more than 70% of the data in one category from X_clean\n",
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "    if len(X[col].unique()) > 20:\n",
    "        X = X.drop(col, axis=1)\n",
    "\n",
    "X_clean=X.copy()\n",
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "    if len(X[col].unique()) < 10:\n",
    "        X = X.drop(col, axis=1)\n",
    "        X_clean = X_clean.drop(col, axis=1)\n",
    "    elif X[col].value_counts(normalize=True).max() > 0.7:\n",
    "        X_clean = X_clean.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find features with absolute correlation > 0.9\n",
    "corr_matrix = X_clean.corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "# Drop one of the highly correlated features from X_clean\n",
    "X_clean = X_clean.drop(high_corr_features, axis=1)\n",
    "\n",
    "# Rename columns to avoid problems with LGBM\n",
    "X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "\n",
    "# Compute Gower distance and define train and test set\n",
    "# calculate the Gower distance matrix for the entire dataset\n",
    "for col in X_clean.select_dtypes(['category']).columns:\n",
    "    X_clean[col] = X_clean[col].astype('object')\n",
    "\n",
    "gower_dist_matrix = gower.gower_matrix(X_clean)\n",
    "\n",
    "# calculate the Gower distance for each data point\n",
    "gower_dist = np.mean(gower_dist_matrix, axis=1)\n",
    "\n",
    "gower_dist=pd.Series(gower_dist,index=X_clean.index)\n",
    "far_index=gower_dist.index[np.where(gower_dist>=np.quantile(gower_dist,0.8))[0]]\n",
    "close_index=gower_dist.index[np.where(gower_dist<np.quantile(gower_dist,0.8))[0]]\n",
    "\n",
    "X_clean_ = X_clean.loc[close_index,:]\n",
    "\n",
    "for col in X_clean_.select_dtypes(['category']).columns:\n",
    "    X_clean_[col] = X_clean_[col].astype('object')\n",
    "\n",
    "# calculate the Gower distance matrix for the training set\n",
    "gower_dist_matrix_train = gower.gower_matrix(X_clean_)\n",
    "\n",
    "# calculate the Gower distance for each data point in the training set\n",
    "gower_dist_train = np.mean(gower_dist_matrix_train, axis=1)\n",
    "\n",
    "gower_dist_train=pd.Series(gower_dist_train,index=X_clean_.index)\n",
    "far_index_train=gower_dist_train.index[np.where(gower_dist_train>=np.quantile(gower_dist_train,0.8))[0]]\n",
    "close_index_train=gower_dist_train.index[np.where(gower_dist_train<np.quantile(gower_dist_train,0.8))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Age_1</th>\n",
       "      <th>Age_2</th>\n",
       "      <th>Age_3</th>\n",
       "      <th>Age_4</th>\n",
       "      <th>Age_5</th>\n",
       "      <th>Age_6</th>\n",
       "      <th>City_Category_1</th>\n",
       "      <th>City_Category_2</th>\n",
       "      <th>Stay_In_Current_City_Years_1</th>\n",
       "      <th>Stay_In_Current_City_Years_2</th>\n",
       "      <th>Stay_In_Current_City_Years_3</th>\n",
       "      <th>Stay_In_Current_City_Years_4</th>\n",
       "      <th>Marital_Status_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166415</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90300</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8700</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81154</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164608</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64428</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128827</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160509</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150466</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Occupation  Product_Category_1  Product_Category_2  \\\n",
       "166415          12                   1                   2   \n",
       "90300           14                   6                  10   \n",
       "8700             4                   8                  14   \n",
       "81154           14                   8                  14   \n",
       "164608           0                   1                   2   \n",
       "...            ...                 ...                 ...   \n",
       "64428            7                   1                   2   \n",
       "128827           1                   5                   8   \n",
       "160509           4                   1                   8   \n",
       "150466           8                   4                   5   \n",
       "4514            10                   1                  15   \n",
       "\n",
       "        Product_Category_3  Gender_1  Age_1  Age_2  Age_3  Age_4  Age_5  \\\n",
       "166415                  15      True   True  False  False  False  False   \n",
       "90300                   13      True  False   True  False  False  False   \n",
       "8700                    17      True  False   True  False  False  False   \n",
       "81154                   17     False  False   True  False  False  False   \n",
       "164608                   5      True  False  False  False   True  False   \n",
       "...                    ...       ...    ...    ...    ...    ...    ...   \n",
       "64428                   15      True   True  False  False  False  False   \n",
       "128827                  14      True  False  False  False  False  False   \n",
       "160509                  17      True  False   True  False  False  False   \n",
       "150466                   8     False  False  False  False  False   True   \n",
       "4514                    16      True   True  False  False  False  False   \n",
       "\n",
       "        Age_6  City_Category_1  City_Category_2  Stay_In_Current_City_Years_1  \\\n",
       "166415  False             True            False                          True   \n",
       "90300   False            False             True                         False   \n",
       "8700    False             True            False                         False   \n",
       "81154   False            False            False                         False   \n",
       "164608  False            False             True                         False   \n",
       "...       ...              ...              ...                           ...   \n",
       "64428   False             True            False                         False   \n",
       "128827   True            False             True                          True   \n",
       "160509  False            False            False                         False   \n",
       "150466  False             True            False                          True   \n",
       "4514    False            False            False                         False   \n",
       "\n",
       "        Stay_In_Current_City_Years_2  Stay_In_Current_City_Years_3  \\\n",
       "166415                         False                         False   \n",
       "90300                           True                         False   \n",
       "8700                           False                          True   \n",
       "81154                          False                         False   \n",
       "164608                         False                         False   \n",
       "...                              ...                           ...   \n",
       "64428                          False                         False   \n",
       "128827                         False                         False   \n",
       "160509                          True                         False   \n",
       "150466                         False                         False   \n",
       "4514                           False                         False   \n",
       "\n",
       "        Stay_In_Current_City_Years_4  Marital_Status_1  \n",
       "166415                         False             False  \n",
       "90300                          False             False  \n",
       "8700                           False              True  \n",
       "81154                          False              True  \n",
       "164608                         False              True  \n",
       "...                              ...               ...  \n",
       "64428                          False             False  \n",
       "128827                         False             False  \n",
       "160509                         False              True  \n",
       "150466                         False             False  \n",
       "4514                           False             False  \n",
       "\n",
       "[15000 rows x 18 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, drop_first=True).astype('float32')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Age_1</th>\n",
       "      <th>Age_2</th>\n",
       "      <th>Age_3</th>\n",
       "      <th>Age_4</th>\n",
       "      <th>Age_5</th>\n",
       "      <th>Age_6</th>\n",
       "      <th>City_Category_1</th>\n",
       "      <th>City_Category_2</th>\n",
       "      <th>Stay_In_Current_City_Years_1</th>\n",
       "      <th>Stay_In_Current_City_Years_2</th>\n",
       "      <th>Stay_In_Current_City_Years_3</th>\n",
       "      <th>Stay_In_Current_City_Years_4</th>\n",
       "      <th>Marital_Status_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166415</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90300</th>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8700</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81154</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164608</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64428</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128827</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160509</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150466</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Occupation  Product_Category_1  Product_Category_2  \\\n",
       "166415        12.0                 1.0                 2.0   \n",
       "90300         14.0                 6.0                10.0   \n",
       "8700           4.0                 8.0                14.0   \n",
       "81154         14.0                 8.0                14.0   \n",
       "164608         0.0                 1.0                 2.0   \n",
       "...            ...                 ...                 ...   \n",
       "64428          7.0                 1.0                 2.0   \n",
       "128827         1.0                 5.0                 8.0   \n",
       "160509         4.0                 1.0                 8.0   \n",
       "150466         8.0                 4.0                 5.0   \n",
       "4514          10.0                 1.0                15.0   \n",
       "\n",
       "        Product_Category_3  Gender_1  Age_1  Age_2  Age_3  Age_4  Age_5  \\\n",
       "166415                15.0       1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "90300                 13.0       1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "8700                  17.0       1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "81154                 17.0       0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "164608                 5.0       1.0    0.0    0.0    0.0    1.0    0.0   \n",
       "...                    ...       ...    ...    ...    ...    ...    ...   \n",
       "64428                 15.0       1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "128827                14.0       1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "160509                17.0       1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "150466                 8.0       0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "4514                  16.0       1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "        Age_6  City_Category_1  City_Category_2  Stay_In_Current_City_Years_1  \\\n",
       "166415    0.0              1.0              0.0                           1.0   \n",
       "90300     0.0              0.0              1.0                           0.0   \n",
       "8700      0.0              1.0              0.0                           0.0   \n",
       "81154     0.0              0.0              0.0                           0.0   \n",
       "164608    0.0              0.0              1.0                           0.0   \n",
       "...       ...              ...              ...                           ...   \n",
       "64428     0.0              1.0              0.0                           0.0   \n",
       "128827    1.0              0.0              1.0                           1.0   \n",
       "160509    0.0              0.0              0.0                           0.0   \n",
       "150466    0.0              1.0              0.0                           1.0   \n",
       "4514      0.0              0.0              0.0                           0.0   \n",
       "\n",
       "        Stay_In_Current_City_Years_2  Stay_In_Current_City_Years_3  \\\n",
       "166415                           0.0                           0.0   \n",
       "90300                            1.0                           0.0   \n",
       "8700                             0.0                           1.0   \n",
       "81154                            0.0                           0.0   \n",
       "164608                           0.0                           0.0   \n",
       "...                              ...                           ...   \n",
       "64428                            0.0                           0.0   \n",
       "128827                           0.0                           0.0   \n",
       "160509                           1.0                           0.0   \n",
       "150466                           0.0                           0.0   \n",
       "4514                             0.0                           0.0   \n",
       "\n",
       "        Stay_In_Current_City_Years_4  Marital_Status_1  \n",
       "166415                           0.0               0.0  \n",
       "90300                            0.0               0.0  \n",
       "8700                             0.0               1.0  \n",
       "81154                            0.0               1.0  \n",
       "164608                           0.0               1.0  \n",
       "...                              ...               ...  \n",
       "64428                            0.0               0.0  \n",
       "128827                           0.0               0.0  \n",
       "160509                           0.0               1.0  \n",
       "150466                           0.0               0.0  \n",
       "4514                             0.0               0.0  \n",
       "\n",
       "[15000 rows x 18 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, drop_first=True).astype('float32').astype('float32')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Occupation                      float32\n",
       "Product_Category_1              float32\n",
       "Product_Category_2              float32\n",
       "Product_Category_3              float32\n",
       "Gender_1                        float32\n",
       "Age_1                           float32\n",
       "Age_2                           float32\n",
       "Age_3                           float32\n",
       "Age_4                           float32\n",
       "Age_5                           float32\n",
       "Age_6                           float32\n",
       "City_Category_1                 float32\n",
       "City_Category_2                 float32\n",
       "Stay_In_Current_City_Years_1    float32\n",
       "Stay_In_Current_City_Years_2    float32\n",
       "Stay_In_Current_City_Years_3    float32\n",
       "Stay_In_Current_City_Years_4    float32\n",
       "Marital_Status_1                float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.loc[close_index,:]\n",
    "X_test = X.loc[far_index,:]\n",
    "y_train = y.loc[close_index]\n",
    "y_test = y.loc[far_index]\n",
    "\n",
    "X_train_ = X_train.loc[close_index_train,:]\n",
    "X_val = X_train.loc[far_index_train,:]\n",
    "y_train_ = y_train.loc[close_index_train]\n",
    "y_val = y_train.loc[far_index_train]\n",
    "\n",
    "# Standardize the data for non-dummy variables\n",
    "non_dummy_cols = X.select_dtypes(exclude=['bool']).columns\n",
    "mean_X_train_ = np.mean(X_train_[non_dummy_cols], axis=0)\n",
    "std_X_train_ = np.std(X_train_[non_dummy_cols], axis=0)\n",
    "X_train_[non_dummy_cols] = (X_train_[non_dummy_cols] - mean_X_train_) / std_X_train_\n",
    "X_val = X_val.copy()\n",
    "X_val[non_dummy_cols] = (X_val[non_dummy_cols] - mean_X_train_) / std_X_train_\n",
    "\n",
    "mean_X_train = np.mean(X_train[non_dummy_cols], axis=0)\n",
    "std_X_train = np.std(X_train[non_dummy_cols], axis=0)\n",
    "X_train[non_dummy_cols] = (X_train[non_dummy_cols] - mean_X_train) / std_X_train\n",
    "X_test = X_test.copy()\n",
    "X_test[non_dummy_cols] = (X_test[non_dummy_cols] - mean_X_train) / std_X_train\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train__tensor = torch.tensor(X_train_.values, dtype=torch.float32)\n",
    "y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
