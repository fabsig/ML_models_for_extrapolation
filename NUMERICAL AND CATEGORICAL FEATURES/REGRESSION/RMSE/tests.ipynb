{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ebff59564c4e818599ea0b9934c6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54e07b6528946889bf5dfeef665c836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4229a9a56004f1e84136da09f890436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7624d644a1dc47c4917eb613c33853d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8960b077e3a24e1485d670273c62eadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE GP:  tensor(0.7159)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import lightgbmlss\n",
    "import optuna\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from drf import drf\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping, train_GP\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "#SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "task_id=361093\n",
    "task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "dataset = task.get_dataset()\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "N_TRIALS=100\n",
    "N_SAMPLES=100\n",
    "PATIENCE=40\n",
    "N_EPOCHS=1000\n",
    "GP_ITERATIONS=10\n",
    "seed=10\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# Compute Gower distance and define train and test set\n",
    "# calculate the Gower distance matrix\n",
    "X_gower = X.copy()\n",
    "\n",
    "for col in X_gower.select_dtypes(['category']).columns:\n",
    "    X_gower[col] = X_gower[col].astype('object')\n",
    "\n",
    "gower_dist_matrix = gower.gower_matrix(X_gower)\n",
    "\n",
    "# calculate the Gower distance for each data point\n",
    "gower_dist = np.mean(gower_dist_matrix, axis=1)\n",
    "\n",
    "gower_dist=pd.Series(gower_dist,index=X.index)\n",
    "far_index=gower_dist.index[np.where(gower_dist>=np.quantile(gower_dist,0.8))[0]]\n",
    "close_index=gower_dist.index[np.where(gower_dist<np.quantile(gower_dist,0.8))[0]]\n",
    "\n",
    "X_train = X.loc[close_index,:]\n",
    "X_gower_ = X_train.copy()\n",
    "\n",
    "for col in X_gower_.select_dtypes(['category']).columns:\n",
    "    X_gower_[col] = X_gower_[col].astype('object')\n",
    "\n",
    "# calculate the Gower distance matrix for the training set\n",
    "gower_dist_matrix_train = gower.gower_matrix(X_gower_)\n",
    "\n",
    "# calculate the Gower distance for each data point in the training set\n",
    "gower_dist_train = np.mean(gower_dist_matrix_train, axis=1)\n",
    "\n",
    "gower_dist_train=pd.Series(gower_dist_train,index=X_train.index)\n",
    "far_index_train=gower_dist_train.index[np.where(gower_dist_train>=np.quantile(gower_dist_train,0.8))[0]]\n",
    "close_index_train=gower_dist_train.index[np.where(gower_dist_train<np.quantile(gower_dist_train,0.8))[0]]\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "# Modify X_train_, X_val, X_train, and X_test to have dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True).astype('float32')\n",
    "\n",
    "X_train = X.loc[close_index,:]\n",
    "X_test = X.loc[far_index,:]\n",
    "y_train = y.loc[close_index]\n",
    "y_test = y.loc[far_index]\n",
    "\n",
    "X_train_ = X_train.loc[close_index_train,:]\n",
    "X_val = X_train.loc[far_index_train,:]\n",
    "y_train_ = y_train.loc[close_index_train]\n",
    "y_val = y_train.loc[far_index_train]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train__tensor = torch.tensor(X_train_.values, dtype=torch.float32)\n",
    "y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Convert to use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    X_train__tensor = X_train__tensor.cuda()\n",
    "    y_train__tensor = y_train__tensor.cuda()\n",
    "    X_train_tensor = X_train_tensor.cuda()\n",
    "    y_train_tensor = y_train_tensor.cuda()\n",
    "    X_val_tensor = X_val_tensor.cuda()\n",
    "    y_val_tensor = y_val_tensor.cuda()\n",
    "    X_test_tensor = X_test_tensor.cuda()\n",
    "    y_test_tensor = y_test_tensor.cuda()\n",
    "\n",
    "# Create flattened versions of the data\n",
    "y_val_np = y_val.values.flatten()\n",
    "y_test_np = y_test.values.flatten()\n",
    "\n",
    "\n",
    "#### Gaussian process\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Define the learning params\n",
    "training_iterations = GP_ITERATIONS\n",
    "\n",
    "# Define the kernels\n",
    "kernels = [\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=0.5, ard_num_dims=X_train_.shape[1])),\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=X_train_.shape[1])),\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=X_train_.shape[1])),\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=X_train_.shape[1])),\n",
    "]\n",
    "\n",
    "best_RMSE = float('inf')\n",
    "best_kernel = None\n",
    "\n",
    "for kernel in kernels:\n",
    "    # Initialize the Gaussian Process model and likelihood\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(X_train__tensor, y_train__tensor, likelihood, kernel)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    # Train the model\n",
    "    train_GP(model,X_train__tensor,y_train__tensor,training_iterations,mll,optimizer)\n",
    "    \n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        y_pred = model(X_val_tensor)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    RMSE = torch.sqrt(torch.mean(torch.square(y_val_tensor - y_pred.mean)))\n",
    "\n",
    "    # Update the best kernel if the current kernel has a lower RMSE\n",
    "    if RMSE < best_RMSE:\n",
    "        best_RMSE = RMSE\n",
    "        best_kernel = kernel\n",
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = best_kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Define the learning params\n",
    "training_iterations = GP_ITERATIONS\n",
    "\n",
    "# Initialize the Gaussian Process model and likelihood\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(X_train_tensor, y_train_tensor, likelihood)\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "# Train the model\n",
    "train_GP(model,X_train_tensor,y_train_tensor,training_iterations,mll,optimizer)\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Make predictions on the validation set\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    y_pred = model(X_test_tensor)\n",
    "\n",
    "# Calculate RMSE\n",
    "RMSE_GP = torch.sqrt(torch.mean(torch.square(y_test_tensor - y_pred.mean)))\n",
    "print(\"RMSE GP: \", RMSE_GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361073\n",
      "Task 361073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 26)\n",
      "Task 361074\n",
      "Task 361074\n",
      "(16599, 16)\n",
      "Task 361076\n",
      "Task 361076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 11)\n",
      "Task 361077\n",
      "Task 361077\n",
      "(13750, 33)\n",
      "Task 361078\n",
      "Task 361078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "Task 361079\n",
      "Task 361079\n",
      "(22784, 16)\n",
      "Task 361080\n",
      "Task 361080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 6)\n",
      "Task 361081\n",
      "Task 361081\n",
      "(10692, 8)\n",
      "Task 361082\n",
      "Task 361082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17379, 6)\n",
      "Task 361083\n",
      "Task 361083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581835, 9)\n",
      "Task 361084\n",
      "Task 361084\n",
      "(21613, 15)\n",
      "Task 361085\n",
      "Task 361085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10081, 6)\n",
      "Task 361086\n",
      "Task 361086\n",
      "(163065, 3)\n",
      "Task 361087\n",
      "Task 361087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13932, 13)\n",
      "Task 361088\n",
      "Task 361088\n",
      "(21263, 79)\n",
      "Task 361279\n",
      "Task 361279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8885, 42)\n",
      "Task 361280\n",
      "Task 361280\n",
      "(4177, 7)\n",
      "Task 361281\n",
      "Task 361281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5465575, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import lightgbmlss\n",
    "import optuna\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from drf import drf\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "#task_id=361093\n",
    "for task_id in benchmark_suite.tasks[1:]:\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    # Create the checkpoint directory if it doesn't exist\n",
    "    os.makedirs('CHECKPOINTS/GOWER', exist_ok=True)\n",
    "    CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[361072, 361073, 361074, 361076, 361077, 361078, 361079, 361080, 361081, 361082, 361083, 361084, 361085, 361086, 361087, 361088, 361279, 361280, 361281]\n"
     ]
    }
   ],
   "source": [
    "print(benchmark_suite.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(benchmark_suite.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361093\n",
      "Task 361093\n",
      "(4052, 6)\n",
      "Task 361094\n",
      "Task 361094\n",
      "(8641, 4)\n",
      "Task 361096\n",
      "Task 361096\n",
      "(15000, 6)\n",
      "Task 361097\n",
      "Task 361097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 263)\n",
      "Task 361098\n",
      "Task 361098\n",
      "(10692, 10)\n",
      "Task 361099\n",
      "Task 361099\n",
      "(15000, 10)\n",
      "Task 361101\n",
      "Task 361101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 9)\n",
      "Task 361102\n",
      "Task 361102\n",
      "(15000, 16)\n",
      "Task 361103\n",
      "Task 361103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 6)\n",
      "Task 361104\n",
      "Task 361104\n",
      "(15000, 7)\n",
      "Task 361287\n",
      "Task 361287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8885, 57)\n",
      "Task 361288\n",
      "Task 361288\n",
      "(4177, 3)\n",
      "Task 361289\n",
      "Task 361289\n",
      "(15000, 3)\n",
      "Task 361291\n",
      "Task 361291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 9)\n",
      "Task 361292\n",
      "Task 361292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 117)\n",
      "Task 361293\n",
      "Task 361293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 5)\n",
      "Task 361294\n",
      "Task 361294\n",
      "(15000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import lightgbmlss\n",
    "import optuna\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from drf import drf\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "#SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "task_id=361093   #361096\n",
    "\n",
    "for task_id in benchmark_suite.tasks:\n",
    "        # Set the random seed for reproducibility\n",
    "        N_TRIALS=100\n",
    "        N_SAMPLES=100\n",
    "        PATIENCE=40\n",
    "        N_EPOCHS=1000\n",
    "        GP_ITERATIONS=1000\n",
    "        BATCH_SIZE=1024\n",
    "        seed=10\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        print(f\"Task {task_id}\")\n",
    "\n",
    "        # Create the checkpoint directory if it doesn't exist\n",
    "        os.makedirs('CHECKPOINTS/GOWER', exist_ok=True)\n",
    "        CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "        print(f\"Task {task_id}\")\n",
    "\n",
    "        task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "        dataset = task.get_dataset()\n",
    "\n",
    "        X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "                dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "        if len(X) > 15000:\n",
    "                indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "                X = X.iloc[indices,]\n",
    "                y = y[indices]\n",
    "\n",
    "        # Remove categorical columns with more than 20 unique values and non-categorical columns with less than 10 unique values\n",
    "        # Remove non-categorical columns with more than 70% of the data in one category\n",
    "        for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "                if len(X[col].unique()) > 20:\n",
    "                        X = X.drop(col, axis=1)\n",
    "\n",
    "        for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "                if len(X[col].unique()) < 10:\n",
    "                        X = X.drop(col, axis=1)\n",
    "                elif X[col].value_counts(normalize=True).max() > 0.7:\n",
    "                        X = X.drop(col, axis=1)\n",
    "        \n",
    "        # Find features with absolute correlation > 0.9\n",
    "        corr_matrix = X.corr().abs()\n",
    "        upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "        # Drop one of the highly correlated features\n",
    "        X = X.drop(high_corr_features, axis=1)\n",
    "        \n",
    "        print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53940"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 15000:\n",
    "    indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "    X = X.iloc[indices,]\n",
    "    y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, True, True, False, True]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Liberal1'] = X['Liberal'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actions_taken</th>\n",
       "      <th>Liberal</th>\n",
       "      <th>Unconstitutional</th>\n",
       "      <th>Precedent_alteration</th>\n",
       "      <th>Unanimous</th>\n",
       "      <th>Year_of_decision</th>\n",
       "      <th>Lower_court_disagreement</th>\n",
       "      <th>Liberal1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actions_taken</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007823</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>-0.007983</td>\n",
       "      <td>-0.025011</td>\n",
       "      <td>0.075318</td>\n",
       "      <td>-0.007765</td>\n",
       "      <td>-0.007823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal</th>\n",
       "      <td>-0.007823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259810</td>\n",
       "      <td>0.054968</td>\n",
       "      <td>0.151452</td>\n",
       "      <td>-0.184997</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unconstitutional</th>\n",
       "      <td>-0.039216</td>\n",
       "      <td>0.259810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>-0.017535</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>0.259810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precedent_alteration</th>\n",
       "      <td>-0.007983</td>\n",
       "      <td>0.054968</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022296</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>-0.039343</td>\n",
       "      <td>0.054968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unanimous</th>\n",
       "      <td>-0.025011</td>\n",
       "      <td>0.151452</td>\n",
       "      <td>-0.017535</td>\n",
       "      <td>-0.022296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>-0.046919</td>\n",
       "      <td>0.151452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year_of_decision</th>\n",
       "      <td>0.075318</td>\n",
       "      <td>-0.184997</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>-0.001521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095766</td>\n",
       "      <td>-0.184997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lower_court_disagreement</th>\n",
       "      <td>-0.007765</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>-0.039343</td>\n",
       "      <td>-0.046919</td>\n",
       "      <td>0.095766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberal1</th>\n",
       "      <td>-0.007823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259810</td>\n",
       "      <td>0.054968</td>\n",
       "      <td>0.151452</td>\n",
       "      <td>-0.184997</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Actions_taken   Liberal  Unconstitutional  \\\n",
       "Actions_taken                  1.000000 -0.007823         -0.039216   \n",
       "Liberal                       -0.007823  1.000000          0.259810   \n",
       "Unconstitutional              -0.039216  0.259810          1.000000   \n",
       "Precedent_alteration          -0.007983  0.054968          0.096501   \n",
       "Unanimous                     -0.025011  0.151452         -0.017535   \n",
       "Year_of_decision               0.075318 -0.184997          0.005088   \n",
       "Lower_court_disagreement      -0.007765 -0.015418          0.014282   \n",
       "Liberal1                      -0.007823  1.000000          0.259810   \n",
       "\n",
       "                          Precedent_alteration  Unanimous  Year_of_decision  \\\n",
       "Actions_taken                        -0.007983  -0.025011          0.075318   \n",
       "Liberal                               0.054968   0.151452         -0.184997   \n",
       "Unconstitutional                      0.096501  -0.017535          0.005088   \n",
       "Precedent_alteration                  1.000000  -0.022296         -0.019644   \n",
       "Unanimous                            -0.022296   1.000000         -0.001521   \n",
       "Year_of_decision                     -0.019644  -0.001521          1.000000   \n",
       "Lower_court_disagreement             -0.039343  -0.046919          0.095766   \n",
       "Liberal1                              0.054968   0.151452         -0.184997   \n",
       "\n",
       "                          Lower_court_disagreement  Liberal1  \n",
       "Actions_taken                            -0.007765 -0.007823  \n",
       "Liberal                                  -0.015418  1.000000  \n",
       "Unconstitutional                          0.014282  0.259810  \n",
       "Precedent_alteration                     -0.039343  0.054968  \n",
       "Unanimous                                -0.046919  0.151452  \n",
       "Year_of_decision                          0.095766 -0.184997  \n",
       "Lower_court_disagreement                  1.000000 -0.015418  \n",
       "Liberal1                                 -0.015418  1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 6], dtype=int64),)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(categorical_indicator)==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_indicator==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_elements = [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "    X[col] = X[col].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liberal',\n",
       " 'Unconstitutional',\n",
       " 'Precedent_alteration',\n",
       " 'Unanimous',\n",
       " 'Lower_court_disagreement']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "    print(len(X[col].unique()))\n",
    "    if len(X[col].unique()) < 10:\n",
    "        X = X.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9580454096742349\n",
      "0.038005923000987166\n"
     ]
    }
   ],
   "source": [
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "    if len(X[col].unique()) < 10:\n",
    "        X = X.drop(col, axis=1)\n",
    "    print(X[col].value_counts(normalize=True).max())\n",
    "    if X[col].value_counts(normalize=True).max() > 0.7:\n",
    "            X = X.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "    print(len(X[col].unique()))\n",
    "    if len(X[col].unique()) > 20:\n",
    "        X = X.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [attribute_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39marray(categorical_indicator)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m [\u001b[43mattribute_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39marray(categorical_indicator)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "[attribute_names[i] for i in np.where(np.array(categorical_indicator)==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Liberal', 'Unconstitutional', 'Precedent_alteration', 'Unanimous',\n",
       "       'Lower_court_disagreement'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.select_dtypes(['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45590</th>\n",
       "      <td>0.52</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>62.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.10</td>\n",
       "      <td>5.17</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>1.01</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>61.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.45</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46038</th>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>61.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.28</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20381</th>\n",
       "      <td>0.31</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>1.20</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>61.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>6.86</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28975</th>\n",
       "      <td>0.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61.3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.37</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35857</th>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>61.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25689</th>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>63.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.17</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29814</th>\n",
       "      <td>0.30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7617</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>61.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.42</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat cut color clarity  depth  table     x     y     z\n",
       "45590   0.52   4     1       5   62.3   57.0  5.10  5.17  3.20\n",
       "12110   1.01   3     4       5   61.3   59.0  6.41  6.45  3.94\n",
       "46038   0.57   2     1       2   61.8   57.0  5.33  5.28  3.28\n",
       "20381   0.31   2     2       5   62.0   56.0  4.35  4.39  2.71\n",
       "12744   1.20   2     6       5   61.8   55.0  6.84  6.86  4.23\n",
       "...      ...  ..   ...     ...    ...    ...   ...   ...   ...\n",
       "28975   0.31   2     1       3   61.3   55.0  4.34  4.37  2.67\n",
       "35857   0.40   2     0       5   61.9   58.0  4.70  4.73  2.92\n",
       "25689   0.30   4     3       5   63.5   59.0  4.22  4.17  2.66\n",
       "29814   0.30   3     0       2   62.4   60.0  4.26  4.23  2.65\n",
       "7617    1.01   1     0       3   61.5   56.0  6.36  6.42  3.93\n",
       "\n",
       "[15000 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Task 361094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Task 361096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Task 361097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m     X_clean_[col] \u001b[38;5;241m=\u001b[39m X_clean_[col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# calculate the Gower distance matrix for the training set\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m gower_dist_matrix_train \u001b[38;5;241m=\u001b[39m \u001b[43mgower\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgower_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_clean_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# calculate the Gower distance for each data point in the training set\u001b[39;00m\n\u001b[0;32m    113\u001b[0m gower_dist_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(gower_dist_matrix_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\gower\\gower_dist.py:89\u001b[0m, in \u001b[0;36mgower_matrix\u001b[1;34m(data_x, data_y, weight, cat_features)\u001b[0m\n\u001b[0;32m     87\u001b[0m     j_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# call the main function\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mgower_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mX_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mY_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_n_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mY_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43my_n_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_max\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m#print(res)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m out[i,j_start:]\u001b[38;5;241m=\u001b[39mres\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\gower\\gower_dist.py:112\u001b[0m, in \u001b[0;36mgower_get\u001b[1;34m(xi_cat, xi_num, xj_cat, xj_num, feature_weight_cat, feature_weight_num, feature_weight_sum, categorical_features, ranges_of_numeric, max_of_numeric)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgower_get\u001b[39m(xi_cat,xi_num,xj_cat,xj_num,feature_weight_cat,\n\u001b[0;32m    107\u001b[0m               feature_weight_num,feature_weight_sum,categorical_features,\n\u001b[0;32m    108\u001b[0m               ranges_of_numeric,max_of_numeric ):\n\u001b[0;32m    109\u001b[0m     \n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# categorical columns\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     sij_cat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(xi_cat \u001b[38;5;241m==\u001b[39m xj_cat,np\u001b[38;5;241m.\u001b[39mzeros_like(xi_cat),np\u001b[38;5;241m.\u001b[39mones_like(xi_cat))\n\u001b[1;32m--> 112\u001b[0m     sum_cat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_weight_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43msij_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# numerical columns\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     abs_delta\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mabsolute(xi_num\u001b[38;5;241m-\u001b[39mxj_num)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from engression import engression\n",
    "import torch\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from pygam import LinearGAM\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import shutil\n",
    "import gpboost as gpb\n",
    "\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "#SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "#task_id=361093\n",
    "\n",
    "for task_id in benchmark_suite.tasks:\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    N_TRIALS=100\n",
    "    N_SAMPLES=100\n",
    "    PATIENCE=40\n",
    "    N_EPOCHS=1000\n",
    "    GP_ITERATIONS=1000\n",
    "    BATCH_SIZE=1024\n",
    "    seed=10\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "    if task_id==361099:\n",
    "        y=np.log(y)\n",
    "\n",
    "    if len(X) > 15000:\n",
    "        indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "        X = X.iloc[indices,]\n",
    "        y = y[indices]\n",
    "\n",
    "    # Remove categorical columns with more than 20 unique values and non-categorical columns with less than 10 unique values\n",
    "    # Remove non-categorical columns with more than 70% of the data in one category from X_clean\n",
    "    for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "        if len(X[col].unique()) > 20:\n",
    "            X = X.drop(col, axis=1)\n",
    "\n",
    "    X_clean=X.copy()\n",
    "    for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "        if len(X[col].unique()) < 10:\n",
    "            X = X.drop(col, axis=1)\n",
    "            X_clean = X_clean.drop(col, axis=1)\n",
    "        elif X[col].value_counts(normalize=True).max() > 0.7:\n",
    "            X_clean = X_clean.drop(col, axis=1)\n",
    "\n",
    "    # Find features with absolute correlation > 0.9\n",
    "    corr_matrix = X_clean.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "    # Drop one of the highly correlated features from X_clean\n",
    "    X_clean = X_clean.drop(high_corr_features, axis=1)\n",
    "\n",
    "    # Rename columns to avoid problems with LGBM\n",
    "    X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "    # Compute Gower distance and define train and test set\n",
    "    # calculate the Gower distance matrix for the entire dataset\n",
    "    for col in X_clean.select_dtypes(['category']).columns:\n",
    "        X_clean[col] = X_clean[col].astype('object')\n",
    "\n",
    "    gower_dist_matrix = gower.gower_matrix(X_clean)\n",
    "\n",
    "    # calculate the Gower distance for each data point\n",
    "    gower_dist = np.mean(gower_dist_matrix, axis=1)\n",
    "\n",
    "    gower_dist=pd.Series(gower_dist,index=X_clean.index)\n",
    "    far_index=gower_dist.index[np.where(gower_dist>=np.quantile(gower_dist,0.8))[0]]\n",
    "    close_index=gower_dist.index[np.where(gower_dist<np.quantile(gower_dist,0.8))[0]]\n",
    "\n",
    "    X_clean_ = X_clean.loc[close_index,:]\n",
    "\n",
    "    for col in X_clean_.select_dtypes(['category']).columns:\n",
    "        X_clean_[col] = X_clean_[col].astype('object')\n",
    "\n",
    "    # calculate the Gower distance matrix for the training set\n",
    "    gower_dist_matrix_train = gower.gower_matrix(X_clean_)\n",
    "\n",
    "    # calculate the Gower distance for each data point in the training set\n",
    "    gower_dist_train = np.mean(gower_dist_matrix_train, axis=1)\n",
    "\n",
    "    gower_dist_train=pd.Series(gower_dist_train,index=X_clean_.index)\n",
    "    far_index_train=gower_dist_train.index[np.where(gower_dist_train>=np.quantile(gower_dist_train,0.8))[0]]\n",
    "    close_index_train=gower_dist_train.index[np.where(gower_dist_train<np.quantile(gower_dist_train,0.8))[0]]\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    # Modify X_train_, X_val, X_train, and X_test to have dummy variables\n",
    "    X = pd.get_dummies(X, drop_first=True).astype('float32')\n",
    "    \n",
    "    print(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id=361095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "N_TRIALS=100\n",
    "N_SAMPLES=100\n",
    "PATIENCE=40\n",
    "N_EPOCHS=1000\n",
    "GP_ITERATIONS=1000\n",
    "BATCH_SIZE=1024\n",
    "seed=10\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "print(f\"Task {task_id}\")\n",
    "\n",
    "task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "dataset = task.get_dataset()\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "if task_id==361099:\n",
    "    y=np.log(y)\n",
    "\n",
    "if len(X) > 15000:\n",
    "    indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "    X = X.iloc[indices,]\n",
    "    y = y[indices]\n",
    "\n",
    "# Remove categorical columns with more than 20 unique values and non-categorical columns with less than 10 unique values\n",
    "# Remove non-categorical columns with more than 70% of the data in one category from X_clean\n",
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "    if len(X[col].unique()) > 20:\n",
    "        X = X.drop(col, axis=1)\n",
    "\n",
    "X_clean=X.copy()\n",
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "    if len(X[col].unique()) < 10:\n",
    "        X = X.drop(col, axis=1)\n",
    "        X_clean = X_clean.drop(col, axis=1)\n",
    "    elif X[col].value_counts(normalize=True).max() > 0.7:\n",
    "        X_clean = X_clean.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find features with absolute correlation > 0.9\n",
    "corr_matrix = X_clean.corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "# Drop one of the highly correlated features from X_clean\n",
    "X_clean = X_clean.drop(high_corr_features, axis=1)\n",
    "\n",
    "# Rename columns to avoid problems with LGBM\n",
    "X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "\n",
    "# Compute Gower distance and define train and test set\n",
    "# calculate the Gower distance matrix for the entire dataset\n",
    "for col in X_clean.select_dtypes(['category']).columns:\n",
    "    X_clean[col] = X_clean[col].astype('object')\n",
    "\n",
    "gower_dist_matrix = gower.gower_matrix(X_clean)\n",
    "\n",
    "# calculate the Gower distance for each data point\n",
    "gower_dist = np.mean(gower_dist_matrix, axis=1)\n",
    "\n",
    "gower_dist=pd.Series(gower_dist,index=X_clean.index)\n",
    "far_index=gower_dist.index[np.where(gower_dist>=np.quantile(gower_dist,0.8))[0]]\n",
    "close_index=gower_dist.index[np.where(gower_dist<np.quantile(gower_dist,0.8))[0]]\n",
    "\n",
    "X_clean_ = X_clean.loc[close_index,:]\n",
    "\n",
    "for col in X_clean_.select_dtypes(['category']).columns:\n",
    "    X_clean_[col] = X_clean_[col].astype('object')\n",
    "\n",
    "# calculate the Gower distance matrix for the training set\n",
    "gower_dist_matrix_train = gower.gower_matrix(X_clean_)\n",
    "\n",
    "# calculate the Gower distance for each data point in the training set\n",
    "gower_dist_train = np.mean(gower_dist_matrix_train, axis=1)\n",
    "\n",
    "gower_dist_train=pd.Series(gower_dist_train,index=X_clean_.index)\n",
    "far_index_train=gower_dist_train.index[np.where(gower_dist_train>=np.quantile(gower_dist_train,0.8))[0]]\n",
    "close_index_train=gower_dist_train.index[np.where(gower_dist_train<np.quantile(gower_dist_train,0.8))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Age_1</th>\n",
       "      <th>Age_2</th>\n",
       "      <th>Age_3</th>\n",
       "      <th>Age_4</th>\n",
       "      <th>Age_5</th>\n",
       "      <th>Age_6</th>\n",
       "      <th>City_Category_1</th>\n",
       "      <th>City_Category_2</th>\n",
       "      <th>Stay_In_Current_City_Years_1</th>\n",
       "      <th>Stay_In_Current_City_Years_2</th>\n",
       "      <th>Stay_In_Current_City_Years_3</th>\n",
       "      <th>Stay_In_Current_City_Years_4</th>\n",
       "      <th>Marital_Status_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166415</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90300</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8700</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81154</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164608</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64428</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128827</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160509</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150466</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Occupation  Product_Category_1  Product_Category_2  \\\n",
       "166415          12                   1                   2   \n",
       "90300           14                   6                  10   \n",
       "8700             4                   8                  14   \n",
       "81154           14                   8                  14   \n",
       "164608           0                   1                   2   \n",
       "...            ...                 ...                 ...   \n",
       "64428            7                   1                   2   \n",
       "128827           1                   5                   8   \n",
       "160509           4                   1                   8   \n",
       "150466           8                   4                   5   \n",
       "4514            10                   1                  15   \n",
       "\n",
       "        Product_Category_3  Gender_1  Age_1  Age_2  Age_3  Age_4  Age_5  \\\n",
       "166415                  15      True   True  False  False  False  False   \n",
       "90300                   13      True  False   True  False  False  False   \n",
       "8700                    17      True  False   True  False  False  False   \n",
       "81154                   17     False  False   True  False  False  False   \n",
       "164608                   5      True  False  False  False   True  False   \n",
       "...                    ...       ...    ...    ...    ...    ...    ...   \n",
       "64428                   15      True   True  False  False  False  False   \n",
       "128827                  14      True  False  False  False  False  False   \n",
       "160509                  17      True  False   True  False  False  False   \n",
       "150466                   8     False  False  False  False  False   True   \n",
       "4514                    16      True   True  False  False  False  False   \n",
       "\n",
       "        Age_6  City_Category_1  City_Category_2  Stay_In_Current_City_Years_1  \\\n",
       "166415  False             True            False                          True   \n",
       "90300   False            False             True                         False   \n",
       "8700    False             True            False                         False   \n",
       "81154   False            False            False                         False   \n",
       "164608  False            False             True                         False   \n",
       "...       ...              ...              ...                           ...   \n",
       "64428   False             True            False                         False   \n",
       "128827   True            False             True                          True   \n",
       "160509  False            False            False                         False   \n",
       "150466  False             True            False                          True   \n",
       "4514    False            False            False                         False   \n",
       "\n",
       "        Stay_In_Current_City_Years_2  Stay_In_Current_City_Years_3  \\\n",
       "166415                         False                         False   \n",
       "90300                           True                         False   \n",
       "8700                           False                          True   \n",
       "81154                          False                         False   \n",
       "164608                         False                         False   \n",
       "...                              ...                           ...   \n",
       "64428                          False                         False   \n",
       "128827                         False                         False   \n",
       "160509                          True                         False   \n",
       "150466                         False                         False   \n",
       "4514                           False                         False   \n",
       "\n",
       "        Stay_In_Current_City_Years_4  Marital_Status_1  \n",
       "166415                         False             False  \n",
       "90300                          False             False  \n",
       "8700                           False              True  \n",
       "81154                          False              True  \n",
       "164608                         False              True  \n",
       "...                              ...               ...  \n",
       "64428                          False             False  \n",
       "128827                         False             False  \n",
       "160509                         False              True  \n",
       "150466                         False             False  \n",
       "4514                           False             False  \n",
       "\n",
       "[15000 rows x 18 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, drop_first=True).astype('float32')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Age_1</th>\n",
       "      <th>Age_2</th>\n",
       "      <th>Age_3</th>\n",
       "      <th>Age_4</th>\n",
       "      <th>Age_5</th>\n",
       "      <th>Age_6</th>\n",
       "      <th>City_Category_1</th>\n",
       "      <th>City_Category_2</th>\n",
       "      <th>Stay_In_Current_City_Years_1</th>\n",
       "      <th>Stay_In_Current_City_Years_2</th>\n",
       "      <th>Stay_In_Current_City_Years_3</th>\n",
       "      <th>Stay_In_Current_City_Years_4</th>\n",
       "      <th>Marital_Status_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166415</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90300</th>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8700</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81154</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164608</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64428</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128827</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160509</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150466</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Occupation  Product_Category_1  Product_Category_2  \\\n",
       "166415        12.0                 1.0                 2.0   \n",
       "90300         14.0                 6.0                10.0   \n",
       "8700           4.0                 8.0                14.0   \n",
       "81154         14.0                 8.0                14.0   \n",
       "164608         0.0                 1.0                 2.0   \n",
       "...            ...                 ...                 ...   \n",
       "64428          7.0                 1.0                 2.0   \n",
       "128827         1.0                 5.0                 8.0   \n",
       "160509         4.0                 1.0                 8.0   \n",
       "150466         8.0                 4.0                 5.0   \n",
       "4514          10.0                 1.0                15.0   \n",
       "\n",
       "        Product_Category_3  Gender_1  Age_1  Age_2  Age_3  Age_4  Age_5  \\\n",
       "166415                15.0       1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "90300                 13.0       1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "8700                  17.0       1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "81154                 17.0       0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "164608                 5.0       1.0    0.0    0.0    0.0    1.0    0.0   \n",
       "...                    ...       ...    ...    ...    ...    ...    ...   \n",
       "64428                 15.0       1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "128827                14.0       1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "160509                17.0       1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "150466                 8.0       0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "4514                  16.0       1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "        Age_6  City_Category_1  City_Category_2  Stay_In_Current_City_Years_1  \\\n",
       "166415    0.0              1.0              0.0                           1.0   \n",
       "90300     0.0              0.0              1.0                           0.0   \n",
       "8700      0.0              1.0              0.0                           0.0   \n",
       "81154     0.0              0.0              0.0                           0.0   \n",
       "164608    0.0              0.0              1.0                           0.0   \n",
       "...       ...              ...              ...                           ...   \n",
       "64428     0.0              1.0              0.0                           0.0   \n",
       "128827    1.0              0.0              1.0                           1.0   \n",
       "160509    0.0              0.0              0.0                           0.0   \n",
       "150466    0.0              1.0              0.0                           1.0   \n",
       "4514      0.0              0.0              0.0                           0.0   \n",
       "\n",
       "        Stay_In_Current_City_Years_2  Stay_In_Current_City_Years_3  \\\n",
       "166415                           0.0                           0.0   \n",
       "90300                            1.0                           0.0   \n",
       "8700                             0.0                           1.0   \n",
       "81154                            0.0                           0.0   \n",
       "164608                           0.0                           0.0   \n",
       "...                              ...                           ...   \n",
       "64428                            0.0                           0.0   \n",
       "128827                           0.0                           0.0   \n",
       "160509                           1.0                           0.0   \n",
       "150466                           0.0                           0.0   \n",
       "4514                             0.0                           0.0   \n",
       "\n",
       "        Stay_In_Current_City_Years_4  Marital_Status_1  \n",
       "166415                           0.0               0.0  \n",
       "90300                            0.0               0.0  \n",
       "8700                             0.0               1.0  \n",
       "81154                            0.0               1.0  \n",
       "164608                           0.0               1.0  \n",
       "...                              ...               ...  \n",
       "64428                            0.0               0.0  \n",
       "128827                           0.0               0.0  \n",
       "160509                           0.0               1.0  \n",
       "150466                           0.0               0.0  \n",
       "4514                             0.0               0.0  \n",
       "\n",
       "[15000 rows x 18 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, drop_first=True).astype('float32').astype('float32')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Occupation                      float32\n",
       "Product_Category_1              float32\n",
       "Product_Category_2              float32\n",
       "Product_Category_3              float32\n",
       "Gender_1                        float32\n",
       "Age_1                           float32\n",
       "Age_2                           float32\n",
       "Age_3                           float32\n",
       "Age_4                           float32\n",
       "Age_5                           float32\n",
       "Age_6                           float32\n",
       "City_Category_1                 float32\n",
       "City_Category_2                 float32\n",
       "Stay_In_Current_City_Years_1    float32\n",
       "Stay_In_Current_City_Years_2    float32\n",
       "Stay_In_Current_City_Years_3    float32\n",
       "Stay_In_Current_City_Years_4    float32\n",
       "Marital_Status_1                float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.loc[close_index,:]\n",
    "X_test = X.loc[far_index,:]\n",
    "y_train = y.loc[close_index]\n",
    "y_test = y.loc[far_index]\n",
    "\n",
    "X_train_ = X_train.loc[close_index_train,:]\n",
    "X_val = X_train.loc[far_index_train,:]\n",
    "y_train_ = y_train.loc[close_index_train]\n",
    "y_val = y_train.loc[far_index_train]\n",
    "\n",
    "# Standardize the data for non-dummy variables\n",
    "non_dummy_cols = X.select_dtypes(exclude=['bool']).columns\n",
    "mean_X_train_ = np.mean(X_train_[non_dummy_cols], axis=0)\n",
    "std_X_train_ = np.std(X_train_[non_dummy_cols], axis=0)\n",
    "X_train_[non_dummy_cols] = (X_train_[non_dummy_cols] - mean_X_train_) / std_X_train_\n",
    "X_val = X_val.copy()\n",
    "X_val[non_dummy_cols] = (X_val[non_dummy_cols] - mean_X_train_) / std_X_train_\n",
    "\n",
    "mean_X_train = np.mean(X_train[non_dummy_cols], axis=0)\n",
    "std_X_train = np.std(X_train[non_dummy_cols], axis=0)\n",
    "X_train[non_dummy_cols] = (X_train[non_dummy_cols] - mean_X_train) / std_X_train\n",
    "X_test = X_test.copy()\n",
    "X_test[non_dummy_cols] = (X_test[non_dummy_cols] - mean_X_train) / std_X_train\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train__tensor = torch.tensor(X_train_.values, dtype=torch.float32)\n",
    "y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5969, -0.6261, -0.9981,  ..., -0.4450, -0.4003, -0.6977],\n",
       "        [ 0.9131,  2.1554,  0.9942,  ..., -0.4450, -0.4003, -0.6977],\n",
       "        [-0.1935, -0.6261, -0.5000,  ..., -0.4450, -0.4003, -0.6977],\n",
       "        ...,\n",
       "        [-1.1421,  1.5991,  0.4961,  ..., -0.4450, -0.4003, -0.6977],\n",
       "        [-0.6678, -0.6261,  0.4961,  ..., -0.4450, -0.4003,  1.4333],\n",
       "        [ 0.2807, -0.6261,  2.2394,  ..., -0.4450, -0.4003, -0.6977]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train__tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.3725, 9.6910, 8.3869,  ..., 8.5807, 9.8716, 9.6598])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train__tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "[I 2024-04-23 02:13:00,592] A new study created in memory with name: no-name-64ae196e-c09d-4a6b-8bd1-f23cdb90b8e0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-04-23 02:13:49,705] Trial 0 failed with parameters: {'n_blocks': 4, 'd_block': 20, 'dropout': 0.6336482349262754, 'learning_rate': 0.010495405390719734, 'weight_decay': 3.1083868392602017e-06, 'n_epochs': 1000} because of the following error: The value nan is not acceptable.\n",
      "[W 2024-04-23 02:13:49,707] Trial 0 failed with value tensor(nan).\n",
      "[W 2024-04-23 02:14:20,063] Trial 1 failed with parameters: {'n_blocks': 2, 'd_block': 107, 'dropout': 0.7605307121989587, 'learning_rate': 0.0002860388842288948, 'weight_decay': 2.765025054332623e-08} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_27504\\415208317.py\", line 222, in MLP_opt\n",
      "    n_epochs=train(MLP_model, criterion, optimizer, n_epochs, train__loader, val_loader, early_stopping, CHECKPOINT_PATH)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\NUMERICAL AND CATEGORICAL FEATURES\\REGRESSION\\RMSE\\utils.py\", line 42, in train\n",
      "    for batch_X, batch_y in train_loader:\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 162, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "[W 2024-04-23 02:14:20,117] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 241\u001b[0m\n\u001b[0;32m    239\u001b[0m sampler_MLP \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m    240\u001b[0m study_MLP \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(sampler\u001b[38;5;241m=\u001b[39msampler_MLP, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 241\u001b[0m \u001b[43mstudy_MLP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMLP_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m MLP_model \u001b[38;5;241m=\u001b[39m MLP(\n\u001b[0;32m    244\u001b[0m     d_in\u001b[38;5;241m=\u001b[39md_in,\n\u001b[0;32m    245\u001b[0m     d_out\u001b[38;5;241m=\u001b[39md_out,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    248\u001b[0m     dropout\u001b[38;5;241m=\u001b[39mstudy_MLP\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    249\u001b[0m     )\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[62], line 222\u001b[0m, in \u001b[0;36mMLP_opt\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    219\u001b[0m     MLP_model \u001b[38;5;241m=\u001b[39m MLP_model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m    221\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39mPATIENCE, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, path\u001b[38;5;241m=\u001b[39mCHECKPOINT_PATH)\n\u001b[1;32m--> 222\u001b[0m n_epochs\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMLP_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain__loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHECKPOINT_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m, n_epochs, n_epochs)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Point prediction\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\NUMERICAL AND CATEGORICAL FEATURES\\REGRESSION\\RMSE\\utils.py:42\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, training_iterations, train_loader, val_loader, early_stopping, checkpoint_path)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(training_iterations):\n\u001b[0;32m     41\u001b[0m     n_epochs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;66;03m# Move batch to device\u001b[39;00m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m     45\u001b[0m             batch_X \u001b[38;5;241m=\u001b[39m batch_X\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from engression import engression\n",
    "import torch\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from pygam import LinearGAM\n",
    "import gower\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import shutil\n",
    "import gpboost as gpb\n",
    "\n",
    "# Create the checkpoint directory if it doesn't exist\n",
    "if os.path.exists('CHECKPOINTS/GOWER'):\n",
    "    shutil.rmtree('CHECKPOINTS/GOWER')\n",
    "os.makedirs('CHECKPOINTS/GOWER')\n",
    "\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "#SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "#task_id=361093\n",
    "for task_id in benchmark_suite.tasks:\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    N_TRIALS=100\n",
    "    N_SAMPLES=100\n",
    "    PATIENCE=40\n",
    "    N_EPOCHS=1000\n",
    "    GP_ITERATIONS=1000\n",
    "    BATCH_SIZE=1024\n",
    "    seed=10\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "    \n",
    "    if task_id==361099:\n",
    "        y=np.log(y)\n",
    "    \n",
    "    if len(X) > 15000:\n",
    "        indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "        X = X.iloc[indices,]\n",
    "        y = y[indices]\n",
    "\n",
    "    # Remove categorical columns with more than 20 unique values and non-categorical columns with less than 10 unique values\n",
    "    # Remove non-categorical columns with more than 70% of the data in one category from X_clean\n",
    "    for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "        if len(X[col].unique()) > 20:\n",
    "            X = X.drop(col, axis=1)\n",
    "\n",
    "    X_clean=X.copy()\n",
    "    for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "        if len(X[col].unique()) < 10:\n",
    "            X = X.drop(col, axis=1)\n",
    "            X_clean = X_clean.drop(col, axis=1)\n",
    "        elif X[col].value_counts(normalize=True).max() > 0.7:\n",
    "            X_clean = X_clean.drop(col, axis=1)\n",
    "\n",
    "    # Find features with absolute correlation > 0.9\n",
    "    corr_matrix = X_clean.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "    # Drop one of the highly correlated features from X_clean\n",
    "    X_clean = X_clean.drop(high_corr_features, axis=1)\n",
    "\n",
    "    # Rename columns to avoid problems with LGBM\n",
    "    X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "    # Compute Gower distance and define train and test set\n",
    "    # calculate the Gower distance matrix for the entire dataset\n",
    "    for col in X_clean.select_dtypes(['category']).columns:\n",
    "        X_clean[col] = X_clean[col].astype('object')\n",
    "\n",
    "    gower_dist_matrix = gower.gower_matrix(X_clean)\n",
    "\n",
    "    # calculate the Gower distance for each data point\n",
    "    gower_dist = np.mean(gower_dist_matrix, axis=1)\n",
    "\n",
    "    gower_dist=pd.Series(gower_dist,index=X_clean.index)\n",
    "    far_index=gower_dist.index[np.where(gower_dist>=np.quantile(gower_dist,0.8))[0]]\n",
    "    close_index=gower_dist.index[np.where(gower_dist<np.quantile(gower_dist,0.8))[0]]\n",
    "\n",
    "    X_clean_ = X_clean.loc[close_index,:]\n",
    "\n",
    "    for col in X_clean_.select_dtypes(['category']).columns:\n",
    "        X_clean_[col] = X_clean_[col].astype('object')\n",
    "\n",
    "    # calculate the Gower distance matrix for the training set\n",
    "    gower_dist_matrix_train = gower.gower_matrix(X_clean_)\n",
    "\n",
    "    # calculate the Gower distance for each data point in the training set\n",
    "    gower_dist_train = np.mean(gower_dist_matrix_train, axis=1)\n",
    "\n",
    "    gower_dist_train=pd.Series(gower_dist_train,index=X_clean_.index)\n",
    "    far_index_train=gower_dist_train.index[np.where(gower_dist_train>=np.quantile(gower_dist_train,0.8))[0]]\n",
    "    close_index_train=gower_dist_train.index[np.where(gower_dist_train<np.quantile(gower_dist_train,0.8))[0]]\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    # Modify X_train_, X_val, X_train, and X_test to have dummy variables\n",
    "    X = pd.get_dummies(X, drop_first=True).astype('float32')\n",
    "\n",
    "    X_train = X.loc[close_index,:]\n",
    "    X_test = X.loc[far_index,:]\n",
    "    y_train = y.loc[close_index]\n",
    "    y_test = y.loc[far_index]\n",
    "\n",
    "    X_train_ = X_train.loc[close_index_train,:]\n",
    "    X_val = X_train.loc[far_index_train,:]\n",
    "    y_train_ = y_train.loc[close_index_train]\n",
    "    y_val = y_train.loc[far_index_train]\n",
    "\n",
    "    # Standardize the data for non-dummy variables\n",
    "    non_dummy_cols = X.select_dtypes(exclude=['bool']).columns\n",
    "    mean_X_train_ = np.mean(X_train_[non_dummy_cols], axis=0)\n",
    "    std_X_train_ = np.std(X_train_[non_dummy_cols], axis=0)\n",
    "    X_train_[non_dummy_cols] = (X_train_[non_dummy_cols] - mean_X_train_) / std_X_train_\n",
    "    X_val = X_val.copy()\n",
    "    X_val[non_dummy_cols] = (X_val[non_dummy_cols] - mean_X_train_) / std_X_train_\n",
    "\n",
    "    mean_X_train = np.mean(X_train[non_dummy_cols], axis=0)\n",
    "    std_X_train = np.std(X_train[non_dummy_cols], axis=0)\n",
    "    X_train[non_dummy_cols] = (X_train[non_dummy_cols] - mean_X_train) / std_X_train\n",
    "    X_test = X_test.copy()\n",
    "    X_test[non_dummy_cols] = (X_test[non_dummy_cols] - mean_X_train) / std_X_train\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train__tensor = torch.tensor(X_train_.values, dtype=torch.float32)\n",
    "    y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Convert to use GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        X_train__tensor = X_train__tensor.cuda()\n",
    "        y_train__tensor = y_train__tensor.cuda()\n",
    "        X_train_tensor = X_train_tensor.cuda()\n",
    "        y_train_tensor = y_train_tensor.cuda()\n",
    "        X_val_tensor = X_val_tensor.cuda()\n",
    "        y_val_tensor = y_val_tensor.cuda()\n",
    "        X_test_tensor = X_test_tensor.cuda()\n",
    "        y_test_tensor = y_test_tensor.cuda()\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    # Create flattened versions of the data\n",
    "    y_val_np = y_val.values.flatten()\n",
    "    y_test_np = y_test.values.flatten()\n",
    "\n",
    "    # Create TensorDatasets for training and validation sets\n",
    "    train__dataset = TensorDataset(X_train__tensor, y_train__tensor)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # Create DataLoaders for training and validation sets\n",
    "    train__loader = DataLoader(train__dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Define d_out and d_in\n",
    "    d_out = 1  \n",
    "    d_in=X_train_.shape[1]\n",
    "\n",
    "    #### MLP\n",
    "    def MLP_opt(trial):\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        n_blocks = trial.suggest_int(\"n_blocks\", 1, 5)\n",
    "        d_block = trial.suggest_int(\"d_block\", 10, 500)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0, 1)\n",
    "\n",
    "        MLP_model = MLP(\n",
    "        d_in=d_in,\n",
    "        d_out=d_out,\n",
    "        n_blocks=n_blocks,\n",
    "        d_block=d_block,\n",
    "        dropout=dropout,\n",
    "        )\n",
    "        n_epochs=N_EPOCHS\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.0001, 0.05, log=True)\n",
    "        weight_decay=trial.suggest_float('weight_decay', 1e-8, 1e-3, log=True)\n",
    "        optimizer=torch.optim.Adam(MLP_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            MLP_model = MLP_model.cuda()\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=PATIENCE, verbose=False, path=CHECKPOINT_PATH)\n",
    "        n_epochs=train(MLP_model, criterion, optimizer, n_epochs, train__loader, val_loader, early_stopping, CHECKPOINT_PATH)\n",
    "        n_epochs = trial.suggest_int('n_epochs', n_epochs, n_epochs)\n",
    "\n",
    "        # Point prediction\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch_X, _ in val_loader:\n",
    "                batch_predictions = MLP_model(batch_X).reshape(-1,)\n",
    "                predictions.append(batch_predictions.cpu().numpy())\n",
    "\n",
    "        y_val_hat_MLP = torch.Tensor(np.concatenate(predictions))\n",
    "        if torch.cuda.is_available():\n",
    "            y_val_hat_MLP = y_val_hat_MLP.cuda()\n",
    "        RMSE_MLP=torch.sqrt(torch.mean(torch.square(y_val_tensor - y_val_hat_MLP)))\n",
    "\n",
    "        return RMSE_MLP\n",
    "\n",
    "    sampler_MLP = optuna.samplers.TPESampler(seed=seed)\n",
    "    study_MLP = optuna.create_study(sampler=sampler_MLP, direction='minimize')\n",
    "    study_MLP.optimize(MLP_opt, n_trials=N_TRIALS)\n",
    "\n",
    "    MLP_model = MLP(\n",
    "        d_in=d_in,\n",
    "        d_out=d_out,\n",
    "        n_blocks=study_MLP.best_params['n_blocks'],\n",
    "        d_block=study_MLP.best_params['d_block'],\n",
    "        dropout=study_MLP.best_params['dropout'],\n",
    "        )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        MLP_model = MLP_model.cuda()\n",
    "        \n",
    "    n_epochs=study_MLP.best_params['n_epochs']\n",
    "    learning_rate=study_MLP.best_params['learning_rate']\n",
    "    weight_decay=study_MLP.best_params['weight_decay']\n",
    "    optimizer=torch.optim.Adam(MLP_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    train_no_early_stopping(MLP_model, criterion, optimizer, n_epochs, train_loader)\n",
    "\n",
    "    # Point prediction\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, _ in test_loader:\n",
    "            batch_predictions = MLP_model(batch_X).reshape(-1,)\n",
    "            predictions.append(batch_predictions.cpu().numpy())\n",
    "\n",
    "    y_test_hat_MLP = torch.Tensor(np.concatenate(predictions))\n",
    "    if torch.cuda.is_available():\n",
    "        y_test_hat_MLP = y_test_hat_MLP.cuda()\n",
    "    RMSE_MLP=torch.sqrt(torch.mean(torch.square(y_test_tensor - y_test_hat_MLP)))\n",
    "    print(\"RMSE MLP: \", RMSE_MLP)\n",
    "    del MLP_model, optimizer, criterion, y_test_hat_MLP, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model = MLP(\n",
    "    d_in=d_in,\n",
    "    d_out=d_out,\n",
    "    n_blocks=3,\n",
    "    d_block=10,\n",
    "    dropout=0,\n",
    "    )\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    MLP_model = MLP_model.cuda()\n",
    "    \n",
    "n_epochs=100\n",
    "learning_rate=0.001\n",
    "weight_decay=0\n",
    "optimizer=torch.optim.Adam(MLP_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_no_early_stopping(MLP_model, criterion, optimizer, n_epochs, train_loader)\n",
    "\n",
    "# Point prediction\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, _ in test_loader:\n",
    "        batch_predictions = MLP_model(batch_X).reshape(-1,)\n",
    "        predictions.append(batch_predictions.cpu().numpy())\n",
    "\n",
    "y_test_hat_MLP = torch.Tensor(np.concatenate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.isnan(X)).sum(axis=1).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actions_taken</th>\n",
       "      <th>Year_of_decision</th>\n",
       "      <th>Liberal_1</th>\n",
       "      <th>Unconstitutional_1</th>\n",
       "      <th>Precedent_alteration_1</th>\n",
       "      <th>Unanimous_1</th>\n",
       "      <th>Lower_court_disagreement_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>-0.958795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.494657</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>-0.958795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.669050</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>1.042976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.669050</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>1.042976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.669050</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.304463</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>-0.958795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.669050</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>-0.958795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.669050</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>1.042976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.494657</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>-0.958795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.669050</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>-0.958795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.494657</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>-0.958795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.669050</td>\n",
       "      <td>-0.373006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3234 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actions_taken  Year_of_decision  Liberal_1  Unconstitutional_1  \\\n",
       "1         -0.176799         -1.983996  -0.958795                 NaN   \n",
       "2         -0.176799         -1.983996  -0.958795                 NaN   \n",
       "4         -0.176799         -1.983996   1.042976                 NaN   \n",
       "6         -0.176799         -1.983996   1.042976                 NaN   \n",
       "8          1.304463         -1.983996  -0.958795                 NaN   \n",
       "...             ...               ...        ...                 ...   \n",
       "4042      -0.176799          1.652324  -0.958795                 NaN   \n",
       "4044      -0.176799          1.652324   1.042976                 NaN   \n",
       "4045      -0.176799          1.652324  -0.958795                 NaN   \n",
       "4046      -0.176799          1.652324  -0.958795                 NaN   \n",
       "4050      -0.176799          1.652324  -0.958795                 NaN   \n",
       "\n",
       "      Precedent_alteration_1  Unanimous_1  Lower_court_disagreement_1  \n",
       "1                        NaN     1.494657                   -0.373006  \n",
       "2                        NaN    -0.669050                   -0.373006  \n",
       "4                        NaN    -0.669050                   -0.373006  \n",
       "6                        NaN    -0.669050                   -0.373006  \n",
       "8                        NaN    -0.669050                   -0.373006  \n",
       "...                      ...          ...                         ...  \n",
       "4042                     NaN    -0.669050                   -0.373006  \n",
       "4044                     NaN     1.494657                   -0.373006  \n",
       "4045                     NaN    -0.669050                   -0.373006  \n",
       "4046                     NaN     1.494657                   -0.373006  \n",
       "4050                     NaN    -0.669050                   -0.373006  \n",
       "\n",
       "[3234 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_hat_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "N_TRIALS=100\n",
    "N_SAMPLES=100\n",
    "PATIENCE=40\n",
    "N_EPOCHS=1000\n",
    "GP_ITERATIONS=1000\n",
    "BATCH_SIZE=1024\n",
    "seed=10\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "CHECKPOINT_PATH = f'CHECKPOINTS/GOWER/task_{task_id}.pt'\n",
    "\n",
    "print(f\"Task {task_id}\")\n",
    "\n",
    "task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "dataset = task.get_dataset()\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "if task_id==361099:\n",
    "    y=np.log(y)\n",
    "\n",
    "if len(X) > 15000:\n",
    "    indices = np.random.choice(X.index, size=15000, replace=False)\n",
    "    X = X.iloc[indices,]\n",
    "    y = y[indices]\n",
    "\n",
    "# Remove categorical columns with more than 20 unique values and non-categorical columns with less than 10 unique values\n",
    "# Remove non-categorical columns with more than 70% of the data in one category from X_clean\n",
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if indicator]:\n",
    "    if len(X[col].unique()) > 20:\n",
    "        X = X.drop(col, axis=1)\n",
    "\n",
    "X_clean=X.copy()\n",
    "for col in [attribute for attribute, indicator in zip(attribute_names, categorical_indicator) if not indicator]:\n",
    "    if len(X[col].unique()) < 10:\n",
    "        X = X.drop(col, axis=1)\n",
    "        X_clean = X_clean.drop(col, axis=1)\n",
    "    elif X[col].value_counts(normalize=True).max() > 0.7:\n",
    "        X_clean = X_clean.drop(col, axis=1)\n",
    "\n",
    "# Find features with absolute correlation > 0.9\n",
    "corr_matrix = X_clean.corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "# Drop one of the highly correlated features from X_clean\n",
    "X_clean = X_clean.drop(high_corr_features, axis=1)\n",
    "\n",
    "# Rename columns to avoid problems with LGBM\n",
    "X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "# Compute Gower distance and define train and test set\n",
    "# calculate the Gower distance matrix for the entire dataset\n",
    "for col in X_clean.select_dtypes(['category']).columns:\n",
    "    X_clean[col] = X_clean[col].astype('object')\n",
    "\n",
    "gower_dist_matrix = gower.gower_matrix(X_clean)\n",
    "\n",
    "# calculate the Gower distance for each data point\n",
    "gower_dist = np.mean(gower_dist_matrix, axis=1)\n",
    "\n",
    "gower_dist=pd.Series(gower_dist,index=X_clean.index)\n",
    "far_index=gower_dist.index[np.where(gower_dist>=np.quantile(gower_dist,0.8))[0]]\n",
    "close_index=gower_dist.index[np.where(gower_dist<np.quantile(gower_dist,0.8))[0]]\n",
    "\n",
    "X_clean_ = X_clean.loc[close_index,:]\n",
    "\n",
    "for col in X_clean_.select_dtypes(['category']).columns:\n",
    "    X_clean_[col] = X_clean_[col].astype('object')\n",
    "\n",
    "# calculate the Gower distance matrix for the training set\n",
    "gower_dist_matrix_train = gower.gower_matrix(X_clean_)\n",
    "\n",
    "# calculate the Gower distance for each data point in the training set\n",
    "gower_dist_train = np.mean(gower_dist_matrix_train, axis=1)\n",
    "\n",
    "gower_dist_train=pd.Series(gower_dist_train,index=X_clean_.index)\n",
    "far_index_train=gower_dist_train.index[np.where(gower_dist_train>=np.quantile(gower_dist_train,0.8))[0]]\n",
    "close_index_train=gower_dist_train.index[np.where(gower_dist_train<np.quantile(gower_dist_train,0.8))[0]]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "# Modify X_train_, X_val, X_train, and X_test to have dummy variables\n",
    "non_dummy_cols = X.select_dtypes(exclude=['bool', 'category', 'object', 'string']).columns\n",
    "X = pd.get_dummies(X, drop_first=True).astype('float32')\n",
    "\n",
    "X_train = X.loc[close_index,:]\n",
    "X_test = X.loc[far_index,:]\n",
    "y_train = y.loc[close_index]\n",
    "y_test = y.loc[far_index]\n",
    "\n",
    "X_train_ = X_train.loc[close_index_train,:]\n",
    "X_val = X_train.loc[far_index_train,:]\n",
    "y_train_ = y_train.loc[close_index_train]\n",
    "y_val = y_train.loc[far_index_train]\n",
    "\n",
    "# Standardize the data for non-dummy variables\n",
    "mean_X_train_ = np.mean(X_train_[non_dummy_cols], axis=0)\n",
    "std_X_train_ = np.std(X_train_[non_dummy_cols], axis=0)\n",
    "X_train_[non_dummy_cols] = (X_train_[non_dummy_cols] - mean_X_train_) / std_X_train_\n",
    "X_val = X_val.copy()\n",
    "X_val[non_dummy_cols] = (X_val[non_dummy_cols] - mean_X_train_) / std_X_train_\n",
    "\n",
    "mean_X_train = np.mean(X_train[non_dummy_cols], axis=0)\n",
    "std_X_train = np.std(X_train[non_dummy_cols], axis=0)\n",
    "X_train[non_dummy_cols] = (X_train[non_dummy_cols] - mean_X_train) / std_X_train\n",
    "X_test = X_test.copy()\n",
    "X_test[non_dummy_cols] = (X_test[non_dummy_cols] - mean_X_train) / std_X_train\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train__tensor = torch.tensor(X_train_.values, dtype=torch.float32)\n",
    "y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Convert to use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    X_train__tensor = X_train__tensor.cuda()\n",
    "    y_train__tensor = y_train__tensor.cuda()\n",
    "    X_train_tensor = X_train_tensor.cuda()\n",
    "    y_train_tensor = y_train_tensor.cuda()\n",
    "    X_val_tensor = X_val_tensor.cuda()\n",
    "    y_val_tensor = y_val_tensor.cuda()\n",
    "    X_test_tensor = X_test_tensor.cuda()\n",
    "    y_test_tensor = y_test_tensor.cuda()\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Create flattened versions of the data\n",
    "y_val_np = y_val.values.flatten()\n",
    "y_test_np = y_test.values.flatten()\n",
    "\n",
    "# Create TensorDatasets for training and validation sets\n",
    "train__dataset = TensorDataset(X_train__tensor, y_train__tensor)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders for training and validation sets\n",
    "train__loader = DataLoader(train__dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Define d_out and d_in\n",
    "d_out = 1  \n",
    "d_in=X_train_.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actions_taken</th>\n",
       "      <th>Year_of_decision</th>\n",
       "      <th>Liberal_1</th>\n",
       "      <th>Unconstitutional_1</th>\n",
       "      <th>Precedent_alteration_1</th>\n",
       "      <th>Unanimous_1</th>\n",
       "      <th>Lower_court_disagreement_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.304463</td>\n",
       "      <td>-1.983996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>-0.176799</td>\n",
       "      <td>1.652324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3234 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actions_taken  Year_of_decision  Liberal_1  Unconstitutional_1  \\\n",
       "1         -0.176799         -1.983996        0.0                 0.0   \n",
       "2         -0.176799         -1.983996        0.0                 0.0   \n",
       "4         -0.176799         -1.983996        1.0                 0.0   \n",
       "6         -0.176799         -1.983996        1.0                 0.0   \n",
       "8          1.304463         -1.983996        0.0                 0.0   \n",
       "...             ...               ...        ...                 ...   \n",
       "4042      -0.176799          1.652324        0.0                 0.0   \n",
       "4044      -0.176799          1.652324        1.0                 0.0   \n",
       "4045      -0.176799          1.652324        0.0                 0.0   \n",
       "4046      -0.176799          1.652324        0.0                 0.0   \n",
       "4050      -0.176799          1.652324        0.0                 0.0   \n",
       "\n",
       "      Precedent_alteration_1  Unanimous_1  Lower_court_disagreement_1  \n",
       "1                        0.0          1.0                         0.0  \n",
       "2                        0.0          0.0                         0.0  \n",
       "4                        0.0          0.0                         0.0  \n",
       "6                        0.0          0.0                         0.0  \n",
       "8                        0.0          0.0                         0.0  \n",
       "...                      ...          ...                         ...  \n",
       "4042                     0.0          0.0                         0.0  \n",
       "4044                     0.0          1.0                         0.0  \n",
       "4045                     0.0          0.0                         0.0  \n",
       "4046                     0.0          1.0                         0.0  \n",
       "4050                     0.0          0.0                         0.0  \n",
       "\n",
       "[3234 rows x 7 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
