{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\1696384795.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "# Specify the directory path\n",
    "directory = 'RESULTS/CLUSTERING'\n",
    "\n",
    "# Get all the file names in the directory\n",
    "file_names = os.listdir(directory)\n",
    "\n",
    "# Extract the task IDs from the file names\n",
    "task_ids = [int(file_name.split('_')[0]) for file_name in file_names]\n",
    "\n",
    "for task_id in task_ids:\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "    \n",
    "    if len(X)>=100000:\n",
    "        continue\n",
    "    \n",
    "    # Find features with absolute correlation > 0.9\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "    # Drop one of the highly correlated features\n",
    "    X = X.drop(high_corr_features, axis=1)\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    N_TRIALS=100\n",
    "    N_SAMPLES=100\n",
    "    PATIENCE=40\n",
    "    N_EPOCHS=1000\n",
    "    GP_ITERATIONS=1000\n",
    "    BATCH_SIZE=1024\n",
    "    seed=10\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "    # New new implementation\n",
    "    N_CLUSTERS=20\n",
    "    # calculate the mean and covariance matrix of the dataset\n",
    "    mean = np.mean(X, axis=0)\n",
    "    cov = np.cov(X.T)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # transform data to compute the clusters\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=0, n_init=\"auto\").fit(X_scaled)\n",
    "    distances=[]\n",
    "    mahalanobis_dist=[]\n",
    "    counts=[]\n",
    "    ideal_len=len(kmeans.labels_)/5\n",
    "    for i in np.arange(N_CLUSTERS):\n",
    "        distances.append(np.abs(np.sum(kmeans.labels_==i)-ideal_len))\n",
    "        counts.append(np.sum(kmeans.labels_==i))\n",
    "        mean_k= np.mean(X.loc[kmeans.labels_==i,:], axis=0)\n",
    "        mahalanobis_dist.append(mahalanobis(mean_k, mean, np.linalg.inv(cov)))\n",
    "\n",
    "    dist_df=pd.DataFrame(data={'mahalanobis_dist': mahalanobis_dist, 'count': counts}, index=np.arange(N_CLUSTERS))\n",
    "    dist_df=dist_df.sort_values('mahalanobis_dist', ascending=False)\n",
    "    dist_df['cumulative_count']=dist_df['count'].cumsum()\n",
    "    dist_df['abs_diff']=np.abs(dist_df['cumulative_count']-ideal_len)\n",
    "\n",
    "    final=(np.where(dist_df['abs_diff']==np.min(dist_df['abs_diff']))[0])[0]\n",
    "    labelss=dist_df.index[0:final+1].to_list()\n",
    "    labels=pd.Series(kmeans.labels_).isin(labelss)\n",
    "    labels.index=X.index\n",
    "    close_index=labels.index[np.where(labels==False)[0]]\n",
    "    far_index=labels.index[np.where(labels==True)[0]]\n",
    "\n",
    "    X_train = X.loc[close_index,:]\n",
    "    X_test = X.loc[far_index,:]\n",
    "    y_train = y.loc[close_index]\n",
    "    y_test = y.loc[far_index]\n",
    "\n",
    "    # calculate the mean and covariance matrix of the dataset\n",
    "    mean_ = np.mean(X_train, axis=0)\n",
    "    cov_ = np.cov(X_train.T)\n",
    "    scaler_ = StandardScaler()\n",
    "\n",
    "    # transform data to compute the clusters\n",
    "    X_train_scaled = scaler_.fit_transform(X_train)\n",
    "\n",
    "    kmeans_ = KMeans(n_clusters=N_CLUSTERS, random_state=0, n_init=\"auto\").fit(X_train_scaled)\n",
    "    distances_=[]\n",
    "    counts_=[]\n",
    "    mahalanobis_dist_=[]\n",
    "    ideal_len_=len(kmeans_.labels_)/5\n",
    "    for i in np.arange(N_CLUSTERS):\n",
    "        distances_.append(np.abs(np.sum(kmeans_.labels_==i)-ideal_len_))\n",
    "        counts_.append(np.sum(kmeans_.labels_==i))\n",
    "        mean_k_= np.mean(X_train.loc[kmeans_.labels_==i,:], axis=0)\n",
    "        mahalanobis_dist_.append(mahalanobis(mean_k_, mean_, np.linalg.inv(cov_)))\n",
    "\n",
    "    dist_df_=pd.DataFrame(data={'mahalanobis_dist': mahalanobis_dist_, 'count': counts_}, index=np.arange(N_CLUSTERS))\n",
    "    dist_df_=dist_df_.sort_values('mahalanobis_dist', ascending=False)\n",
    "    dist_df_['cumulative_count']=dist_df_['count'].cumsum()\n",
    "    dist_df_['abs_diff']=np.abs(dist_df_['cumulative_count']-ideal_len_)\n",
    "\n",
    "    final_=(np.where(dist_df_['abs_diff']==np.min(dist_df_['abs_diff']))[0])[0]\n",
    "    labelss_=dist_df_.index[0:final_+1].to_list()\n",
    "    labels_=pd.Series(kmeans_.labels_).isin(labelss_)\n",
    "    labels_.index=X_train.index\n",
    "    close_index_=labels_.index[np.where(labels_==False)[0]]\n",
    "    far_index_=labels_.index[np.where(labels_==True)[0]]\n",
    "\n",
    "    X_train_ = X_train.loc[close_index_,:]\n",
    "    X_val = X_train.loc[far_index_,:]\n",
    "    y_train_ = y_train.loc[close_index_]\n",
    "    y_val = y_train.loc[far_index_]\n",
    "\n",
    "\n",
    "    # Standardize the data\n",
    "    mean_X_train_ = np.mean(X_train_, axis=0)\n",
    "    std_X_train_ = np.std(X_train_, axis=0)\n",
    "    X_train__scaled = (X_train_ - mean_X_train_) / std_X_train_\n",
    "    X_val_scaled = (X_val - mean_X_train_) / std_X_train_\n",
    "\n",
    "    mean_X_train = np.mean(X_train, axis=0)\n",
    "    std_X_train = np.std(X_train, axis=0)\n",
    "    X_train_scaled = (X_train - mean_X_train) / std_X_train\n",
    "    X_test_scaled = (X_test - mean_X_train) / std_X_train\n",
    "\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train__tensor = torch.tensor(X_train__scaled.values, dtype=torch.float32)\n",
    "    y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "    X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val_scaled.values, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Convert to use GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        X_train__tensor = X_train__tensor.cuda()\n",
    "        y_train__tensor = y_train__tensor.cuda()\n",
    "        X_train_tensor = X_train_tensor.cuda()\n",
    "        y_train_tensor = y_train_tensor.cuda()\n",
    "        X_val_tensor = X_val_tensor.cuda()\n",
    "        y_val_tensor = y_val_tensor.cuda()\n",
    "        X_test_tensor = X_test_tensor.cuda()\n",
    "        y_test_tensor = y_test_tensor.cuda()\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    # Create flattened versions of the data\n",
    "    y_val_np = y_val.values.flatten()\n",
    "    y_test_np = y_test.values.flatten()\n",
    "\n",
    "    # Create TensorDatasets for training and validation sets\n",
    "    train__dataset = TensorDataset(X_train__tensor, y_train__tensor)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # Create DataLoaders for training and validation sets\n",
    "    train__loader = DataLoader(train__dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Define d_out and d_in\n",
    "    d_out = 1  \n",
    "    d_in=X_train_.shape[1]\n",
    "\n",
    "    constant_prediction = np.array([np.mean(y_train)]*len(y_test))\n",
    "    RMSE_constant = np.sqrt(np.mean((y_test - constant_prediction) ** 2))\n",
    "\n",
    "    # Load the clustering results\n",
    "    results = pd.read_csv('RESULTS/CLUSTERING/'+str(task_id)+'_clustering_RMSE_results.csv')\n",
    "\n",
    "    # Update the value of the \"constant\" row with RMSE_constant\n",
    "    results['RMSE'][0] = RMSE_constant\n",
    "\n",
    "    # Save the updated clustering results\n",
    "    results.to_csv('RESULTS/CLUSTERING/'+str(task_id)+'_clustering_RMSE_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\905732815.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\905732815.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\905732815.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\905732815.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\905732815.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_35304\\905732815.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m X_umap \u001b[38;5;241m=\u001b[39m umap\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# calculate the Euclidean distance matrix\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m euclidean_dist_matrix \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_umap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# calculate the Euclidean distance for each data point\u001b[39;00m\n\u001b[0;32m     85\u001b[0m euclidean_dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(euclidean_dist_matrix, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:347\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    343\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m         )\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:385\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    383\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    384\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n\u001b[1;32m--> 385\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "# Specify the directory path\n",
    "directory = 'RESULTS/UMAP_DECOMPOSITION'\n",
    "\n",
    "# Get all the file names in the directory\n",
    "file_names = os.listdir(directory)\n",
    "\n",
    "# Extract the task IDs from the file names\n",
    "task_ids = [int(file_name.split('_')[0]) for file_name in file_names]\n",
    "\n",
    "for task_id in task_ids:\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "    \n",
    "    if len(X)>=100000:\n",
    "        continue\n",
    "    \n",
    "    # Find features with absolute correlation > 0.9\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "    # Drop one of the highly correlated features\n",
    "    X = X.drop(high_corr_features, axis=1)\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    N_TRIALS=100\n",
    "    N_SAMPLES=100\n",
    "    PATIENCE=40\n",
    "    N_EPOCHS=1000\n",
    "    GP_ITERATIONS=1000\n",
    "    BATCH_SIZE=1024\n",
    "    seed=10\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "    # Apply UMAP decomposition\n",
    "    umap = UMAP(n_components=2, random_state=42)\n",
    "    X_umap = umap.fit_transform(X)\n",
    "\n",
    "    # calculate the Euclidean distance matrix\n",
    "    euclidean_dist_matrix = euclidean_distances(X_umap)\n",
    "\n",
    "    # calculate the Euclidean distance for each data point\n",
    "    euclidean_dist = np.mean(euclidean_dist_matrix, axis=1)\n",
    "\n",
    "    euclidean_dist = pd.Series(euclidean_dist, index=X.index)\n",
    "    far_index = euclidean_dist.index[np.where(euclidean_dist >= np.quantile(euclidean_dist, 0.8))[0]]\n",
    "    close_index = euclidean_dist.index[np.where(euclidean_dist < np.quantile(euclidean_dist, 0.8))[0]]\n",
    "\n",
    "    X_train = X.loc[close_index,:]\n",
    "    X_test = X.loc[far_index,:]\n",
    "    y_train = y.loc[close_index]\n",
    "    y_test = y.loc[far_index]\n",
    "\n",
    "    # Apply UMAP decomposition on the training set\n",
    "    X_umap_train = umap.fit_transform(X_train)\n",
    "\n",
    "    # calculate the Euclidean distance matrix for the training set\n",
    "    euclidean_dist_matrix_train = euclidean_distances(X_umap_train)\n",
    "\n",
    "    # calculate the Euclidean distance for each data point in the training set\n",
    "    euclidean_dist_train = np.mean(euclidean_dist_matrix_train, axis=1)\n",
    "\n",
    "    euclidean_dist_train = pd.Series(euclidean_dist_train, index=X_train.index)\n",
    "    far_index_train = euclidean_dist_train.index[np.where(euclidean_dist_train >= np.quantile(euclidean_dist_train, 0.8))[0]]\n",
    "    close_index_train = euclidean_dist_train.index[np.where(euclidean_dist_train < np.quantile(euclidean_dist_train, 0.8))[0]]\n",
    "\n",
    "    X_train_ = X_train.loc[close_index_train,:]\n",
    "    X_val = X_train.loc[far_index_train,:]\n",
    "    y_train_ = y_train.loc[close_index_train]\n",
    "    y_val = y_train.loc[far_index_train]\n",
    "\n",
    "\n",
    "        # Standardize the data\n",
    "    mean_X_train_ = np.mean(X_train_, axis=0)\n",
    "    std_X_train_ = np.std(X_train_, axis=0)\n",
    "    X_train__scaled = (X_train_ - mean_X_train_) / std_X_train_\n",
    "    X_val_scaled = (X_val - mean_X_train_) / std_X_train_\n",
    "\n",
    "    mean_X_train = np.mean(X_train, axis=0)\n",
    "    std_X_train = np.std(X_train, axis=0)\n",
    "    X_train_scaled = (X_train - mean_X_train) / std_X_train\n",
    "    X_test_scaled = (X_test - mean_X_train) / std_X_train\n",
    "\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train__tensor = torch.tensor(X_train__scaled.values, dtype=torch.float32)\n",
    "    y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "    X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val_scaled.values, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Convert to use GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        X_train__tensor = X_train__tensor.cuda()\n",
    "        y_train__tensor = y_train__tensor.cuda()\n",
    "        X_train_tensor = X_train_tensor.cuda()\n",
    "        y_train_tensor = y_train_tensor.cuda()\n",
    "        X_val_tensor = X_val_tensor.cuda()\n",
    "        y_val_tensor = y_val_tensor.cuda()\n",
    "        X_test_tensor = X_test_tensor.cuda()\n",
    "        y_test_tensor = y_test_tensor.cuda()\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    # Create flattened versions of the data\n",
    "    y_val_np = y_val.values.flatten()\n",
    "    y_test_np = y_test.values.flatten()\n",
    "\n",
    "    # Create TensorDatasets for training and validation sets\n",
    "    train__dataset = TensorDataset(X_train__tensor, y_train__tensor)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # Create DataLoaders for training and validation sets\n",
    "    train__loader = DataLoader(train__dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Define d_out and d_in\n",
    "    d_out = 1  \n",
    "    d_in=X_train_.shape[1]\n",
    "\n",
    "    constant_prediction = np.array([np.mean(y_train)]*len(y_test))\n",
    "    RMSE_constant = np.sqrt(np.mean((y_test - constant_prediction) ** 2))\n",
    "\n",
    "    # Load the clustering results\n",
    "    results = pd.read_csv('RESULTS/UMAP_DECOMPOSITION/'+str(task_id)+'_umap_decomposition_RMSE_results.csv')\n",
    "\n",
    "    # Update the value of the \"constant\" row with RMSE_constant\n",
    "    results['RMSE'][0] = RMSE_constant\n",
    "\n",
    "    # Save the updated clustering results\n",
    "    results.to_csv('RESULTS/UMAP_DECOMPOSITION/'+str(task_id)+'_umap_decomposition_RMSE_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "# Specify the directory path\n",
    "directory = 'RESULTS/SPATIAL_DEPTH'\n",
    "\n",
    "# Get all the file names in the directory\n",
    "file_names = os.listdir(directory)\n",
    "\n",
    "# Extract the task IDs from the file names\n",
    "task_ids = [int(file_name.split('_')[0]) for file_name in file_names]\n",
    "\n",
    "for task_id in task_ids:\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "    \n",
    "    if len(X)>=100000:\n",
    "        continue\n",
    "    \n",
    "    # Find features with absolute correlation > 0.9\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "    # Drop one of the highly correlated features\n",
    "    X = X.drop(high_corr_features, axis=1)\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    N_TRIALS=100\n",
    "    N_SAMPLES=100\n",
    "    PATIENCE=40\n",
    "    N_EPOCHS=1000\n",
    "    GP_ITERATIONS=1000\n",
    "    BATCH_SIZE=1024\n",
    "    seed=10\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "    # activate pandas conversion for rpy2\n",
    "    pandas2ri.activate()\n",
    "\n",
    "    # import R's \"ddalpha\" package\n",
    "    ddalpha = importr('ddalpha')\n",
    "\n",
    "    # explicitly import the projDepth function\n",
    "    spatialDepth = robjects.r['depth.spatial']\n",
    "\n",
    "    # calculate the spatial depth for each data point\n",
    "    spatial_depth = spatialDepth(X, X)\n",
    "\n",
    "    spatial_depth=pd.Series(spatial_depth,index=X.index)\n",
    "    far_index=spatial_depth.index[np.where(spatial_depth<=np.quantile(spatial_depth,0.2))[0]]\n",
    "    close_index=spatial_depth.index[np.where(spatial_depth>np.quantile(spatial_depth,0.2))[0]]\n",
    "\n",
    "    X_train = X.loc[close_index,:]\n",
    "    X_test = X.loc[far_index,:]\n",
    "    y_train = y.loc[close_index]\n",
    "    y_test = y.loc[far_index]\n",
    "\n",
    "    # convert the R vector to a pandas Series\n",
    "    spatial_depth_ = spatialDepth(X_train, X_train)\n",
    "\n",
    "    spatial_depth_=pd.Series(spatial_depth_,index=X_train.index)\n",
    "    far_index_=spatial_depth_.index[np.where(spatial_depth_<=np.quantile(spatial_depth_,0.2))[0]]\n",
    "    close_index_=spatial_depth_.index[np.where(spatial_depth_>np.quantile(spatial_depth_,0.2))[0]]\n",
    "\n",
    "    X_train_ = X_train.loc[close_index_,:]\n",
    "    X_val = X_train.loc[far_index_,:]\n",
    "    y_train_ = y_train.loc[close_index_]\n",
    "    y_val = y_train.loc[far_index_]\n",
    "\n",
    "\n",
    "        # Standardize the data\n",
    "    mean_X_train_ = np.mean(X_train_, axis=0)\n",
    "    std_X_train_ = np.std(X_train_, axis=0)\n",
    "    X_train__scaled = (X_train_ - mean_X_train_) / std_X_train_\n",
    "    X_val_scaled = (X_val - mean_X_train_) / std_X_train_\n",
    "\n",
    "    mean_X_train = np.mean(X_train, axis=0)\n",
    "    std_X_train = np.std(X_train, axis=0)\n",
    "    X_train_scaled = (X_train - mean_X_train) / std_X_train\n",
    "    X_test_scaled = (X_test - mean_X_train) / std_X_train\n",
    "\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train__tensor = torch.tensor(X_train__scaled.values, dtype=torch.float32)\n",
    "    y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "    X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val_scaled.values, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Convert to use GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        X_train__tensor = X_train__tensor.cuda()\n",
    "        y_train__tensor = y_train__tensor.cuda()\n",
    "        X_train_tensor = X_train_tensor.cuda()\n",
    "        y_train_tensor = y_train_tensor.cuda()\n",
    "        X_val_tensor = X_val_tensor.cuda()\n",
    "        y_val_tensor = y_val_tensor.cuda()\n",
    "        X_test_tensor = X_test_tensor.cuda()\n",
    "        y_test_tensor = y_test_tensor.cuda()\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    # Create flattened versions of the data\n",
    "    y_val_np = y_val.values.flatten()\n",
    "    y_test_np = y_test.values.flatten()\n",
    "\n",
    "    # Create TensorDatasets for training and validation sets\n",
    "    train__dataset = TensorDataset(X_train__tensor, y_train__tensor)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # Create DataLoaders for training and validation sets\n",
    "    train__loader = DataLoader(train__dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Define d_out and d_in\n",
    "    d_out = 1  \n",
    "    d_in=X_train_.shape[1]\n",
    "\n",
    "    constant_prediction = np.array([np.mean(y_train)]*len(y_test))\n",
    "    RMSE_constant = np.sqrt(np.mean((y_test - constant_prediction) ** 2))\n",
    "\n",
    "    # Load the clustering results\n",
    "    results = pd.read_csv('RESULTS/SPATIAL_DEPTH/'+str(task_id)+'_spatial_depth_RMSE_results.csv')\n",
    "\n",
    "    # Update the value of the \"constant\" row with RMSE_constant\n",
    "    results['RMSE'][0] = RMSE_constant\n",
    "\n",
    "    # Save the updated clustering results\n",
    "    results.to_csv('RESULTS/SPATIAL_DEPTH/'+str(task_id)+'_spatial_depth_RMSE_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 361072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Task 361280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_30140\\2541933432.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RMSE'][0] = RMSE_constant\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "# Specify the directory path\n",
    "directory = 'RESULTS/MAHALANOBIS'\n",
    "\n",
    "# Get all the file names in the directory\n",
    "file_names = os.listdir(directory)\n",
    "\n",
    "# Extract the task IDs from the file names\n",
    "task_ids = [int(file_name.split('_')[0]) for file_name in file_names]\n",
    "\n",
    "for task_id in task_ids:\n",
    "\n",
    "    print(f\"Task {task_id}\")\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "    \n",
    "    if len(X)>=100000:\n",
    "        continue\n",
    "    \n",
    "    # Find features with absolute correlation > 0.9\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "    # Drop one of the highly correlated features\n",
    "    X = X.drop(high_corr_features, axis=1)\n",
    "\n",
    "    # Set the random seed for reproducibility\n",
    "    N_TRIALS=100\n",
    "    N_SAMPLES=100\n",
    "    PATIENCE=40\n",
    "    N_EPOCHS=1000\n",
    "    GP_ITERATIONS=1000\n",
    "    BATCH_SIZE=1024\n",
    "    seed=10\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "    # calculate the mean and covariance matrix of the dataset\n",
    "    mean = np.mean(X, axis=0)\n",
    "    cov = np.cov(X.T)\n",
    "\n",
    "    # calculate the Mahalanobis distance for each data point\n",
    "    mahalanobis_dist = [mahalanobis(x, mean, np.linalg.inv(cov)) for x in X.values]\n",
    "\n",
    "    mahalanobis_dist=pd.Series(mahalanobis_dist,index=X.index)\n",
    "    far_index=mahalanobis_dist.index[np.where(mahalanobis_dist>=np.quantile(mahalanobis_dist,0.8))[0]]\n",
    "    close_index=mahalanobis_dist.index[np.where(mahalanobis_dist<np.quantile(mahalanobis_dist,0.8))[0]]\n",
    "\n",
    "    X_train = X.loc[close_index,:]\n",
    "    X_test = X.loc[far_index,:]\n",
    "    y_train = y.loc[close_index]\n",
    "    y_test = y.loc[far_index]\n",
    "\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    cov = np.cov(X_train.T)\n",
    "\n",
    "    # calculate the Mahalanobis distance for each data point\n",
    "    mahalanobis_dist_ = [mahalanobis(x, mean, np.linalg.inv(cov)) for x in X_train.values]\n",
    "\n",
    "    mahalanobis_dist_=pd.Series(mahalanobis_dist_,index=X_train.index)\n",
    "    far_index_=mahalanobis_dist_.index[np.where(mahalanobis_dist_>=np.quantile(mahalanobis_dist_,0.8))[0]]\n",
    "    close_index_=mahalanobis_dist_.index[np.where(mahalanobis_dist_<np.quantile(mahalanobis_dist_,0.8))[0]]\n",
    "\n",
    "    X_train_ = X_train.loc[close_index_,:]\n",
    "    X_val = X_train.loc[far_index_,:]\n",
    "    y_train_ = y_train.loc[close_index_]\n",
    "    y_val = y_train.loc[far_index_]\n",
    "\n",
    "    # Standardize the data\n",
    "    mean_X_train_ = np.mean(X_train_, axis=0)\n",
    "    std_X_train_ = np.std(X_train_, axis=0)\n",
    "    X_train__scaled = (X_train_ - mean_X_train_) / std_X_train_\n",
    "    X_val_scaled = (X_val - mean_X_train_) / std_X_train_\n",
    "\n",
    "    mean_X_train = np.mean(X_train, axis=0)\n",
    "    std_X_train = np.std(X_train, axis=0)\n",
    "    X_train_scaled = (X_train - mean_X_train) / std_X_train\n",
    "    X_test_scaled = (X_test - mean_X_train) / std_X_train\n",
    "\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train__tensor = torch.tensor(X_train__scaled.values, dtype=torch.float32)\n",
    "    y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "    X_train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val_scaled.values, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Convert to use GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        X_train__tensor = X_train__tensor.cuda()\n",
    "        y_train__tensor = y_train__tensor.cuda()\n",
    "        X_train_tensor = X_train_tensor.cuda()\n",
    "        y_train_tensor = y_train_tensor.cuda()\n",
    "        X_val_tensor = X_val_tensor.cuda()\n",
    "        y_val_tensor = y_val_tensor.cuda()\n",
    "        X_test_tensor = X_test_tensor.cuda()\n",
    "        y_test_tensor = y_test_tensor.cuda()\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    # Create flattened versions of the data\n",
    "    y_val_np = y_val.values.flatten()\n",
    "    y_test_np = y_test.values.flatten()\n",
    "\n",
    "    # Create TensorDatasets for training and validation sets\n",
    "    train__dataset = TensorDataset(X_train__tensor, y_train__tensor)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # Create DataLoaders for training and validation sets\n",
    "    train__loader = DataLoader(train__dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Define d_out and d_in\n",
    "    d_out = 1  \n",
    "    d_in=X_train_.shape[1]\n",
    "\n",
    "    constant_prediction = np.array([np.mean(y_train)]*len(y_test))\n",
    "    RMSE_constant = np.sqrt(np.mean((y_test - constant_prediction) ** 2))\n",
    "\n",
    "    # Load the clustering results\n",
    "    results = pd.read_csv('RESULTS/MAHALANOBIS/'+str(task_id)+'_mahalanobis_RMSE_results.csv')\n",
    "\n",
    "    # Update the value of the \"constant\" row with RMSE_constant\n",
    "    results['RMSE'][0] = RMSE_constant\n",
    "\n",
    "    # Save the updated clustering results\n",
    "    results.to_csv('RESULTS/MAHALANOBIS/'+str(task_id)+'_mahalanobis_RMSE_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
