{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "[I 2024-02-20 17:25:27,801] A new study created in memory with name: no-name-f102c980-3a5b-4376-9fbd-645716f7c368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89ef8dca1d640948ee53df6519589aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:25:38,486] Trial 0 finished with value: 61.8878542160432 and parameters: {'n_blocks': 4, 'd_block': 20, 'dropout': 0.6336482349262754, 'learning_rate': 0.010495405390719734, 'weight_decay': 3.1083868392602017e-06, 'n_epochs': 43}. Best is trial 0 with value: 61.8878542160432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c471d9762d4b35923cbb7f4ed4fe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:26:56,364] Trial 1 finished with value: 367.74707685166317 and parameters: {'n_blocks': 2, 'd_block': 107, 'dropout': 0.7605307121989587, 'learning_rate': 0.0002860388842288948, 'weight_decay': 2.765025054332623e-08, 'n_epochs': 563}. Best is trial 0 with value: 61.8878542160432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72f7846a99744dca5c317867c0d21cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:28:12,094] Trial 2 finished with value: 10.012117630178597 and parameters: {'n_blocks': 4, 'd_block': 478, 'dropout': 0.003948266327914451, 'learning_rate': 0.002412079153798176, 'weight_decay': 0.00011563912803570738, 'n_epochs': 156}. Best is trial 2 with value: 10.012117630178597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e368ae0499d45788d364d2a00b8dcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:28:37,723] Trial 3 finished with value: 687.1707511457577 and parameters: {'n_blocks': 4, 'd_block': 364, 'dropout': 0.29187606817063316, 'learning_rate': 0.029994721053560828, 'weight_decay': 3.7400629930578146e-05, 'n_epochs': 48}. Best is trial 2 with value: 10.012117630178597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e45c96e7ef4c0db656a9688196db0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:28:53,694] Trial 4 finished with value: 34.32406426910931 and parameters: {'n_blocks': 3, 'd_block': 79, 'dropout': 0.3733407600514692, 'learning_rate': 0.006598821883612051, 'weight_decay': 1.618698156523955e-06, 'n_epochs': 77}. Best is trial 2 with value: 10.012117630178597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ae3fe6453c4c00b7502dbc26930e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:29:29,798] Trial 5 finished with value: 34.30768456132583 and parameters: {'n_blocks': 3, 'd_block': 313, 'dropout': 0.5131382425543909, 'learning_rate': 0.005693803629695728, 'weight_decay': 1.0120332166548561e-05, 'n_epochs': 125}. Best is trial 2 with value: 10.012117630178597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c244c234494e411f8a767c76ece7748a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:34:01,958] Trial 6 finished with value: 656.4224662058078 and parameters: {'n_blocks': 5, 'd_block': 266, 'dropout': 0.9086488808086682, 'learning_rate': 0.0007271242493848924, 'weight_decay': 2.8333273009960152e-08, 'n_epochs': 623}. Best is trial 2 with value: 10.012117630178597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeb9fe8cb4243f1bf7cdf38b83a0d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:36:09,539] Trial 7 finished with value: 815.261944553728 and parameters: {'n_blocks': 2, 'd_block': 65, 'dropout': 0.8286813263076767, 'learning_rate': 0.00013383563361780206, 'weight_decay': 1.3534298216580227e-05, 'n_epochs': 714}. Best is trial 2 with value: 10.012117630178597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903bef6ee3de4490a1129be826def760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:36:25,372] Trial 8 finished with value: 9136.531093068048 and parameters: {'n_blocks': 3, 'd_block': 412, 'dropout': 0.1989475396788123, 'learning_rate': 0.020540606581753273, 'weight_decay': 5.731432699830849e-07, 'n_epochs': 3}. Best is trial 2 with value: 10.012117630178597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f5036bc66b4e89b3704f39825f1532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-20 17:37:42,874] Trial 9 finished with value: 1190.8960749744613 and parameters: {'n_blocks': 4, 'd_block': 155, 'dropout': 0.8839364795611863, 'learning_rate': 0.0007560423904195248, 'weight_decay': 6.684662552536899e-08, 'n_epochs': 282}. Best is trial 2 with value: 10.012117630178597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efba76b469b146eb8add5c537776b93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS MLP:  11.790757381123871\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import lightgbmlss\n",
    "import optuna\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from drf import drf\n",
    "import os\n",
    "from pygam import LinearGAM, s, f\n",
    "from utils import EarlyStopping, train, train_trans, train_no_early_stopping, train_trans_no_early_stopping, train_GP, ExactGPModel\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "task_id=361072\n",
    "task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "dataset = task.get_dataset()\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "N_TRIALS=10\n",
    "N_SAMPLES=100\n",
    "PATIENCE=40\n",
    "N_EPOCHS=1000\n",
    "GP_ITERATIONS=1000\n",
    "BATCH_SIZE=1024\n",
    "seed=10\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "# calculate the mean and covariance matrix of the dataset\n",
    "mean = np.mean(X, axis=0)\n",
    "cov = np.cov(X.T)\n",
    "\n",
    "# calculate the Mahalanobis distance for each data point\n",
    "mahalanobis_dist = [mahalanobis(x, mean, np.linalg.inv(cov)) for x in X.values]\n",
    "\n",
    "mahalanobis_dist=pd.Series(mahalanobis_dist,index=X.index)\n",
    "far_index=mahalanobis_dist.index[np.where(mahalanobis_dist>=np.quantile(mahalanobis_dist,0.8))[0]]\n",
    "close_index=mahalanobis_dist.index[np.where(mahalanobis_dist<np.quantile(mahalanobis_dist,0.8))[0]]\n",
    "\n",
    "X_train = X.loc[close_index,:]\n",
    "X_test = X.loc[far_index,:]\n",
    "y_train = y.loc[close_index]\n",
    "y_test = y.loc[far_index]\n",
    "\n",
    "mean = np.mean(X_train, axis=0)\n",
    "cov = np.cov(X_train.T)\n",
    "\n",
    "# calculate the Mahalanobis distance for each data point\n",
    "mahalanobis_dist_ = [mahalanobis(x, mean, np.linalg.inv(cov)) for x in X_train.values]\n",
    "\n",
    "mahalanobis_dist_=pd.Series(mahalanobis_dist_,index=X_train.index)\n",
    "far_index_=mahalanobis_dist_.index[np.where(mahalanobis_dist_>=np.quantile(mahalanobis_dist_,0.8))[0]]\n",
    "close_index_=mahalanobis_dist_.index[np.where(mahalanobis_dist_<np.quantile(mahalanobis_dist_,0.8))[0]]\n",
    "\n",
    "X_train_ = X_train.loc[close_index_,:]\n",
    "X_val = X_train.loc[far_index_,:]\n",
    "y_train_ = y_train.loc[close_index_]\n",
    "y_val = y_train.loc[far_index_]\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train__tensor = torch.tensor(X_train_.values, dtype=torch.float32)\n",
    "y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Convert to use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    X_train__tensor = X_train__tensor.cuda()\n",
    "    y_train__tensor = y_train__tensor.cuda()\n",
    "    X_train_tensor = X_train_tensor.cuda()\n",
    "    y_train_tensor = y_train_tensor.cuda()\n",
    "    X_val_tensor = X_val_tensor.cuda()\n",
    "    y_val_tensor = y_val_tensor.cuda()\n",
    "    X_test_tensor = X_test_tensor.cuda()\n",
    "    y_test_tensor = y_test_tensor.cuda()\n",
    "\n",
    "# Create flattened versions of the data\n",
    "y_val_np = y_val.values.flatten()\n",
    "y_test_np = y_test.values.flatten()\n",
    "\n",
    "# Create TensorDatasets for training and validation sets\n",
    "train__dataset = TensorDataset(X_train__tensor, y_train__tensor)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders for training and validation sets\n",
    "train__loader = DataLoader(train__dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# #### MLP\n",
    "d_out = 1  \n",
    "d_in=X_train_.shape[1]\n",
    "\n",
    "def MLP_opt(trial):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    n_blocks = trial.suggest_int(\"n_blocks\", 1, 5)\n",
    "    d_block = trial.suggest_int(\"d_block\", 10, 500)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 1)\n",
    "\n",
    "    MLP_model = MLP(\n",
    "    d_in=d_in,\n",
    "    d_out=d_out,\n",
    "    n_blocks=n_blocks,\n",
    "    d_block=d_block,\n",
    "    dropout=dropout,\n",
    "    )\n",
    "    n_epochs=N_EPOCHS\n",
    "    learning_rate=trial.suggest_float('learning_rate', 0.0001, 0.05, log=True)\n",
    "    weight_decay=trial.suggest_float('weight_decay', 1e-8, 1e-3, log=True)\n",
    "    optimizer=torch.optim.Adam(MLP_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        MLP_model = MLP_model.cuda()\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=PATIENCE, verbose=False)\n",
    "    n_epochs=train(MLP_model, criterion, optimizer, n_epochs, train__loader, val_loader, early_stopping)\n",
    "    n_epochs = trial.suggest_int('n_epochs', n_epochs, n_epochs)\n",
    "\n",
    "    # Point prediction\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, _ in val_loader:\n",
    "            batch_predictions = MLP_model(batch_X).reshape(-1,)\n",
    "            predictions.append(batch_predictions.cpu().numpy())\n",
    "\n",
    "    y_val_hat_MLP = np.concatenate(predictions)\n",
    "\n",
    "    # Estimate standard deviation of the prediction error\n",
    "    std_dev_error = np.std(y_val - y_val_hat_MLP)\n",
    "\n",
    "    # Calculate the CRPS for each prediction\n",
    "    crps_values = [crps_gaussian(y_val_np[i], mu=y_val_hat_MLP[i], sig=std_dev_error) for i in range(len(y_val_hat_MLP))]\n",
    "\n",
    "    # Calculate the mean CRPS\n",
    "    mean_crps = np.mean(crps_values)\n",
    "\n",
    "    return mean_crps\n",
    "\n",
    "sampler_MLP = optuna.samplers.TPESampler(seed=seed)\n",
    "study_MLP = optuna.create_study(sampler=sampler_MLP, direction='minimize')\n",
    "study_MLP.optimize(MLP_opt, n_trials=N_TRIALS)\n",
    "\n",
    "MLP_model = MLP(\n",
    "    d_in=d_in,\n",
    "    d_out=d_out,\n",
    "    n_blocks=study_MLP.best_params['n_blocks'],\n",
    "    d_block=study_MLP.best_params['d_block'],\n",
    "    dropout=study_MLP.best_params['dropout'],\n",
    "    )\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    MLP_model = MLP_model.cuda()\n",
    "    \n",
    "n_epochs=study_MLP.best_params['n_epochs']\n",
    "learning_rate=study_MLP.best_params['learning_rate']\n",
    "weight_decay=study_MLP.best_params['weight_decay']\n",
    "optimizer=torch.optim.Adam(MLP_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_no_early_stopping(MLP_model, criterion, optimizer, n_epochs, train_loader)\n",
    "\n",
    "# Point prediction\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, _ in test_loader:\n",
    "        batch_predictions = MLP_model(batch_X).reshape(-1,)\n",
    "        predictions.append(batch_predictions.cpu().numpy())\n",
    "\n",
    "y_test_hat_MLP = np.concatenate(predictions)\n",
    "\n",
    "# Estimate standard deviation of the prediction error\n",
    "std_dev_error = np.std(y_test - y_test_hat_MLP)\n",
    "\n",
    "# Create a normal distribution for each prediction\n",
    "pred_distributions = [norm(loc=y_test_hat_MLP[i], scale=std_dev_error) for i in range(len(y_test_hat_MLP))]\n",
    "\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_gaussian(y_test_np[i], mu=y_test_hat_MLP[i], sig=std_dev_error) for i in range(len(y_test_hat_MLP))]\n",
    "\n",
    "# Calculate the mean CRPS\n",
    "crps_MLP = np.mean(crps_values)\n",
    "\n",
    "print(\"CRPS MLP: \", crps_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
