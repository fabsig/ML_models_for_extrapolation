{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setuptools\n",
    "import openml\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm\n",
    "import lightgbmlss\n",
    "import optuna\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from engression import engression, engression_bagged\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "from properscoring import crps_gaussian, crps_ensemble\n",
    "import random\n",
    "import gpytorch\n",
    "import tqdm.auto as tqdm\n",
    "from lightgbmlss.model import *\n",
    "from lightgbmlss.distributions.Gaussian import *\n",
    "from drf import drf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install setuptools\n",
    "# pip install openml\n",
    "# pip install lightgbm\n",
    "# pip install optuna\n",
    "# pip install engression\n",
    "\n",
    "\n",
    "# numpy-1.26.3 pandas-2.1.4 setuptools-69.0.3 openml lightgbm-4.2.0  optuna-3.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    }
   ],
   "source": [
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "\n",
    "task_id=361072\n",
    "task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "dataset = task.get_dataset()\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192, 21)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361072  shape:  (8192, 21)\n",
      "task:  361073  shape:  (15000, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361074  shape:  (16599, 16)\n",
      "task:  361076  shape:  (6497, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361077  shape:  (13750, 33)\n",
      "task:  361078  shape:  (20640, 8)\n",
      "task:  361079  shape:  (22784, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361080  shape:  (53940, 6)\n",
      "task:  361081  shape:  (10692, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361082  shape:  (17379, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361083  shape:  (581835, 9)\n",
      "task:  361084  shape:  (21613, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361085  shape:  (10081, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361086  shape:  (163065, 3)\n",
      "task:  361087  shape:  (13932, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361088  shape:  (21263, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361279  shape:  (8885, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361280  shape:  (4177, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:  361281  shape:  (5465575, 8)\n"
     ]
    }
   ],
   "source": [
    "for task_id in benchmark_suite.tasks:\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "            dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
    "    \n",
    "    print('task: ', task_id, ' shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(benchmark_suite.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New new implementation\n",
    "N_CLUSTERS=20\n",
    "# calculate the mean and covariance matrix of the dataset\n",
    "mean = np.mean(X, axis=0)\n",
    "cov = np.cov(X.T)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# transform data to compute the clusters\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=0, n_init=\"auto\").fit(X_scaled)\n",
    "distances=[]\n",
    "mahalanobis_dist=[]\n",
    "counts=[]\n",
    "ideal_len=len(kmeans.labels_)/5\n",
    "for i in np.arange(N_CLUSTERS):\n",
    "    distances.append(np.abs(np.sum(kmeans.labels_==i)-ideal_len))\n",
    "    counts.append(np.sum(kmeans.labels_==i))\n",
    "    mean_k= np.mean(X.loc[kmeans.labels_==i,:], axis=0)\n",
    "    mahalanobis_dist.append(mahalanobis(mean_k, mean, np.linalg.inv(cov)))\n",
    "\n",
    "dist_df=pd.DataFrame(data={'mahalanobis_dist': mahalanobis_dist, 'count': counts}, index=np.arange(N_CLUSTERS))\n",
    "dist_df=dist_df.sort_values('mahalanobis_dist', ascending=False)\n",
    "dist_df['cumulative_count']=dist_df['count'].cumsum()\n",
    "dist_df['abs_diff']=np.abs(dist_df['cumulative_count']-ideal_len)\n",
    "\n",
    "final=(np.where(dist_df['abs_diff']==np.min(dist_df['abs_diff']))[0])[0]\n",
    "labelss=dist_df.index[0:final+1].to_list()\n",
    "labels=pd.Series(kmeans.labels_).isin(labelss)\n",
    "labels.index=X.index\n",
    "close_index=labels.index[np.where(labels==False)[0]]\n",
    "far_index=labels.index[np.where(labels==True)[0]]\n",
    "\n",
    "X_train = X.loc[close_index,:]\n",
    "X_test = X.loc[far_index,:]\n",
    "y_train = y.loc[close_index]\n",
    "y_test = y.loc[far_index]\n",
    "\n",
    "# calculate the mean and covariance matrix of the dataset\n",
    "mean_ = np.mean(X_train, axis=0)\n",
    "cov_ = np.cov(X_train.T)\n",
    "scaler_ = StandardScaler()\n",
    "\n",
    "# transform data to compute the clusters\n",
    "X_train_scaled = scaler_.fit_transform(X_train)\n",
    "\n",
    "kmeans_ = KMeans(n_clusters=N_CLUSTERS, random_state=0, n_init=\"auto\").fit(X_train_scaled)\n",
    "distances_=[]\n",
    "counts_=[]\n",
    "mahalanobis_dist_=[]\n",
    "ideal_len_=len(kmeans_.labels_)/5\n",
    "for i in np.arange(N_CLUSTERS):\n",
    "    distances_.append(np.abs(np.sum(kmeans_.labels_==i)-ideal_len_))\n",
    "    counts_.append(np.sum(kmeans_.labels_==i))\n",
    "    mean_k_= np.mean(X_train.loc[kmeans_.labels_==i,:], axis=0)\n",
    "    mahalanobis_dist_.append(mahalanobis(mean_k_, mean_, np.linalg.inv(cov_)))\n",
    "\n",
    "dist_df_=pd.DataFrame(data={'mahalanobis_dist': mahalanobis_dist_, 'count': counts_}, index=np.arange(N_CLUSTERS))\n",
    "dist_df_=dist_df_.sort_values('mahalanobis_dist', ascending=False)\n",
    "dist_df_['cumulative_count']=dist_df_['count'].cumsum()\n",
    "dist_df_['abs_diff']=np.abs(dist_df_['cumulative_count']-ideal_len_)\n",
    "\n",
    "final_=(np.where(dist_df_['abs_diff']==np.min(dist_df_['abs_diff']))[0])[0]\n",
    "labelss_=dist_df_.index[0:final_+1].to_list()\n",
    "labels_=pd.Series(kmeans_.labels_).isin(labelss_)\n",
    "labels_.index=X_train.index\n",
    "close_index_=labels_.index[np.where(labels_==False)[0]]\n",
    "far_index_=labels_.index[np.where(labels_==True)[0]]\n",
    "\n",
    "X_train_ = X_train.loc[close_index_,:]\n",
    "X_val = X_train.loc[far_index_,:]\n",
    "y_train_ = y_train.loc[close_index_]\n",
    "y_val = y_train.loc[far_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train__tensor = torch.tensor(X_train_.values, dtype=torch.float32)\n",
    "y_train__tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Convert to use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    X_train__tensor = X_train__tensor.cuda()\n",
    "    y_train__tensor = y_train__tensor.cuda()\n",
    "    X_train_tensor = X_train_tensor.cuda()\n",
    "    y_train_tensor = y_train_tensor.cuda()\n",
    "    X_val_tensor = X_val_tensor.cuda()\n",
    "    y_val_tensor = y_val_tensor.cuda()\n",
    "    X_test_tensor = X_test_tensor.cuda()\n",
    "    y_test_tensor = y_test_tensor.cuda()\n",
    "\n",
    "# Create flattened versions of the data\n",
    "y_val_np = y_val.values.flatten()\n",
    "y_test_np = y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499be6ebc4fa4c529fdf808b9ac1201d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f12ff6af97a4c829902a9f1ff040f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce9cb4a76b34bcd8f633c0572fcdafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa60193cd52c4860a09d770ae2feec6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "seed=10\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Define the learning params\n",
    "training_iterations = 1000\n",
    "\n",
    "# Define the kernels\n",
    "kernels = [\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=0.5, ard_num_dims=X_train_.shape[1])),\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=X_train_.shape[1])),\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=X_train_.shape[1])),\n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=X_train_.shape[1])),\n",
    "]\n",
    "\n",
    "best_crps = float('inf')\n",
    "best_kernel = None\n",
    "\n",
    "def train(model,X_train_tensor,y_train_tensor):\n",
    "    iterator = tqdm.tqdm(range(training_iterations), desc=\"Train\")\n",
    "\n",
    "    for _ in iterator:\n",
    "        # Zero backprop gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Get output from model\n",
    "        output = model(X_train_tensor)\n",
    "        # Calc loss and backprop derivatives\n",
    "        loss = -mll(output, y_train_tensor)\n",
    "        loss.backward()\n",
    "        iterator.set_postfix(loss=loss.item())\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "for kernel in kernels:\n",
    "    # Initialize the Gaussian Process model and likelihood\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(X_train_tensor, y_train_tensor, likelihood, kernel)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    # Train the model\n",
    "    train(model,X_train__tensor,y_train__tensor)\n",
    "    \n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        y_pred = model(X_val_tensor)\n",
    "\n",
    "    # Calculate CRPS\n",
    "    y_pred_np = y_pred.mean.numpy().flatten()\n",
    "    y_pred_std_np = y_pred.stddev.numpy().flatten()\n",
    "\n",
    "    # Calculate the CRPS for each prediction\n",
    "    crps_values = [crps_gaussian(y_val_np[i], mu=y_pred_np[i], sig=y_pred_std_np[i]) for i in range(len(y_val_np))]\n",
    "\n",
    "    # Calculate the mean CRPS\n",
    "    mean_crps = np.mean(crps_values)\n",
    "\n",
    "    # Update the best kernel if the current kernel has a lower CRPS\n",
    "    if mean_crps < best_crps:\n",
    "        best_crps = mean_crps\n",
    "        best_kernel = kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d8c9f5a8ce49bf9ae37bde16f2d14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS_GP:  59.16435169591171\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "seed=10\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = best_kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Define the learning params\n",
    "training_iterations = 1000\n",
    "\n",
    "# Initialize the Gaussian Process model and likelihood\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(X_train_tensor, y_train_tensor, likelihood)\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    likelihood = likelihood.cuda()\n",
    "    mll = mll.cuda()\n",
    "    kernel = kernel.cuda()\n",
    "\n",
    "# Train the model\n",
    "train(model,X_train_tensor,y_train_tensor)\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Make predictions on the validation set\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    y_pred = model(X_test_tensor)\n",
    "\n",
    "# Calculate CRPS\n",
    "y_pred_np = y_pred.mean.numpy().flatten()\n",
    "y_pred_std_np = y_pred.stddev.numpy().flatten()\n",
    "\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_gaussian(y_test_np[i], mu=y_pred_np[i], sig=y_pred_std_np[i]) for i in range(len(y_test_np))]\n",
    "\n",
    "# Calculate the mean CRPS\n",
    "CRPS_GP = np.mean(crps_values)\n",
    "\n",
    "# Update the best kernel if the current kernel has a lower CRPS\n",
    "print('CRPS_GP: ', CRPS_GP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,criterion,loss_Adam,optimizer,training_iterations,X_train_tensor,y_train_tensor):\n",
    "    iterator = tqdm.tqdm(range(training_iterations), desc=\"Train\")\n",
    "\n",
    "    for _ in iterator:\n",
    "        # making a pridiction in forward pass\n",
    "        y_train_hat = model(X_train_tensor).reshape(-1,)\n",
    "        # calculating the loss between original and predicted data points\n",
    "        loss = criterion(y_train_hat, torch.Tensor(y_train_tensor))\n",
    "        # store loss into list\n",
    "        loss_Adam.append(loss.item())\n",
    "        # zeroing gradients after each iteration\n",
    "        optimizer.zero_grad()\n",
    "        # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
    "        loss.backward()\n",
    "        # updating the parameters after each iteration\n",
    "        optimizer.step()\n",
    "        iterator.set_postfix(loss=loss.item())\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:48:28,809] A new study created in memory with name: no-name-ba6b04ff-f31c-476f-8822-5a2fd68c0d23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917b039e40e84f819e32521fc627fe52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/3769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:49:03,277] Trial 0 finished with value: 51.87233409758446 and parameters: {'n_blocks': 4, 'd_block': 20, 'dropout': 0.6336482349262754, 'n_epochs': 3769, 'learning_rate': 0.002215416944953109, 'weight_decay': 1.33040303714882e-07}. Best is trial 0 with value: 51.87233409758446.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88580129d42b4a85abe30e796766f715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:49:16,100] Trial 1 finished with value: 855.2130560594854 and parameters: {'n_blocks': 1, 'd_block': 383, 'dropout': 0.16911083656253545, 'n_epochs': 532, 'learning_rate': 0.007075637776590665, 'weight_decay': 0.0005847452881552242}. Best is trial 0 with value: 51.87233409758446.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0e774ea83b4f478a48351ed132c6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/3101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:50:06,488] Trial 2 finished with value: 790.857583782651 and parameters: {'n_blocks': 1, 'd_block': 261, 'dropout': 0.8126209616521135, 'n_epochs': 3101, 'learning_rate': 0.008871477434617912, 'weight_decay': 2.879919449586155e-07}. Best is trial 0 with value: 51.87233409758446.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2b73f2e421438dac15f51fab2b4c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/796 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:53:09,235] Trial 3 finished with value: 65.94627040143702 and parameters: {'n_blocks': 5, 'd_block': 360, 'dropout': 0.5425443680112613, 'n_epochs': 796, 'learning_rate': 0.0010177368807699995, 'weight_decay': 2.3478377182859888e-05}. Best is trial 0 with value: 51.87233409758446.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412e9ea0f3c74b5c980430121944c722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/2614 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:56:03,058] Trial 4 finished with value: 52.314464085940614 and parameters: {'n_blocks': 3, 'd_block': 223, 'dropout': 0.6177669784693172, 'n_epochs': 2614, 'learning_rate': 0.005693803629695728, 'weight_decay': 1.0120332166548561e-05}. Best is trial 0 with value: 51.87233409758446.\n"
     ]
    }
   ],
   "source": [
    "N_TRIALS=5\n",
    "\n",
    "d_out = 1  \n",
    "d_in=X_train_.shape[1]\n",
    "\n",
    "def MLP_opt(trial):\n",
    "\n",
    "    seed=10\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    n_blocks = trial.suggest_int(\"n_blocks\", 1, 5)\n",
    "    d_block = trial.suggest_int(\"d_block\", 10, 500)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 1)\n",
    "\n",
    "    MLP_model = MLP(\n",
    "    d_in=d_in,\n",
    "    d_out=d_out,\n",
    "    n_blocks=n_blocks,\n",
    "    d_block=d_block,\n",
    "    dropout=dropout,\n",
    "    )\n",
    "    n_epochs=trial.suggest_int('n_epochs', 100, 5000)\n",
    "    learning_rate=trial.suggest_float('learning_rate', 0.0001, 0.05, log=True)\n",
    "    weight_decay=trial.suggest_float('weight_decay', 1e-8, 1e-3, log=True)\n",
    "    optimizer=torch.optim.Adam(MLP_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    loss_Adam=[]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        MLP_model = MLP_model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "    \n",
    "    train(MLP_model,criterion,loss_Adam,optimizer,n_epochs,X_train__tensor,y_train__tensor)\n",
    "\n",
    "    # Point prediction\n",
    "    y_val_hat_MLP = (MLP_model(X_val_tensor).reshape(-1,)).detach().numpy()\n",
    "\n",
    "    # Estimate standard deviation of the prediction error\n",
    "    std_dev_error = np.std(y_val - y_val_hat_MLP)\n",
    "\n",
    "    # Calculate the CRPS for each prediction\n",
    "    crps_values = [crps_gaussian(y_val_np[i], mu=y_val_hat_MLP[i], sig=std_dev_error) for i in range(len(y_val_hat_MLP))]\n",
    "\n",
    "    # Calculate the mean CRPS\n",
    "    mean_crps = np.mean(crps_values)\n",
    "\n",
    "    return mean_crps\n",
    "\n",
    "sampler_MLP = optuna.samplers.TPESampler(seed=10)\n",
    "study_MLP = optuna.create_study(sampler=sampler_MLP, direction='minimize')\n",
    "study_MLP.optimize(MLP_opt, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42107f50c1e140ee9f1f2e06c2aca13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/3769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS MLP:  48.76351590288167\n"
     ]
    }
   ],
   "source": [
    "seed=10\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "MLP_model = MLP(\n",
    "    d_in=d_in,\n",
    "    d_out=d_out,\n",
    "    n_blocks=study_MLP.best_params['n_blocks'],\n",
    "    d_block=study_MLP.best_params['d_block'],\n",
    "    dropout=study_MLP.best_params['dropout'],\n",
    "    )\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    MLP_model = MLP_model.cuda()\n",
    "    \n",
    "n_epochs=study_MLP.best_params['n_epochs']\n",
    "learning_rate=study_MLP.best_params['learning_rate']\n",
    "weight_decay=study_MLP.best_params['weight_decay']\n",
    "optimizer=torch.optim.Adam(MLP_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n",
    "loss_Adam=[]\n",
    "\n",
    "train(MLP_model,criterion,loss_Adam,optimizer,n_epochs,X_train_tensor,y_train_tensor)\n",
    "\n",
    "# Point prediction\n",
    "y_test_hat_MLP = (MLP_model(X_test_tensor).reshape(-1,)).detach().numpy()\n",
    "\n",
    "# Estimate standard deviation of the prediction error\n",
    "std_dev_error = np.std(y_test - y_test_hat_MLP)\n",
    "\n",
    "# Create a normal distribution for each prediction\n",
    "pred_distributions = [norm(loc=y_test_hat_MLP[i], scale=std_dev_error) for i in range(len(y_test_hat_MLP))]\n",
    "\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_gaussian(y_test_np[i], mu=y_test_hat_MLP[i], sig=std_dev_error) for i in range(len(y_test_hat_MLP))]\n",
    "\n",
    "# Calculate the mean CRPS\n",
    "crps_MLP = np.mean(crps_values)\n",
    "\n",
    "print(\"CRPS MLP: \", crps_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:57:40,330] A new study created in memory with name: no-name-dc43c548-45c6-4e8a-add5-ec068b1bb14f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780dd319754a49f28c0dc498d22e5f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/1201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:58:03,064] Trial 0 finished with value: 57.87352118978276 and parameters: {'n_blocks': 4, 'd_block': 20, 'dropout1': 0.6336482349262754, 'dropout2': 0.7488038825386119, 'd_hidden_multiplier': 1.7462675307564761, 'n_epochs': 1201, 'learning_rate': 0.000342425210145967, 'weight_decay': 6.348243270946383e-05}. Best is trial 0 with value: 57.87352118978276.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36604227834541a0b572a313fe751d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/2610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:58:39,131] Trial 1 finished with value: 13.988067222045578 and parameters: {'n_blocks': 1, 'd_block': 53, 'dropout1': 0.6853598183677972, 'dropout2': 0.9533933461949365, 'd_hidden_multiplier': 0.5098706658197861, 'n_epochs': 2610, 'learning_rate': 0.015604131457893529, 'weight_decay': 1.155128593079557e-05}. Best is trial 1 with value: 13.988067222045578.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ab9c6ce8114703883a6576cc34603a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/796 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 15:00:57,785] Trial 2 finished with value: 12.033695503985886 and parameters: {'n_blocks': 4, 'd_block': 153, 'dropout1': 0.9177741225129434, 'dropout2': 0.7145757833976906, 'd_hidden_multiplier': 1.8563609200281532, 'n_epochs': 796, 'learning_rate': 0.0010177368807699995, 'weight_decay': 2.3478377182859888e-05}. Best is trial 2 with value: 12.033695503985886.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b30d788c65540de8f8135fb1fcfdbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/3045 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 15:16:41,351] Trial 3 finished with value: 10.319901510056718 and parameters: {'n_blocks': 3, 'd_block': 223, 'dropout1': 0.6177669784693172, 'dropout2': 0.5131382425543909, 'd_hidden_multiplier': 2.125992954828668, 'n_epochs': 3045, 'learning_rate': 0.014902984681415245, 'weight_decay': 4.057287303826027e-06}. Best is trial 3 with value: 10.319901510056718.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3759ab99a774af7923c7ed281e5c5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/4161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 15:27:40,910] Trial 4 finished with value: 12.952644959584417 and parameters: {'n_blocks': 5, 'd_block': 166, 'dropout1': 0.09045934927090737, 'dropout2': 0.30070005663620336, 'd_hidden_multiplier': 0.7849609046588744, 'n_epochs': 4161, 'learning_rate': 0.00013383563361780206, 'weight_decay': 1.3534298216580227e-05}. Best is trial 3 with value: 10.319901510056718.\n"
     ]
    }
   ],
   "source": [
    "N_TRIALS=5\n",
    "\n",
    "d_out = 1  \n",
    "d_in=X_train_.shape[1]\n",
    "\n",
    "def ResNet_opt(trial):\n",
    "\n",
    "    seed=10\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    n_blocks = trial.suggest_int(\"n_blocks\", 1, 5)\n",
    "    d_block = trial.suggest_int(\"d_block\", 10, 500)\n",
    "    dropout1 = trial.suggest_float(\"dropout1\", 0, 1)\n",
    "    dropout2 = trial.suggest_float(\"dropout2\", 0, 1)\n",
    "    d_hidden_multiplier=trial.suggest_float(\"d_hidden_multiplier\", 0.5, 3)\n",
    "\n",
    "    ResNet_model = ResNet(\n",
    "    d_in=d_in,\n",
    "    d_out=d_out,\n",
    "    n_blocks=n_blocks,\n",
    "    d_block=d_block,\n",
    "    d_hidden=None,\n",
    "    d_hidden_multiplier=d_hidden_multiplier,\n",
    "    dropout1=dropout1,\n",
    "    dropout2=dropout2,\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        ResNet_model = ResNet_model.cuda()\n",
    "    n_epochs=trial.suggest_int('n_epochs', 100, 5000)\n",
    "    learning_rate=trial.suggest_float('learning_rate', 0.0001, 0.05, log=True)\n",
    "    weight_decay=trial.suggest_float('weight_decay', 1e-8, 1e-3, log=True)\n",
    "    optimizer=torch.optim.Adam(ResNet_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    loss_Adam=[]\n",
    "\n",
    "    train(ResNet_model,criterion,loss_Adam,optimizer,n_epochs,X_train__tensor,y_train__tensor)\n",
    "\n",
    "    # Point prediction\n",
    "    y_val_hat_ResNet = (ResNet_model(X_val_tensor).reshape(-1,)).detach().numpy()\n",
    "\n",
    "    # Estimate standard deviation of the prediction error\n",
    "    std_dev_error = np.std(y_val - y_val_hat_ResNet)\n",
    "\n",
    "    # Calculate the CRPS for each prediction\n",
    "    crps_values = [crps_gaussian(y_val_np[i], mu=y_val_hat_ResNet[i], sig=std_dev_error) for i in range(len(y_val_hat_ResNet))]\n",
    "\n",
    "    # Calculate the mean CRPS\n",
    "    crps_ResNet = np.mean(crps_values)\n",
    "\n",
    "    return crps_ResNet\n",
    "\n",
    "sampler_ResNet = optuna.samplers.TPESampler(seed=10)\n",
    "study_ResNet = optuna.create_study(sampler=sampler_ResNet, direction='minimize')\n",
    "study_ResNet.optimize(ResNet_opt, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26144ded24447c4859f16a301cbb7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/3045 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS ResNet:  15.745058930608618\n"
     ]
    }
   ],
   "source": [
    "seed=10\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "ResNet_model = ResNet(\n",
    "    d_in=d_in,\n",
    "    d_out=d_out,\n",
    "    n_blocks=study_ResNet.best_params['n_blocks'],\n",
    "    d_block=study_ResNet.best_params['d_block'],\n",
    "    d_hidden=None,\n",
    "    d_hidden_multiplier=study_ResNet.best_params['d_hidden_multiplier'],\n",
    "    dropout1=study_ResNet.best_params['dropout1'],\n",
    "    dropout2=study_ResNet.best_params['dropout2'],\n",
    "    )\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    ResNet_model = ResNet_model.cuda()\n",
    "\n",
    "n_epochs=study_ResNet.best_params['n_epochs']\n",
    "learning_rate=study_ResNet.best_params['learning_rate']\n",
    "weight_decay=study_ResNet.best_params['weight_decay']\n",
    "optimizer=torch.optim.Adam(ResNet_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n",
    "loss_Adam=[]\n",
    "\n",
    "train(ResNet_model,criterion,loss_Adam,optimizer,n_epochs,X_train_tensor,y_train_tensor)\n",
    "\n",
    "# Point prediction\n",
    "y_test_hat_ResNet = (ResNet_model(X_test_tensor).reshape(-1,)).detach().numpy()\n",
    "\n",
    "# Estimate standard deviation of the prediction error\n",
    "std_dev_error = np.std(y_test - y_test_hat_ResNet)\n",
    "\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_gaussian(y_test_np[i], mu=y_test_hat_ResNet[i], sig=std_dev_error) for i in range(len(y_test_hat_ResNet))]\n",
    "\n",
    "# Calculate the mean CRPS\n",
    "crps_ResNet = np.mean(crps_values)\n",
    "\n",
    "print(\"CRPS ResNet: \", crps_ResNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 14:12:45,034] A new study created in memory with name: no-name-89d98ae0-5fc5-4bd5-a718-264130e5fee5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aa108623b14d20b2ac3d10ac89e312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/3827 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-01-26 14:48:25,053] Trial 0 failed with parameters: {'n_blocks': 4, 'd_block_multiplier': 1, 'attention_n_heads': 13, 'attention_dropout': 0.7488038825386119, 'ffn_d_hidden_multiplier': 1.7462675307564761, 'ffn_dropout': 0.22479664553084766, 'residual_dropout': 0.19806286475962398, 'n_epochs': 3827, 'learning_rate': 0.0002860388842288948} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_27316\\2411606154.py\", line 60, in FTTrans_opt\n",
      "    train_trans(FTTrans_model,criterion,loss_Adam,optimizer,n_epochs,X_train__tensor,y_train__tensor)\n",
      "  File \"C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_27316\\2411606154.py\", line 8, in train_trans\n",
      "    y_train_hat = model(X_train_tensor, None).reshape(-1,)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\rtdl_revisiting_models.py\", line 871, in forward\n",
      "    x = self.backbone(x)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\rtdl_revisiting_models.py\", line 656, in forward\n",
      "    x = block['attention'](x[:, :1] if i_block + 1 == n_blocks else x, x)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\rtdl_revisiting_models.py\", line 454, in forward\n",
      "    attention_probs = F.softmax(attention_logits, dim=-1)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\functional.py\", line 1856, in softmax\n",
      "    ret = input.softmax(dim)\n",
      "KeyboardInterrupt\n",
      "[W 2024-01-26 14:48:25,099] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m sampler_FTTrans \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     77\u001b[0m study_FTTrans \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(sampler\u001b[38;5;241m=\u001b[39msampler_FTTrans, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m \u001b[43mstudy_FTTrans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFTTrans_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[23], line 60\u001b[0m, in \u001b[0;36mFTTrans_opt\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     57\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     58\u001b[0m loss_Adam\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m---> 60\u001b[0m \u001b[43mtrain_trans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFTTrans_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_Adam\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train__tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train__tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Point prediction\u001b[39;00m\n\u001b[0;32m     63\u001b[0m y_val_hat_FTTrans \u001b[38;5;241m=\u001b[39m (FTTrans_model(X_val_tensor, \u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m, in \u001b[0;36mtrain_trans\u001b[1;34m(model, criterion, loss_Adam, optimizer, training_iterations, X_train_tensor, y_train_tensor)\u001b[0m\n\u001b[0;32m      4\u001b[0m iterator \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(training_iterations), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# making a pridiction in forward pass\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     y_train_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# calculating the loss between original and predicted data points\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_train_hat, torch\u001b[38;5;241m.\u001b[39mTensor(y_train_tensor))\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\rtdl_revisiting_models.py:871\u001b[0m, in \u001b[0;36mFTTransformer.forward\u001b[1;34m(self, x_cont, x_cat)\u001b[0m\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x_embeddings, _INTERNAL_ERROR\n\u001b[0;32m    870\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(x_embeddings, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 871\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\rtdl_revisiting_models.py:656\u001b[0m, in \u001b[0;36mFTTransformerBackbone.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_normalization\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m block:\n\u001b[0;32m    655\u001b[0m     x \u001b[38;5;241m=\u001b[39m block[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_normalization\u001b[39m\u001b[38;5;124m'\u001b[39m](x)\n\u001b[1;32m--> 656\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi_block\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_blocks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m x \u001b[38;5;241m=\u001b[39m block[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_residual_dropout\u001b[39m\u001b[38;5;124m'\u001b[39m](x)\n\u001b[0;32m    658\u001b[0m x \u001b[38;5;241m=\u001b[39m x_identity \u001b[38;5;241m+\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\rtdl_revisiting_models.py:454\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, x_q, x_kv)\u001b[0m\n\u001b[0;32m    452\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reshape(k)\n\u001b[0;32m    453\u001b[0m attention_logits \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(d_head_key)\n\u001b[1;32m--> 454\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    456\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1856\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1854\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1856\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_TRIALS=5\n",
    "\n",
    "def train_trans(model,criterion,loss_Adam,optimizer,training_iterations,X_train_tensor,y_train_tensor):\n",
    "    iterator = tqdm.tqdm(range(training_iterations), desc=\"Train\")\n",
    "\n",
    "    for _ in iterator:\n",
    "        # making a pridiction in forward pass\n",
    "        y_train_hat = model(X_train_tensor, None).reshape(-1,)\n",
    "        # calculating the loss between original and predicted data points\n",
    "        loss = criterion(y_train_hat, torch.Tensor(y_train_tensor))\n",
    "        # store loss into list\n",
    "        loss_Adam.append(loss.item())\n",
    "        # zeroing gradients after each iteration\n",
    "        optimizer.zero_grad()\n",
    "        # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
    "        loss.backward()\n",
    "        # updating the parameters after each iteration\n",
    "        optimizer.step()\n",
    "        iterator.set_postfix(loss=loss.item())\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "d_out = 1  \n",
    "d_in=X_train_.shape[1]\n",
    "\n",
    "def FTTrans_opt(trial):\n",
    "\n",
    "    seed=10\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    n_blocks = trial.suggest_int(\"n_blocks\", 1, 5)\n",
    "    d_block_multiplier = trial.suggest_int(\"d_block_multiplier\", 1, 25)\n",
    "    attention_n_heads = trial.suggest_int(\"attention_n_heads\", 1, 20)\n",
    "    attention_dropout = trial.suggest_float(\"attention_dropout\", 0, 1)\n",
    "    ffn_d_hidden_multiplier=trial.suggest_float(\"ffn_d_hidden_multiplier\", 0.5, 3)\n",
    "    ffn_dropout = trial.suggest_float(\"ffn_dropout\", 0, 1)\n",
    "    residual_dropout = trial.suggest_float(\"residual_dropout\", 0, 1)\n",
    "\n",
    "    FTTrans_model = FTTransformer(\n",
    "    n_cont_features=d_in,\n",
    "    cat_cardinalities=[],\n",
    "    d_out=d_out,\n",
    "    n_blocks=n_blocks,\n",
    "    d_block=d_block_multiplier*attention_n_heads,\n",
    "    attention_n_heads=attention_n_heads,\n",
    "    attention_dropout=attention_dropout,\n",
    "    ffn_d_hidden=None,\n",
    "    ffn_d_hidden_multiplier=ffn_d_hidden_multiplier,\n",
    "    ffn_dropout=ffn_dropout,\n",
    "    residual_dropout=residual_dropout,\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        FTTrans_model = FTTrans_model.cuda()\n",
    "\n",
    "    n_epochs=trial.suggest_int('n_epochs', 100, 5000)\n",
    "    learning_rate=trial.suggest_float('learning_rate', 0.0001, 0.05, log=True)\n",
    "    weight_decay=trial.suggest_float('weight_decay', 1e-8, 1e-3, log=True)\n",
    "    optimizer=torch.optim.Adam(FTTrans_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    loss_Adam=[]\n",
    "\n",
    "    train_trans(FTTrans_model,criterion,loss_Adam,optimizer,n_epochs,X_train__tensor,y_train__tensor)\n",
    "\n",
    "    # Point prediction\n",
    "    y_val_hat_FTTrans = (FTTrans_model(X_val_tensor, None).reshape(-1,)).detach().numpy()\n",
    "\n",
    "    # Estimate standard deviation of the prediction error\n",
    "    std_dev_error = np.std(y_val - y_val_hat_FTTrans)\n",
    "\n",
    "    # Calculate the CRPS for each prediction\n",
    "    crps_values = [crps_gaussian(y_val_np[i], mu=y_val_hat_FTTrans[i], sig=std_dev_error) for i in range(len(y_val_hat_FTTrans))]\n",
    "\n",
    "    # Calculate the mean CRPS\n",
    "    crps_FTTrans= np.mean(crps_values)\n",
    "\n",
    "    return crps_FTTrans\n",
    "\n",
    "sampler_FTTrans = optuna.samplers.TPESampler(seed=10)\n",
    "study_FTTrans = optuna.create_study(sampler=sampler_FTTrans, direction='minimize')\n",
    "study_FTTrans.optimize(FTTrans_opt, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=10\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "FTTrans_model = FTTransformer(\n",
    "    n_cont_features=d_in,\n",
    "    cat_cardinalities=[],\n",
    "    d_out=d_out,\n",
    "    n_blocks=study_FTTrans.best_params['n_blocks'],\n",
    "    d_block=study_FTTrans.best_params['d_block'],\n",
    "    attention_n_heads=study_FTTrans.best_params['attention_n_heads'],\n",
    "    attention_dropout=study_FTTrans.best_params['attention_dropout'],\n",
    "    ffn_d_hidden=None,\n",
    "    ffn_d_hidden_multiplier=study_FTTrans.best_params['ffn_d_hidden_multiplier'],\n",
    "    ffn_dropout=study_FTTrans.best_params['ffn_dropout'],\n",
    "    residual_dropout=study_FTTrans.best_params['residual_dropout'],\n",
    "    )\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    FTTrans_model = FTTrans_model.cuda()\n",
    "\n",
    "n_epochs=study_FTTrans.best_params['n_epochs']\n",
    "learning_rate=study_FTTrans.best_params['learning_rate']\n",
    "weight_decay=study_FTTrans.best_params['weight_decay']\n",
    "optimizer=torch.optim.Adam(FTTrans_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n",
    "loss_Adam=[]\n",
    "\n",
    "train_trans(FTTrans_model,criterion,loss_Adam,optimizer,n_epochs,X_train_tensor,y_train_tensor)\n",
    "\n",
    "# Point prediction\n",
    "y_test_hat_FTTrans = (FTTrans_model(X_test_tensor, None).reshape(-1,)).detach().numpy()\n",
    "\n",
    "# Estimate standard deviation of the prediction error\n",
    "std_dev_error = np.std(y_test - y_test_hat_FTTrans)\n",
    "\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_gaussian(y_test_np[i], mu=y_test_hat_FTTrans[i], sig=std_dev_error) for i in range(len(y_test_hat_FTTrans))]\n",
    "\n",
    "# Calculate the mean CRPS\n",
    "crps_FTTrans= np.mean(crps_values)\n",
    "\n",
    "print(\"CRPS FTTrans: \", crps_FTTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosted trees, random forest, engression, linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 16:53:23,764] A new study created in memory with name: no-name-f51e5684-c888-4a7b-b7ad-92a8e391465d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-26 16:53:27,320] Trial 0 finished with value: 6.937608925970823 and parameters: {'learning_rate': 0.0713003929222653, 'n_estimators': 108, 'reg_lambda': 0.005044685709888605, 'max_depth': 23, 'min_child_samples': 55}. Best is trial 0 with value: 6.937608925970823.\n",
      "[I 2024-01-26 16:53:29,770] Trial 1 finished with value: 12.527109038809398 and parameters: {'learning_rate': 0.0006784471913345375, 'n_estimators': 179, 'reg_lambda': 0.0699481785242808, 'max_depth': 6, 'min_child_samples': 18}. Best is trial 0 with value: 6.937608925970823.\n",
      "[W 2024-01-26 16:53:31,431] Trial 2 failed with parameters: {'learning_rate': 0.03428667811840723, 'n_estimators': 482, 'reg_lambda': 1.08526150100961e-08, 'max_depth': 16, 'min_child_samples': 83} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_12104\\1320909563.py\", line 72, in boosted\n",
      "    boosted_tree_model.train(opt_params, dtrain_, num_boost_round=n_rounds)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbmlss\\model.py\", line 175, in train\n",
      "    self.booster = lgb.train(params,\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbm\\engine.py\", line 276, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbm\\basic.py\", line 3899, in update\n",
      "    grad, hess = fobj(self.__inner_predict(0), self.train_set)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbmlss\\distributions\\distribution_utils.py\", line 104, in objective_fn\n",
      "    grad, hess = self.compute_gradients_and_hessians(loss, predt, weights)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbmlss\\distributions\\distribution_utils.py\", line 452, in compute_gradients_and_hessians\n",
      "    hess = [autograd(grad[i].nansum(), inputs=predt[i], retain_graph=True)[0] for i in range(len(grad))]\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbmlss\\distributions\\distribution_utils.py\", line 452, in <listcomp>\n",
      "    hess = [autograd(grad[i].nansum(), inputs=predt[i], retain_graph=True)[0] for i in range(len(grad))]\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 394, in grad\n",
      "    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-01-26 16:53:31,440] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m sampler_boost \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     86\u001b[0m study_boost \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(sampler\u001b[38;5;241m=\u001b[39msampler_boost, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m \u001b[43mstudy_boost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboosted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m N_SAMPLES\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrf\u001b[39m(trial):\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[10], line 72\u001b[0m, in \u001b[0;36mboosted\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     70\u001b[0m boosted_tree_model \u001b[38;5;241m=\u001b[39m LightGBMLSS(Gaussian(stabilization\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m, response_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnll\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     71\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m \u001b[43mboosted_tree_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Predict both the mean and standard deviation\u001b[39;00m\n\u001b[0;32m     75\u001b[0m pred_params\u001b[38;5;241m=\u001b[39mboosted_tree_model\u001b[38;5;241m.\u001b[39mpredict(X_val, pred_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbmlss\\model.py:175\u001b[0m, in \u001b[0;36mLightGBMLSS.train\u001b[1;34m(self, params, train_set, num_boost_round, valid_sets, valid_names, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_sets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     valid_sets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_valid_margin(valid_sets, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_values)\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m                         \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mkeep_training_booster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_training_booster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbm\\engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[0;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[0;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[0;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbm\\basic.py:3899\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3898\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_parameter({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39m__set_objective_to_none \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 3899\u001b[0m grad, hess \u001b[38;5;241m=\u001b[39m \u001b[43mfobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inner_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__boost(grad, hess)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbmlss\\distributions\\distribution_utils.py:104\u001b[0m, in \u001b[0;36mDistributionClass.objective_fn\u001b[1;34m(self, predt, data)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Calculate gradients and hessians\u001b[39;00m\n\u001b[0;32m    103\u001b[0m predt, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params_loss(predt, target, start_values, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 104\u001b[0m grad, hess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradients_and_hessians\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad, hess\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbmlss\\distributions\\distribution_utils.py:452\u001b[0m, in \u001b[0;36mDistributionClass.compute_gradients_and_hessians\u001b[1;34m(self, loss, predt, weights)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnll\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# Gradient and Hessian\u001b[39;00m\n\u001b[0;32m    451\u001b[0m     grad \u001b[38;5;241m=\u001b[39m autograd(loss, inputs\u001b[38;5;241m=\u001b[39mpredt, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 452\u001b[0m     hess \u001b[38;5;241m=\u001b[39m [autograd(grad[i]\u001b[38;5;241m.\u001b[39mnansum(), inputs\u001b[38;5;241m=\u001b[39mpredt[i], retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(grad))]\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# Gradient and Hessian\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     grad \u001b[38;5;241m=\u001b[39m autograd(loss, inputs\u001b[38;5;241m=\u001b[39mpredt, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\lightgbmlss\\distributions\\distribution_utils.py:452\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnll\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# Gradient and Hessian\u001b[39;00m\n\u001b[0;32m    451\u001b[0m     grad \u001b[38;5;241m=\u001b[39m autograd(loss, inputs\u001b[38;5;241m=\u001b[39mpredt, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 452\u001b[0m     hess \u001b[38;5;241m=\u001b[39m [\u001b[43mautograd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnansum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(grad))]\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# Gradient and Hessian\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     grad \u001b[38;5;241m=\u001b[39m autograd(loss, inputs\u001b[38;5;241m=\u001b[39mpredt, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    390\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[0;32m    391\u001b[0m         grad_outputs_\n\u001b[0;32m    392\u001b[0m     )\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 394\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[0;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    405\u001b[0m         output\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (output, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, t_inputs)\n\u001b[0;32m    409\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_TRIALS=5\n",
    "\n",
    "'''def boosted(trial):\n",
    "\n",
    "    params = {'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.5, log=True),\n",
    "              'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "              'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "              'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "              'min_child_samples': trial.suggest_int('min_child_samples', 10, 100)}\n",
    "    \n",
    "    boosted_tree_model=lgbm.LGBMRegressor(**params)\n",
    "    boosted_tree_model.fit(X_train_, y_train_)\n",
    "    y_val_hat_boost=boosted_tree_model.predict(X_val)\n",
    "    RMSE_boost=np.sqrt(np.mean((y_val-y_val_hat_boost)**2))\n",
    "\n",
    "    return RMSE_boost\n",
    "\n",
    "sampler_boost = optuna.samplers.TPESampler(seed=10)\n",
    "study_boost = optuna.create_study(sampler=sampler_boost, direction='minimize')\n",
    "study_boost.optimize(boosted, n_trials=N_TRIALS)\n",
    "\n",
    "boosted_model=lgbm.LGBMRegressor(**study_boost.best_params)\n",
    "\n",
    "def rf(trial):\n",
    "\n",
    "    params = {'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "              'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "              'max_features': trial.suggest_int('max_features', 1, 30),\n",
    "              'min_samples_leaf': trial.suggest_int('min_samples_leaf', 10, 100)}\n",
    "    \n",
    "    rf_model=RandomForestRegressor(**params)\n",
    "    rf_model.fit(X_train_, y_train_)\n",
    "    y_val_hat_rf=rf_model.predict(X_val)\n",
    "    # Calculate the standard deviation of the residuals\n",
    "    std_dev = np.std(y_val - y_val_hat_rf)\n",
    "    # Calculate the CRPS for each prediction\n",
    "    y_val_np = y_val.values.flatten()\n",
    "    crps_values = [crps_gaussian(y_val_np[i], mu=y_val_hat_rf[i], sig=std_dev) for i in range(len(y_val_np))]\n",
    "    CRPS_rf = np.mean(crps_values)\n",
    "\n",
    "    return CRPS_rf\n",
    "\n",
    "sampler_rf = optuna.samplers.TPESampler(seed=10)\n",
    "study_rf = optuna.create_study(sampler=sampler_rf, direction='minimize')\n",
    "study_rf.optimize(rf, n_trials=N_TRIALS)\n",
    "\n",
    "rf_model=RandomForestRegressor(**study_rf.best_params)'''\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "# Create lgb dataset\n",
    "dtrain_ = lgb.Dataset(torch.tensor(X_train_.values, dtype=torch.float32).clone().detach(), label=y_train_.values)\n",
    "\n",
    "def boosted(trial):\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.5, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "    }\n",
    "    opt_params = params.copy()\n",
    "    n_rounds = opt_params[\"n_estimators\"]\n",
    "    del opt_params[\"n_estimators\"]\n",
    "    opt_params['feature_pre_filter']=False\n",
    "\n",
    "    # Use LightGBMLossGuideRegressor for distributional prediction\n",
    "    boosted_tree_model = LightGBMLSS(Gaussian(stabilization=\"None\", response_fn=\"exp\", loss_fn=\"nll\"))\n",
    "    torch.manual_seed(10)\n",
    "    boosted_tree_model.train(opt_params, dtrain_, num_boost_round=n_rounds)\n",
    "\n",
    "    # Predict both the mean and standard deviation\n",
    "    pred_params=boosted_tree_model.predict(X_val, pred_type=\"parameters\")\n",
    "    y_val_hat_boost=pred_params['loc']\n",
    "    y_val_hat_std = pred_params['scale']\n",
    "\n",
    "    # Calculate the CRPS for each prediction\n",
    "    crps_values = [crps_gaussian(y_val_np[i], mu=y_val_hat_boost[i], sig=y_val_hat_std[i]) for i in range(len(y_val))]\n",
    "\n",
    "    # Return the mean CRPS as the objective to be minimized\n",
    "    return np.mean(crps_values)\n",
    "\n",
    "sampler_boost = optuna.samplers.TPESampler(seed=10)\n",
    "study_boost = optuna.create_study(sampler=sampler_boost, direction='minimize')\n",
    "study_boost.optimize(boosted, n_trials=N_TRIALS)\n",
    "\n",
    "N_SAMPLES=100\n",
    "\n",
    "def rf(trial):\n",
    "    params = {'num_trees': trial.suggest_int('num_trees', 100, 500),\n",
    "          'mtry': trial.suggest_int('mtry', 1, 30),\n",
    "          'min_node_size': trial.suggest_int('min_node_size', 10, 100)}\n",
    "    \n",
    "    drf_model = drf(**params)\n",
    "    drf_model.fit(X_train_, y_train_)\n",
    "    \n",
    "    # Generate a sample from the drf model for each data point\n",
    "    y_val_hat=drf_model.predict(newdata = X_val, functional = \"quantile\", quantiles=list(np.random.uniform(0,1,N_SAMPLES)))\n",
    "\n",
    "    # Calculate the CRPS for each prediction\n",
    "    crps_values = [crps_ensemble(y_val_np[i], y_val_hat.quantile[i].reshape(-1)) for i in range(len(y_val_np))]\n",
    "\n",
    "    # Return the mean CRPS as the objective to be minimized\n",
    "    return np.mean(crps_values)\n",
    "\n",
    "sampler_drf = optuna.samplers.TPESampler(seed=10)\n",
    "study_drf = optuna.create_study(sampler=sampler_drf, direction='minimize')\n",
    "study_drf.optimize(rf, n_trials=N_TRIALS)\n",
    "\n",
    "def engressor_NN(trial):\n",
    "\n",
    "    params = {'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.01, log=True),\n",
    "              'num_epoches': trial.suggest_int('num_epoches', 100, 1000),\n",
    "              'num_layer': trial.suggest_int('num_layer', 2, 5),\n",
    "              'hidden_dim': trial.suggest_int('hidden_dim', 100, 500),}\n",
    "    params['noise_dim']=params['hidden_dim']\n",
    "    \n",
    "    engressor_model=engression(torch.Tensor(np.array(X_train_)), torch.Tensor(np.array(y_train_).reshape(-1,1)), lr=params['learning_rate'], num_epoches=params['num_epoches'],num_layer=params['num_layer'], hidden_dim=params['hidden_dim'], noise_dim=params['noise_dim'], batch_size=1000)\n",
    "    # Generate a sample from the engression model for each data point\n",
    "    y_val_hat_engression_samples = [engressor_model.sample(torch.Tensor(np.array([X_val.values[i]])), sample_size=N_SAMPLES) for i in range(len(X_val))]\n",
    "\n",
    "    # Calculate the CRPS for each prediction\n",
    "    crps_values = [crps_ensemble(y_val_np[i], np.array(y_val_hat_engression_samples[i]).reshape(-1,)) for i in range(len(y_val_np))]\n",
    "\n",
    "    return np.mean(crps_values)\n",
    "\n",
    "sampler_engression = optuna.samplers.TPESampler(seed=10)\n",
    "study_engression = optuna.create_study(sampler=sampler_engression, direction='minimize')\n",
    "study_engression.optimize(engressor_NN, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5434, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train__tensor.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU.\n",
      "\n",
      "Data is standardized for training only; the printed training losses are on the standardized scale. \n",
      "However during evaluation, the predictions, evaluation metrics, and plots will be on the original scale.\n",
      "\n",
      "Training based on mini-batch gradient descent with a batch size of 1000.\n",
      "[Epoch 1 (0%), batch 6] energy-loss: 0.8719,  E(|Y-Yhat|): 0.9254,  E(|Yhat-Yhat'|): 0.1071\n",
      "\n",
      "Training loss on the original (non-standardized) scale:\n",
      "\tEnergy-loss: 4.0458,  E(|Y-Yhat|): 4.2826,  E(|Yhat-Yhat'|): 0.4736\n",
      "\n",
      "Prediction-loss E(|Y-Yhat|) and variance-loss E(|Yhat-Yhat'|) should ideally be equally large\n",
      "-- consider training for more epochs or adjusting hyperparameters if there is a mismatch \n"
     ]
    }
   ],
   "source": [
    "engressor_model=engression(X_train__tensor, y_train__tensor.reshape(-1,1), lr=0.001, num_epoches=5,num_layer=2, hidden_dim=2, noise_dim=2, batch_size=1000)\n",
    "\n",
    "y_val_hat_engression=engressor_model.predict(X_val_tensor, target=\"mean\")\n",
    "\n",
    "RMSE_engression=torch.sqrt(torch.mean(torch.square(y_val_tensor.reshape(-1,1) - y_val_hat_engression)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.9943)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_engression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU.\n",
      "\n",
      "Data is standardized for training only; the printed training losses are on the standardized scale. \n",
      "However during evaluation, the predictions, evaluation metrics, and plots will be on the original scale.\n",
      "\n",
      "Training based on mini-batch gradient descent with a batch size of 1000.\n",
      "[Epoch 1 (0%), batch 6] energy-loss: 0.8607,  E(|Y-Yhat|): 0.9379,  E(|Yhat-Yhat'|): 0.1544\n",
      "\n",
      "Training loss on the original (non-standardized) scale:\n",
      "\tEnergy-loss: 3.4879,  E(|Y-Yhat|): 4.0124,  E(|Yhat-Yhat'|): 1.0489\n",
      "\n",
      "Prediction-loss E(|Y-Yhat|) and variance-loss E(|Yhat-Yhat'|) should ideally be equally large\n",
      "-- consider training for more epochs or adjusting hyperparameters if there is a mismatch \n",
      "tensor([45.2676])\n",
      "tensor(45.2691)\n"
     ]
    }
   ],
   "source": [
    "seed=10\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "engressor_model=engression(torch.Tensor(np.array(X_train_)), torch.Tensor(np.array(y_train_).reshape(-1,1)), lr=0.001, num_epoches=5,num_layer=2, hidden_dim=2, noise_dim=2, batch_size=1000)\n",
    "y_val_hat_engression=engressor_model.predict(torch.Tensor(np.array(X_val)), target=\"mean\")\n",
    "RMSE_engression=np.sqrt((((torch.Tensor(np.array(y_val).reshape(-1,1)))-y_val_hat_engression)**2).mean(axis=0))\n",
    "print(RMSE_engression)\n",
    "\n",
    "y_val_hat_engression=engressor_model.predict(X_val_tensor, target=\"mean\")\n",
    "RMSE_engression=torch.sqrt(torch.mean(torch.square(y_val_tensor.reshape(-1,1) - y_val_hat_engression)))\n",
    "print(RMSE_engression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/somepago/saint.git\n",
      "  Cloning https://github.com/somepago/saint.git to c:\\users\\dalma\\appdata\\local\\temp\\pip-req-build-bqlg_yj2\n",
      "  Resolved https://github.com/somepago/saint.git to commit e288e84c77a54cfd2ffb55a53678fb7cbbb16630\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/somepago/saint.git 'C:\\Users\\dalma\\AppData\\Local\\Temp\\pip-req-build-bqlg_yj2'\n",
      "ERROR: git+https://github.com/somepago/saint.git does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/somepago/saint.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/LeoGrin/tabular-benchmark.git\n",
      "  Cloning https://github.com/LeoGrin/tabular-benchmark.git to c:\\users\\dalma\\appdata\\local\\temp\\pip-req-build-xqta0bl4\n",
      "  Resolved https://github.com/LeoGrin/tabular-benchmark.git to commit 9d54cf53d9fd3159e367e70a00005f4fcbf2c79d\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/LeoGrin/tabular-benchmark.git 'C:\\Users\\dalma\\AppData\\Local\\Temp\\pip-req-build-xqta0bl4'\n",
      "  Running command git submodule update --init --recursive -q\n",
      "ERROR: git+https://github.com/LeoGrin/tabular-benchmark.git does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/LeoGrin/tabular-benchmark.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (588987684.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[42], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    git clone https://github.com/LeoGrin/tabular-benchmark.git\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "git clone https://github.com/LeoGrin/tabular-benchmark.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabular_benchmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/dalma/Desktop/THESIS_ETH_NEW/CODE/TABULAR BENCHMARK/tabular-benchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtabular_benchmark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SaintModel\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tabular_benchmark'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/dalma/Desktop/THESIS_ETH_NEW/CODE/TABULAR BENCHMARK/tabular-benchmark\")\n",
    "\n",
    "from tabular_benchmark import SaintModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-widedeepNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached pytorch_widedeep-1.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas>=1.3.5 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pytorch-widedeep) (2.1.4)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pytorch-widedeep) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.7.3 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pytorch-widedeep) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pytorch-widedeep) (1.4.0)\n",
      "Collecting gensim (from pytorch-widedeep)\n",
      "  Using cached gensim-4.3.2-cp310-cp310-win_amd64.whl.metadata (8.5 kB)\n",
      "Collecting spacy (from pytorch-widedeep)\n",
      "  Using cached spacy-3.7.2-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Collecting opencv-contrib-python (from pytorch-widedeep)\n",
      "  Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting imutils (from pytorch-widedeep)\n",
      "  Using cached imutils-0.5.4-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pytorch-widedeep) (4.66.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pytorch-widedeep) (2.1.2)\n",
      "Collecting torchvision>=0.15.0 (from pytorch-widedeep)\n",
      "  Using cached torchvision-0.16.2-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting einops (from pytorch-widedeep)\n",
      "  Using cached einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting wrapt (from pytorch-widedeep)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting torchmetrics (from pytorch-widedeep)\n",
      "  Downloading torchmetrics-1.3.0.post0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pytorch-widedeep) (14.0.2)\n",
      "Collecting fastparquet>=0.8.1 (from pytorch-widedeep)\n",
      "  Using cached fastparquet-2023.10.1-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting cramjam>=2.3 (from fastparquet>=0.8.1->pytorch-widedeep)\n",
      "  Downloading cramjam-2.8.1-cp310-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from fastparquet>=0.8.1->pytorch-widedeep) (2023.12.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from fastparquet>=0.8.1->pytorch-widedeep) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pandas>=1.3.5->pytorch-widedeep) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pandas>=1.3.5->pytorch-widedeep) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from pandas>=1.3.5->pytorch-widedeep) (2023.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-widedeep) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-widedeep) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-widedeep) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-widedeep) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from torch>=2.0.0->pytorch-widedeep) (3.1.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from torchvision>=0.15.0->pytorch-widedeep) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from torchvision>=0.15.0->pytorch-widedeep) (10.2.0)\n",
      "Collecting smart-open>=1.8.1 (from gensim->pytorch-widedeep)\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy->pytorch-widedeep)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached murmurhash-1.0.10-cp310-cp310-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->pytorch-widedeep)\n",
      "  Using cached cymem-2.0.8-cp310-cp310-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->pytorch-widedeep)\n",
      "  Using cached preshed-3.0.9-cp310-cp310-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy->pytorch-widedeep)\n",
      "  Using cached thinc-8.2.2-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy->pytorch-widedeep)\n",
      "  Using cached wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy->pytorch-widedeep)\n",
      "  Using cached srsly-2.4.8-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy->pytorch-widedeep)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy->pytorch-widedeep)\n",
      "  Using cached pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from spacy->pytorch-widedeep) (57.4.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from tqdm->pytorch-widedeep) (0.4.6)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics->pytorch-widedeep)\n",
      "  Downloading lightning_utilities-0.10.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->pytorch-widedeep)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.6 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->pytorch-widedeep)\n",
      "  Using cached pydantic_core-2.14.6-cp310-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->pytorch-widedeep) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from requests->torchvision>=0.15.0->pytorch-widedeep) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from requests->torchvision>=0.15.0->pytorch-widedeep) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from requests->torchvision>=0.15.0->pytorch-widedeep) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from requests->torchvision>=0.15.0->pytorch-widedeep) (2023.11.17)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy->pytorch-widedeep)\n",
      "  Using cached blis-0.7.11-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy->pytorch-widedeep)\n",
      "  Using cached confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting click<9.0.0,>=7.1.1 (from typer<0.10.0,>=0.3.0->spacy->pytorch-widedeep)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy->pytorch-widedeep)\n",
      "  Using cached cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->pytorch-widedeep) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dalma\\desktop\\thesis_eth_new\\code\\.venv\\lib\\site-packages (from sympy->torch>=2.0.0->pytorch-widedeep) (1.3.0)\n",
      "Using cached pytorch_widedeep-1.4.0-py3-none-any.whl (21.9 MB)\n",
      "Using cached fastparquet-2023.10.1-cp310-cp310-win_amd64.whl (667 kB)\n",
      "Using cached torchvision-0.16.2-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "Using cached einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Using cached gensim-4.3.2-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "Downloading opencv_contrib_python-4.9.0.80-cp37-abi3-win_amd64.whl (45.3 MB)\n",
      "   ---------------------------------------- 0.0/45.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.7/45.3 MB 14.8 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.9/45.3 MB 19.7 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 3.0/45.3 MB 19.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.9/45.3 MB 19.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 4.7/45.3 MB 20.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.9/45.3 MB 20.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 6.8/45.3 MB 21.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 7.6/45.3 MB 20.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 8.5/45.3 MB 20.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.7/45.3 MB 21.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.7/45.3 MB 21.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.9/45.3 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 12.8/45.3 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 13.9/45.3 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 14.4/45.3 MB 21.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 15.6/45.3 MB 22.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 16.9/45.3 MB 21.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 18.2/45.3 MB 23.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 18.7/45.3 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 19.7/45.3 MB 21.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.4/45.3 MB 20.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 21.6/45.3 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.4/45.3 MB 20.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.4/45.3 MB 20.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.3/45.3 MB 21.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 24.7/45.3 MB 21.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 26.2/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 27.1/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 28.2/45.3 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 29.1/45.3 MB 21.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 30.0/45.3 MB 19.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.9/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 31.9/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 32.6/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 33.4/45.3 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.5/45.3 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.5/45.3 MB 21.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 36.4/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.2/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.1/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.0/45.3 MB 21.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.1/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.8/45.3 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 42.7/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.5/45.3 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/45.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.9/45.3 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.3/45.3 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.3/45.3 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.3/45.3 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.3/45.3 MB 14.5 MB/s eta 0:00:00\n",
      "Using cached spacy-3.7.2-cp310-cp310-win_amd64.whl (12.1 MB)\n",
      "Downloading torchmetrics-1.3.0.post0-py3-none-any.whl (840 kB)\n",
      "   ---------------------------------------- 0.0/840.2 kB ? eta -:--:--\n",
      "   ------------------------------------- - 809.0/840.2 kB 25.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 840.2/840.2 kB 17.7 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.16.0-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cramjam-2.8.1-cp310-none-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.7/1.6 MB 15.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 16.9 MB/s eta 0:00:00\n",
      "Using cached cymem-2.0.8-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
      "Using cached murmurhash-1.0.10-cp310-cp310-win_amd64.whl (25 kB)\n",
      "Using cached preshed-3.0.9-cp310-cp310-win_amd64.whl (122 kB)\n",
      "Using cached pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "Using cached pydantic_core-2.14.6-cp310-none-win_amd64.whl (1.9 MB)\n",
      "Using cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.4.8-cp310-cp310-win_amd64.whl (481 kB)\n",
      "Using cached thinc-8.2.2-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Using cached wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached blis-0.7.11-cp310-cp310-win_amd64.whl (6.6 MB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Using cached confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: imutils, cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, smart-open, pydantic-core, opencv-contrib-python, murmurhash, lightning-utilities, langcodes, einops, cramjam, cloudpathlib, click, catalogue, blis, annotated-types, typer, srsly, pydantic, preshed, gensim, torchvision, torchmetrics, fastparquet, confection, weasel, thinc, spacy, pytorch-widedeep\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 click-8.1.7 cloudpathlib-0.16.0 confection-0.1.4 cramjam-2.8.1 cymem-2.0.8 einops-0.7.0 fastparquet-2023.10.1 gensim-4.3.2 imutils-0.5.4 langcodes-3.3.0 lightning-utilities-0.10.1 murmurhash-1.0.10 opencv-contrib-python-4.9.0.80 preshed-3.0.9 pydantic-2.5.3 pydantic-core-2.14.6 pytorch-widedeep-1.4.0 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.2 torchmetrics-1.3.0.post0 torchvision-0.16.2 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-27 19:03:48,527] A new study created in memory with name: no-name-5bc6fe89-4443-43b2-96ce-9b768f459b96\n",
      "[W 2024-01-27 19:03:48,810] Trial 0 failed with parameters: {'n_layers': 4, 'n_heads': 1, 'embed_dim': 321, 'dropout': 0.7488038825386119} because of the following error: TypeError(\"TabTransformer.__init__() got an unexpected keyword argument 'embed_dim'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_28528\\648684132.py\", line 25, in Saint_opt\n",
      "    saint_model = TabTransformer(\n",
      "TypeError: TabTransformer.__init__() got an unexpected keyword argument 'embed_dim'\n",
      "[W 2024-01-27 19:03:48,810] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TabTransformer.__init__() got an unexpected keyword argument 'embed_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m sampler_saint \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m     56\u001b[0m study_saint \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(sampler\u001b[38;5;241m=\u001b[39msampler_saint, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m \u001b[43mstudy_saint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSaint_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Preprocess the data\u001b[39;00m\n\u001b[0;32m     60\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m TabPreprocessor(embed_cols\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[57], line 25\u001b[0m, in \u001b[0;36mSaint_opt\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     22\u001b[0m     embeddings_input\u001b[38;5;241m.\u001b[39mappend((col, X_train_[col]\u001b[38;5;241m.\u001b[39mnunique()))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m saint_model \u001b[38;5;241m=\u001b[39m \u001b[43mTabTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuous_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinuous_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Define the trainer\u001b[39;00m\n\u001b[0;32m     36\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(saint_model, objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[nn\u001b[38;5;241m.\u001b[39mMSELoss()])\n",
      "\u001b[1;31mTypeError\u001b[0m: TabTransformer.__init__() got an unexpected keyword argument 'embed_dim'"
     ]
    }
   ],
   "source": [
    "from pytorch_widedeep.models import TabTransformer\n",
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_widedeep.training import Trainer\n",
    "\n",
    "def Saint_opt(trial):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    n_heads = trial.suggest_int(\"n_heads\", 1, 20)\n",
    "    embed_dim = trial.suggest_int(\"embed_dim\", 10, 500)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0, 1)\n",
    "\n",
    "    # Preprocess the data\n",
    "    preprocessor = TabPreprocessor(embed_cols=X_train_.columns.tolist())\n",
    "    X_train__saint = preprocessor.fit_transform(X_train_)\n",
    "    X_val_saint = preprocessor.transform(X_val)\n",
    "\n",
    "    embeddings_input = []\n",
    "    for col in X_train_.columns:\n",
    "        embeddings_input.append((col, X_train_[col].nunique()))\n",
    "\n",
    "    # Define the model\n",
    "    saint_model = TabTransformer(\n",
    "        column_idx=preprocessor.column_idx,\n",
    "        input_dim=len(preprocessor.column_idx),\n",
    "        embed_dim=embed_dim,\n",
    "        continuous_cols=preprocessor.continuous_cols,\n",
    "        n_layers=n_layers,\n",
    "        n_heads=n_heads,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = Trainer(saint_model, objective=\"regression\", metrics=[nn.MSELoss()])\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(\n",
    "        X_train=X_train__saint,\n",
    "        target=y_train_,\n",
    "        n_epochs=trial.suggest_int('n_epochs', 100, 5000),\n",
    "        #batch_size=trial.suggest_categorical('batch_size', [16, 32, 64, 128]),\n",
    "        val_split=0.1,\n",
    "    )\n",
    "\n",
    "    # Predict on the validation set and calculate the CRPS\n",
    "    y_val_hat_saint = trainer.predict(X_val_saint)\n",
    "    std_dev_error = np.std(y_val - y_val_hat_saint)\n",
    "    crps_saint = [crps_gaussian(y_val_np[i], mu=y_val_hat_saint[i], sig=std_dev_error) for i in range(len(y_val_hat_saint))]\n",
    "    crps_saint = np.mean(crps_saint)\n",
    "\n",
    "    return crps_saint\n",
    "\n",
    "sampler_saint = optuna.samplers.TPESampler(seed=seed)\n",
    "study_saint = optuna.create_study(sampler=sampler_saint, direction='minimize')\n",
    "study_saint.optimize(Saint_opt, n_trials=N_TRIALS)\n",
    "\n",
    "# Preprocess the data\n",
    "preprocessor = TabPreprocessor(embed_cols=X_train.columns.tolist())\n",
    "X_train_saint = preprocessor.fit_transform(X_train)\n",
    "X_test_saint = preprocessor.transform(X_test)\n",
    "\n",
    "embeddings_input = []\n",
    "for col in X_train.columns:\n",
    "    embeddings_input.append((col, X_train[col].nunique()))\n",
    "\n",
    "# Define the model\n",
    "saint_model = TabTransformer(\n",
    "    column_idx=preprocessor.column_idx,\n",
    "    input_dim=len(preprocessor.column_idx),\n",
    "    embed_dim=study_saint.best_params['embed_dim'],\n",
    "    continuous_cols=preprocessor.continuous_cols,\n",
    "    n_layers=study_saint.best_params['n_layers'],\n",
    "    n_heads=study_saint.best_params['n_heads'],\n",
    "    dropout=study_saint.best_params['dropout'],\n",
    ")\n",
    "\n",
    "trainer = Trainer(saint_model, objective=\"regression\", metrics=[nn.MSELoss()])\n",
    "\n",
    "trainer.fit(\n",
    "    X_train=X_train_saint,\n",
    "    target=y_train,\n",
    "    n_epochs=study_saint.best_params['n_epochs'],\n",
    "    #batch_size=study_saint.best_params['batch_size'],\n",
    "    val_split=0.1,\n",
    ")\n",
    "\n",
    "y_test_hat_saint = trainer.predict(X_test_saint)\n",
    "std_dev_error = np.std(y_test - y_test_hat_saint)\n",
    "crps_saint = [crps_gaussian(y_test_np[i], mu=y_test_hat_saint[i], sig=std_dev_error) for i in range(len(y_test_hat_saint))]\n",
    "crps_saint = np.mean(crps_saint)\n",
    "print(\"CRPS SAINT: \", crps_saint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.8883],\n",
       "        [ -9.3065],\n",
       "        [ -2.5412],\n",
       "        ...,\n",
       "        [ -3.7598],\n",
       "        [ -9.0308],\n",
       "        [-12.7551]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_tensor.reshape(-1,1) - y_val_hat_engression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed)\n\u001b[0;32m      6\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m----> 8\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach(), label\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      9\u001b[0m opt_params \u001b[38;5;241m=\u001b[39m study_boost\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     10\u001b[0m n_rounds \u001b[38;5;241m=\u001b[39m opt_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "N_SAMPLES=100\n",
    "seed=10\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "dtrain = lgb.Dataset(torch.tensor(X_train.values, dtype=torch.float32).clone().detach(), label=y_train.values)\n",
    "opt_params = study_boost.best_params.copy()\n",
    "n_rounds = opt_params[\"n_estimators\"]\n",
    "del opt_params[\"n_estimators\"]\n",
    "opt_params['feature_pre_filter']=False\n",
    "# Use LightGBMLossGuideRegressor for distributional prediction\n",
    "boosted_tree_model = LightGBMLSS(Gaussian(stabilization=\"None\", response_fn=\"exp\", loss_fn=\"nll\"))\n",
    "torch.manual_seed(10)\n",
    "boosted_tree_model.train(opt_params, dtrain, num_boost_round=n_rounds)\n",
    "# Predict both the mean and standard deviation\n",
    "pred_params=boosted_tree_model.predict(X_test, pred_type=\"parameters\")\n",
    "y_test_hat_boost=pred_params['loc']\n",
    "y_test_hat_std = pred_params['scale']\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_gaussian(y_test_np[i], mu=y_test_hat_boost[i], sig=y_test_hat_std[i]) for i in range(len(y_test))]\n",
    "# Return the mean CRPS as the objective to be minimized\n",
    "CRPS_boosted=np.mean(crps_values)\n",
    "\n",
    "'''\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_test_hat_rf=rf_model.predict(X_test)\n",
    "# Calculate the standard deviation of the residuals\n",
    "std_dev = np.std(y_test - y_test_hat_rf)\n",
    "# Calculate the CRPS for each prediction\n",
    "y_test_np = y_test.values.flatten()\n",
    "crps_values = [crps_gaussian(y_test_np[i], mu=y_test_hat_rf[i], sig=std_dev) for i in range(len(y_test_np))]\n",
    "CRPS_rf = np.mean(crps_values)'''\n",
    "\n",
    "drf_model=drf(**study_drf.best_params)\n",
    "drf_model.fit(X_train, y_train)\n",
    "# Generate a sample from the drf model for each data point\n",
    "y_test_hat_drf=drf_model.predict(newdata = X_test, functional = \"quantile\", quantiles=list(np.random.uniform(0,1,N_SAMPLES)))\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_ensemble(y_test_np[i], y_test_hat_drf.quantile[i].reshape(-1)) for i in range(len(y_test_np))]\n",
    "# Return the mean CRPS as the objective to be minimized\n",
    "CRPS_rf=np.mean(crps_values)\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_test_hat_linreg=lin_reg.predict(X_test)\n",
    "# Calculate the standard deviation of the residuals\n",
    "std_dev = np.std(y_test - y_test_hat_linreg)\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_gaussian(y_test_np[i], mu=y_test_hat_linreg[i], sig=std_dev) for i in range(len(y_test_np))]\n",
    "CRPS_linreg = np.mean(crps_values)\n",
    "\n",
    "params=study_engression.best_params\n",
    "params['noise_dim']=params['hidden_dim']\n",
    "X_train_tensor = torch.Tensor(np.array(X_train))\n",
    "y_train_tensor = torch.Tensor(np.array(y_train).reshape(-1,1))\n",
    "# Check if CUDA is available and if so, move the tensors and the model to the GPU\n",
    "if torch.cuda.is_available():\n",
    "    X_train_tensor = X_train_tensor.cuda()\n",
    "    y_train_tensor = y_train_tensor.cuda()\n",
    "    engressor_model=engression(X_train_tensor, y_train_tensor, lr=params['learning_rate'], num_epoches=params['num_epoches'],num_layer=params['num_layer'], hidden_dim=params['hidden_dim'], noise_dim=params['noise_dim'], batch_size=1000).cuda()\n",
    "else:\n",
    "    engressor_model=engression(X_train_tensor, y_train_tensor, lr=params['learning_rate'], num_epoches=params['num_epoches'],num_layer=params['num_layer'], hidden_dim=params['hidden_dim'], noise_dim=params['noise_dim'], batch_size=1000)\n",
    "# Generate a sample from the engression model for each data point\n",
    "y_test_hat_engression_samples = [engressor_model.sample(torch.Tensor(np.array([X_test.values[i]])).cuda() if torch.cuda.is_available() else torch.Tensor(np.array([X_test.values[i]])), sample_size=N_SAMPLES) for i in range(len(X_test))]\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_ensemble(y_test_np[i], np.array(y_test_hat_engression_samples[i]).reshape(-1,)) for i in range(len(y_test_np))]\n",
    "CRPS_engression=np.mean(crps_values)\n",
    "\n",
    "\n",
    "print(\"CRPS linear regression: \",CRPS_linreg)\n",
    "print(\"CRPS boosted trees\", CRPS_boosted)\n",
    "print(\"CRPS random forest\", CRPS_rf)\n",
    "print(\"CRPS engression\", CRPS_engression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_FTTrans=None\n",
    "crps_results = {'GP': CRPS_GP, 'MLP': crps_MLP, 'ResNet': crps_ResNet, 'FTTrans': crps_FTTrans, 'boosted_trees': CRPS_boosted, 'drf': CRPS_rf, 'linear_regression': CRPS_linreg, 'engression': CRPS_engression}  # Add all your methods here\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(list(crps_results.items()), columns=['Method', 'CRPS'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(f'RESULTS/CLUSTERING/{task_id}_clustering_crps_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian process with stochastic variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-22 17:10:06,859] A new study created in memory with name: no-name-bea4cf5f-3031-4dec-a045-a078b921cc60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-01-22 17:18:36,997] Trial 0 failed with parameters: {'lengthscale': 0.08747537025773001, 'learning_rate': 0.00011376505702653915} because of the following error: AxisError(-1, 0, None).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_14344\\2994460075.py\", line 77, in SVGP_opt\n",
      "    crps_values = [CRPS(y_val_np[i], pred_distributions[i]) for i in range(len(y_val_np))]\n",
      "  File \"C:\\Users\\dalma\\AppData\\Local\\Temp\\ipykernel_14344\\2994460075.py\", line 77, in <listcomp>\n",
      "    crps_values = [CRPS(y_val_np[i], pred_distributions[i]) for i in range(len(y_val_np))]\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\CRPS\\CRPS.py\", line 109, in __init__\n",
      "    self.fc = np.sort(ensemble_members)\n",
      "  File \"c:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 1017, in sort\n",
      "    a.sort(axis=axis, kind=kind, order=order)\n",
      "numpy.exceptions.AxisError: axis -1 is out of bounds for array of dimension 0\n",
      "[W 2024-01-22 17:18:37,119] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis -1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[21], line 85\u001b[0m\n",
      "\u001b[0;32m     83\u001b[0m sampler_SVGP \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;32m     84\u001b[0m study_SVGP \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(sampler\u001b[38;5;241m=\u001b[39msampler_SVGP, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m---> 85\u001b[0m \u001b[43mstudy_SVGP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSVGP_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n",
      "\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n",
      "\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n",
      "\u001b[0;32m    360\u001b[0m \n",
      "\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n",
      "\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n",
      "\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n",
      "\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n",
      "\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n",
      "\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n",
      "\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n",
      "\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n",
      "\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n",
      "\u001b[0;32m    250\u001b[0m ):\n",
      "\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n",
      "\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n",
      "\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n",
      "\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n",
      "\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "\n",
      "Cell \u001b[1;32mIn[21], line 77\u001b[0m, in \u001b[0;36mSVGP_opt\u001b[1;34m(trial)\u001b[0m\n",
      "\u001b[0;32m     74\u001b[0m pred_distributions \u001b[38;5;241m=\u001b[39m [norm(loc\u001b[38;5;241m=\u001b[39my_pred_np[i], scale\u001b[38;5;241m=\u001b[39my_pred_std_np[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pred_np))]\n",
      "\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Calculate the CRPS for each prediction\u001b[39;00m\n",
      "\u001b[1;32m---> 77\u001b[0m crps_values \u001b[38;5;241m=\u001b[39m [CRPS(y_val_np[i], pred_distributions[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_val_np))]\n",
      "\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Calculate the mean CRPS\u001b[39;00m\n",
      "\u001b[0;32m     80\u001b[0m mean_crps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(crps_values)\n",
      "\n",
      "Cell \u001b[1;32mIn[21], line 77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n",
      "\u001b[0;32m     74\u001b[0m pred_distributions \u001b[38;5;241m=\u001b[39m [norm(loc\u001b[38;5;241m=\u001b[39my_pred_np[i], scale\u001b[38;5;241m=\u001b[39my_pred_std_np[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pred_np))]\n",
      "\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Calculate the CRPS for each prediction\u001b[39;00m\n",
      "\u001b[1;32m---> 77\u001b[0m crps_values \u001b[38;5;241m=\u001b[39m [\u001b[43mCRPS\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val_np\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_distributions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_val_np))]\n",
      "\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Calculate the mean CRPS\u001b[39;00m\n",
      "\u001b[0;32m     80\u001b[0m mean_crps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(crps_values)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\CRPS\\CRPS.py:109\u001b[0m, in \u001b[0;36mCRPS.__init__\u001b[1;34m(self, ensemble_members, observation, adjusted_ensemble_size)\u001b[0m\n",
      "\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,ensemble_members,observation,adjusted_ensemble_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m):\n",
      "\u001b[0;32m     91\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n",
      "\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n",
      "\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m        ensemble_members: numpy.ndarray\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m        \u001b[39;00m\n",
      "\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_members\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mob \u001b[38;5;241m=\u001b[39m observation\n",
      "\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dalma\\Desktop\\THESIS_ETH_NEW\\CODE\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1017\u001b[0m, in \u001b[0;36msort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n",
      "\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m   1016\u001b[0m     a \u001b[38;5;241m=\u001b[39m asanyarray(a)\u001b[38;5;241m.\u001b[39mcopy(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m-> 1017\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\n",
      "\u001b[1;31mAxisError\u001b[0m: axis -1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "N_TRIALS=2\n",
    "\n",
    "def SVGP_opt(trial):\n",
    "\n",
    "    seed=10\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    class SVGPMODEL(gpytorch.models.ApproximateGP):\n",
    "        def __init__(self, inducing_points):\n",
    "            variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "            variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "            super(SVGPMODEL, self).__init__(variational_strategy)\n",
    "            self.mean_module = gpytorch.means.ConstantMean()\n",
    "            self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "                gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=inducing_points.shape[1]),\n",
    "                ard_num_dims=inducing_points.shape[1]\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            mean_x = self.mean_module(x)\n",
    "            covar_x = self.covar_module(x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_.values, dtype=torch.float32)\n",
    "\n",
    "    # Initialize the Gaussian Process model and likelihood\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = SVGPMODEL(X_train_tensor)\n",
    "\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Define the learning params\n",
    "    n_epochs=5 #trial.suggest_int('n_epochs', 100, 5000)\n",
    "    learning_rate=trial.suggest_float('learning_rate', 0.0001, 0.05, log=True)\n",
    "\n",
    "    # Use the negative log likelihood as the loss\n",
    "    mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=y_train_tensor.numel())\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train_tensor)\n",
    "        loss = -mll(output, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        y_pred = model(torch.tensor(X_val.values, dtype=torch.float32))\n",
    "\n",
    "    # Calculate CRPS\n",
    "    y_val_np = y_val.values.flatten()\n",
    "    y_pred_np = y_pred.mean.numpy().flatten()\n",
    "    y_pred_std_np = y_pred.stddev.numpy().flatten()\n",
    "    \n",
    "    # Calculate the CRPS for each prediction\n",
    "    crps_values = [crps_gaussian(y_val_np[i], mu=y_pred_np[i], sig=y_pred_std_np[i]) for i in range(len(y_val_np))]\n",
    "\n",
    "    # Calculate the mean CRPS\n",
    "    mean_crps= np.mean(crps_values)\n",
    "    \n",
    "    return mean_crps\n",
    "\n",
    "sampler_SVGP = optuna.samplers.TPESampler(seed=10)\n",
    "study_SVGP = optuna.create_study(sampler=sampler_SVGP, direction='minimize')\n",
    "study_SVGP.optimize(SVGP_opt, n_trials=N_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study_SVGP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Access the best parameters\u001b[39;00m\n",
      "\u001b[1;32m----> 2\u001b[0m best_params_SVGP \u001b[38;5;241m=\u001b[39m \u001b[43mstudy_SVGP\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params\n",
      "\u001b[0;32m      3\u001b[0m lengthscale \u001b[38;5;241m=\u001b[39m best_params_SVGP[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlengthscale\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;32m      4\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m best_params_SVGP[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'study_SVGP' is not defined"
     ]
    }
   ],
   "source": [
    "# Access the best parameters\n",
    "best_params_SVGP = study_SVGP.best_params\n",
    "lengthscale = best_params_SVGP['lengthscale']\n",
    "n_epochs = best_params_SVGP['n_epochs']\n",
    "learning_rate = best_params_SVGP['learning_rate']\n",
    "\n",
    "class SVGPMODEL(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "        super(SVGPMODEL, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.MaternKernel(nu=1.5, ard_num_dims=inducing_points.shape[1], lengthscale=lengthscale),\n",
    "            ard_num_dims=inducing_points.shape[1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "# Initialize the final Gaussian Process model with the best parameters\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "final_model = SVGPMODEL(X_tensor)\n",
    "\n",
    "# Set the model in training mode\n",
    "final_model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the negative log likelihood as the loss\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, final_model, num_data=y_tensor.numel())\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = final_model(X_tensor)\n",
    "    loss = -mll(output, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Set the final model in evaluation mode\n",
    "final_model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Make predictions on the validation set\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    y_pred = final_model(torch.tensor(X_test.values, dtype=torch.float32))\n",
    "\n",
    "\n",
    "# Calculate CRPS\n",
    "y_test_np = y_test.values.flatten()\n",
    "y_pred_np = y_pred.mean.numpy().flatten()\n",
    "y_pred_std_np = y_pred.stddev.numpy().flatten()\n",
    "\n",
    "# Calculate the CRPS for each prediction\n",
    "crps_values = [crps_gaussian(y_test_np[i], mu=y_pred_np[i], sig=y_pred_std_np[i]) for i in range(len(y_test_np))]\n",
    "\n",
    "# Calculate the mean CRPS\n",
    "CRPS_SVGP= np.mean(crps_values)\n",
    "\n",
    "print(\"CRPS SVGP: \", CRPS_SVGP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfcdafd4c2f198e9231774dbaa691ef2a9d56c92dabac0fe3d9f172dfc08608e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
