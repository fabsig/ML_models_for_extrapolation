{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "task = openml.tasks.get_task(361072)  # download the OpenML task\n",
    "dataset = task.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Dataset\n",
       "==============\n",
       "Name..........: cpu_act\n",
       "Version.......: 8\n",
       "Format........: arff\n",
       "Upload Date...: 2022-07-05 20:47:51\n",
       "Licence.......: Public\n",
       "Download URL..: https://api.openml.org/data/v1/download/22103257/cpu_act.arff\n",
       "OpenML URL....: https://www.openml.org/d/44132\n",
       "# of features.: 22\n",
       "# of instances: 8192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from hpsklearn import any_regressor\n",
    "from hpsklearn import any_preprocessing\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4853\n",
      "[LightGBM] [Info] Number of data points in the train set: 6553, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 84.025790\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4853\n",
      "[LightGBM] [Info] Number of data points in the train set: 6553, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 84.025790\n"
     ]
    }
   ],
   "source": [
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_test_hat_linreg=lin_reg.predict(X_test)\n",
    "RMSE_linreg=np.sqrt(np.mean((y_test-y_test_hat_linreg))**2)\n",
    "\n",
    "boosted_tree_model=lgbm.LGBMRegressor()\n",
    "boosted_tree_model.fit(X_train, y_train)\n",
    "y_test_hat_boost=boosted_tree_model.predict(X_test)\n",
    "RMSE_boost=np.sqrt(np.mean((y_test-y_test_hat_boost))**2)\n",
    "\n",
    "rf=lgbm.LGBMRegressor(boosting_type=\"rf\", subsample_freq=1, subsample=0.5)\n",
    "rf.fit(X_train, y_train)\n",
    "y_test_hat_rf=rf.predict(X_test)\n",
    "RMSE_rf=np.sqrt(np.mean((y_test-y_test_hat_rf))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11346621438751542\n",
      "0.023893443004829713\n",
      "0.059410165217422935\n"
     ]
    }
   ],
   "source": [
    "print(RMSE_linreg)\n",
    "print(RMSE_boost)\n",
    "print(RMSE_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-01 18:22:39,677] A new study created in memory with name: no-name-e55adffb-0af4-4dc3-962d-c559e45b3c56\n",
      "[I 2023-12-01 18:22:39,856] Trial 0 finished with value: 0.07645441916241363 and parameters: {'learning_rate': 0.3879471152007055, 'reg_lambda': 1.537331564587801e-08, 'max_depth': 20, 'min_child_samples': 78}. Best is trial 0 with value: 0.07645441916241363.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-01 18:22:39,989] Trial 1 finished with value: 0.07715370419782382 and parameters: {'learning_rate': 0.2542684360282693, 'reg_lambda': 1.0547992438188775e-06, 'max_depth': 6, 'min_child_samples': 79}. Best is trial 0 with value: 0.07645441916241363.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-01 18:22:40,141] Trial 2 finished with value: 0.06273914299447474 and parameters: {'learning_rate': 0.09286430991564236, 'reg_lambda': 6.238186113062485e-08, 'max_depth': 21, 'min_child_samples': 96}. Best is trial 2 with value: 0.06273914299447474.\n",
      "[I 2023-12-01 18:22:40,290] Trial 3 finished with value: 0.08182313435194251 and parameters: {'learning_rate': 0.011934650500678082, 'reg_lambda': 0.0004071274363191098, 'max_depth': 25, 'min_child_samples': 65}. Best is trial 2 with value: 0.06273914299447474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-01 18:22:40,408] Trial 4 finished with value: 0.06407551628125277 and parameters: {'learning_rate': 0.3636601055415818, 'reg_lambda': 4.235304245072407e-06, 'max_depth': 28, 'min_child_samples': 75}. Best is trial 2 with value: 0.06273914299447474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-01 18:22:40,525] Trial 5 finished with value: 0.05473747974342514 and parameters: {'learning_rate': 0.27584674032551804, 'reg_lambda': 1.9034015928564192e-07, 'max_depth': 12, 'min_child_samples': 71}. Best is trial 5 with value: 0.05473747974342514.\n",
      "[I 2023-12-01 18:22:40,648] Trial 6 finished with value: 0.04526480738855055 and parameters: {'learning_rate': 0.2264982554672681, 'reg_lambda': 8.056120247993029e-05, 'max_depth': 19, 'min_child_samples': 56}. Best is trial 6 with value: 0.04526480738855055.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-01 18:22:40,777] Trial 7 finished with value: 0.030392082826789756 and parameters: {'learning_rate': 0.32869461914641895, 'reg_lambda': 0.0025665550309028774, 'max_depth': 25, 'min_child_samples': 57}. Best is trial 7 with value: 0.030392082826789756.\n",
      "[I 2023-12-01 18:22:40,826] Trial 8 finished with value: 0.10098310073038085 and parameters: {'learning_rate': 0.4552379515962474, 'reg_lambda': 7.4666329224550155e-06, 'max_depth': 3, 'min_child_samples': 37}. Best is trial 7 with value: 0.030392082826789756.\n",
      "[I 2023-12-01 18:22:40,867] Trial 9 finished with value: 0.08410339589672867 and parameters: {'learning_rate': 0.06585233731313939, 'reg_lambda': 0.2871652845130526, 'max_depth': 2, 'min_child_samples': 66}. Best is trial 7 with value: 0.030392082826789756.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.32869461914641895,\n",
       " 'reg_lambda': 0.0025665550309028774,\n",
       " 'max_depth': 25,\n",
       " 'min_child_samples': 57}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def boosted(trial):\n",
    "\n",
    "    params = {'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),\n",
    "              'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "              'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "              #'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
    "              'min_child_samples': trial.suggest_int('min_child_samples', 10, 100)}\n",
    "    \n",
    "    boosted_tree_model=lgbm.LGBMRegressor(**params)\n",
    "    boosted_tree_model.fit(X_train_, y_train_)\n",
    "    y_val_hat_boost=boosted_tree_model.predict(X_val)\n",
    "    RMSE_boost=np.sqrt(np.mean((y_val-y_val_hat_boost))**2)\n",
    "\n",
    "    return RMSE_boost\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=10)\n",
    "study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "study.optimize(boosted, n_trials=10)\n",
    "\n",
    "boosted_model=lgbm.LGBMRegressor(**study.best_params)\n",
    "\n",
    "\n",
    "def boosted(trial):\n",
    "\n",
    "    params = {'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),\n",
    "              'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "              'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "              #'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
    "              'min_child_samples': trial.suggest_int('min_child_samples', 10, 100)}\n",
    "    \n",
    "    boosted_tree_model=lgbm.LGBMRegressor(**params)\n",
    "    boosted_tree_model.fit(X_train_, y_train_)\n",
    "    y_val_hat_boost=boosted_tree_model.predict(X_val)\n",
    "    RMSE_boost=np.sqrt(np.mean((y_val-y_val_hat_boost))**2)\n",
    "\n",
    "    return RMSE_boost\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=10)\n",
    "study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "study.optimize(boosted, n_trials=10)\n",
    "\n",
    "boosted_model=lgbm.LGBMRegressor(**study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x23be77daf50>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the difference when using Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "# calculate the mean and covariance matrix of the dataset\n",
    "mean = np.mean(X, axis=0)\n",
    "cov = np.cov(X.T)\n",
    "\n",
    "# calculate the Mahalanobis distance for each data point\n",
    "mahalanobis_dist = [mahalanobis(x, mean, np.linalg.inv(cov)) for x in X.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis_dist=pd.Series(mahalanobis_dist,index=X.index)\n",
    "far_index=mahalanobis_dist.index[np.where(mahalanobis_dist>=np.quantile(mahalanobis_dist,0.8))[0]]\n",
    "close_index=mahalanobis_dist.index[np.where(mahalanobis_dist<np.quantile(mahalanobis_dist,0.8))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.loc[close_index,:]\n",
    "X_test = X.loc[far_index,:]\n",
    "y_train = y.loc[close_index]\n",
    "y_test = y.loc[far_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "cov = np.cov(X_train.T)\n",
    "\n",
    "# calculate the Mahalanobis distance for each data point\n",
    "mahalanobis_dist_ = [mahalanobis(x, mean, np.linalg.inv(cov)) for x in X_train.values]\n",
    "\n",
    "mahalanobis_dist_=pd.Series(mahalanobis_dist_,index=X_train.index)\n",
    "far_index_=mahalanobis_dist_.index[np.where(mahalanobis_dist_>=np.quantile(mahalanobis_dist_,0.8))[0]]\n",
    "close_index_=mahalanobis_dist_.index[np.where(mahalanobis_dist_<np.quantile(mahalanobis_dist_,0.8))[0]]\n",
    "\n",
    "X_train_ = X_train.loc[close_index_,:]\n",
    "X_val = X_train.loc[far_index_,:]\n",
    "y_train_ = y_train.loc[close_index_]\n",
    "y_val = y_train.loc[far_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 10:46:33,251] A new study created in memory with name: no-name-58356da7-33ad-49d2-b3f6-1e494bc2f549\n",
      "[I 2023-12-04 10:49:40,006] Trial 0 finished with value: 18.320949842839397 and parameters: {'lenghtscale': 7.71320643266746}. Best is trial 0 with value: 18.320949842839397.\n",
      "[I 2023-12-04 10:50:09,981] Trial 1 finished with value: 77.15865751334859 and parameters: {'lenghtscale': 0.207519493594015}. Best is trial 0 with value: 18.320949842839397.\n",
      "[I 2023-12-04 10:54:18,896] Trial 2 finished with value: 18.320949841533366 and parameters: {'lenghtscale': 6.336482349262754}. Best is trial 2 with value: 18.320949841533366.\n",
      "[I 2023-12-04 11:02:42,473] Trial 3 finished with value: 18.320951111080884 and parameters: {'lenghtscale': 7.488038825386118}. Best is trial 2 with value: 18.320949841533366.\n",
      "[I 2023-12-04 11:10:54,250] Trial 4 finished with value: 18.321006223368716 and parameters: {'lenghtscale': 4.9850701230259045}. Best is trial 2 with value: 18.320949841533366.\n",
      "[I 2023-12-04 11:11:24,144] Trial 5 finished with value: 77.15865751334859 and parameters: {'lenghtscale': 2.2479664553084766}. Best is trial 2 with value: 18.320949841533366.\n",
      "[I 2023-12-04 11:11:53,669] Trial 6 finished with value: 77.15865751334859 and parameters: {'lenghtscale': 1.9806286475962398}. Best is trial 2 with value: 18.320949841533366.\n",
      "[I 2023-12-04 11:15:26,222] Trial 7 finished with value: 18.32097096095577 and parameters: {'lenghtscale': 7.605307121989587}. Best is trial 2 with value: 18.320949841533366.\n",
      "[I 2023-12-04 11:15:37,943] Trial 8 finished with value: 77.15865751334859 and parameters: {'lenghtscale': 1.6911083656253545}. Best is trial 2 with value: 18.320949841533366.\n",
      "[I 2023-12-04 11:15:50,086] Trial 9 finished with value: 77.15865751334859 and parameters: {'lenghtscale': 0.8833981417401027}. Best is trial 2 with value: 18.320949841533366.\n",
      "[I 2023-12-04 11:15:50,322] A new study created in memory with name: no-name-4f540368-dcf9-4014-a540-2c436d7ecd17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:50,794] Trial 0 finished with value: 6.548774458745064 and parameters: {'learning_rate': 0.3879471152007055, 'n_estimators': 108, 'reg_lambda': 0.005044685709888605, 'max_depth': 23, 'min_child_samples': 55}. Best is trial 0 with value: 6.548774458745064.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:50,985] Trial 1 finished with value: 6.419385988876968 and parameters: {'learning_rate': 0.12015035631011535, 'n_estimators': 179, 'reg_lambda': 0.0699481785242808, 'max_depth': 6, 'min_child_samples': 18}. Best is trial 1 with value: 6.419385988876968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:51,556] Trial 2 finished with value: 6.536407589304645 and parameters: {'learning_rate': 0.34582631100022065, 'n_estimators': 482, 'reg_lambda': 1.08526150100961e-08, 'max_depth': 16, 'min_child_samples': 83}. Best is trial 1 with value: 6.419385988876968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:52,075] Trial 3 finished with value: 6.657181105841132 and parameters: {'learning_rate': 0.3101377727464002, 'n_estimators': 389, 'reg_lambda': 4.235304245072407e-06, 'max_depth': 28, 'min_child_samples': 75}. Best is trial 1 with value: 6.419385988876968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:52,300] Trial 4 finished with value: 6.5263899496196025 and parameters: {'learning_rate': 0.27584674032551804, 'n_estimators': 157, 'reg_lambda': 2.2912202578440842e-05, 'max_depth': 21, 'min_child_samples': 50}. Best is trial 1 with value: 6.419385988876968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:52,753] Trial 5 finished with value: 6.556287617886695 and parameters: {'learning_rate': 0.22266685673331393, 'n_estimators': 347, 'reg_lambda': 0.0004151874170225355, 'max_depth': 20, 'min_child_samples': 64}. Best is trial 1 with value: 6.419385988876968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:53,218] Trial 6 finished with value: 6.391910326154809 and parameters: {'learning_rate': 0.40455936644804574, 'n_estimators': 309, 'reg_lambda': 1.5060518616773197, 'max_depth': 10, 'min_child_samples': 18}. Best is trial 6 with value: 6.391910326154809.\n",
      "[I 2023-12-04 11:15:53,275] Trial 7 finished with value: 6.855905014952471 and parameters: {'learning_rate': 0.15734302775173967, 'n_estimators': 145, 'reg_lambda': 0.2871652845130526, 'max_depth': 2, 'min_child_samples': 66}. Best is trial 6 with value: 6.391910326154809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:53,783] Trial 8 finished with value: 6.553463831834591 and parameters: {'learning_rate': 0.27831721640042933, 'n_estimators': 428, 'reg_lambda': 6.173448891970491e-07, 'max_depth': 26, 'min_child_samples': 42}. Best is trial 6 with value: 6.391910326154809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:54,041] Trial 9 finished with value: 6.607179212431153 and parameters: {'learning_rate': 0.37977736884963004, 'n_estimators': 218, 'reg_lambda': 0.9024607364578421, 'max_depth': 10, 'min_child_samples': 25}. Best is trial 6 with value: 6.391910326154809.\n",
      "[I 2023-12-04 11:15:54,057] A new study created in memory with name: no-name-63af5c07-1fac-4a13-a198-41201059cbc4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:54,894] Trial 0 finished with value: 7.902924394262695 and parameters: {'n_estimators': 409, 'reg_lambda': 1.537331564587801e-08, 'max_depth': 20, 'subsample_freq': 8, 'subsample': 0.7492535061512953, 'min_child_samples': 30}. Best is trial 0 with value: 7.902924394262695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:55,191] Trial 1 finished with value: 8.1667682993641 and parameters: {'n_estimators': 179, 'reg_lambda': 0.0699481785242808, 'max_depth': 6, 'subsample_freq': 1, 'subsample': 0.8426799091838986, 'min_child_samples': 96}. Best is trial 0 with value: 7.902924394262695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:55,367] Trial 2 finished with value: 7.997044966912059 and parameters: {'n_estimators': 101, 'reg_lambda': 0.0004071274363191098, 'max_depth': 25, 'subsample_freq': 7, 'subsample': 0.8608776587158997, 'min_child_samples': 36}. Best is trial 0 with value: 7.902924394262695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:56,087] Trial 3 finished with value: 8.109009403219488 and parameters: {'n_estimators': 468, 'reg_lambda': 0.02698870526662559, 'max_depth': 17, 'subsample_freq': 2, 'subsample': 0.6866703800257346, 'min_child_samples': 71}. Best is trial 0 with value: 7.902924394262695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:56,457] Trial 4 finished with value: 8.019792959551717 and parameters: {'n_estimators': 277, 'reg_lambda': 8.056120247993029e-05, 'max_depth': 19, 'subsample_freq': 6, 'subsample': 0.8251985909657336, 'min_child_samples': 64}. Best is trial 0 with value: 7.902924394262695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:57,109] Trial 5 finished with value: 8.0104005724075 and parameters: {'n_estimators': 422, 'reg_lambda': 0.0004952498715186091, 'max_depth': 28, 'subsample_freq': 4, 'subsample': 0.5452296746354537, 'min_child_samples': 37}. Best is trial 0 with value: 7.902924394262695.\n",
      "[I 2023-12-04 11:15:57,181] Trial 6 finished with value: 9.238879152045008 and parameters: {'n_estimators': 145, 'reg_lambda': 0.2871652845130526, 'max_depth': 2, 'subsample_freq': 7, 'subsample': 0.7737930779596218, 'min_child_samples': 84}. Best is trial 0 with value: 7.902924394262695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:57,375] Trial 7 finished with value: 8.273070816054899 and parameters: {'n_estimators': 179, 'reg_lambda': 0.5148168134404182, 'max_depth': 11, 'subsample_freq': 8, 'subsample': 0.6479808534398394, 'min_child_samples': 90}. Best is trial 0 with value: 7.902924394262695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:57,818] Trial 8 finished with value: 7.927649663794281 and parameters: {'n_estimators': 230, 'reg_lambda': 3.055927730910031e-07, 'max_depth': 12, 'subsample_freq': 1, 'subsample': 0.9105528289184642, 'min_child_samples': 23}. Best is trial 0 with value: 7.902924394262695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5242, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 91.111980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 11:15:58,269] Trial 9 finished with value: 8.310839394080224 and parameters: {'n_estimators': 254, 'reg_lambda': 3.15026008204159, 'max_depth': 30, 'subsample_freq': 5, 'subsample': 0.91306142192137, 'min_child_samples': 32}. Best is trial 0 with value: 7.902924394262695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "N_TRIALS=10\n",
    "\n",
    "def gp(trial):\n",
    "\n",
    "    params = {'lenghtscale': trial.suggest_float('lenghtscale', 0, 10)}\n",
    "    \n",
    "    gp=GaussianProcessRegressor(kernel=Matern(length_scale=params['lenghtscale'], nu=1.5))\n",
    "    gp.fit(X_train_, y_train_)\n",
    "    y_val_hat_gp=gp.predict(X_val)\n",
    "    RMSE_gp=np.sqrt(np.mean((y_val-y_val_hat_gp)**2))\n",
    "    return RMSE_gp\n",
    "\n",
    "sampler_gp = optuna.samplers.TPESampler(seed=10)\n",
    "study_gp = optuna.create_study(sampler=sampler_gp, direction='minimize')\n",
    "study_gp.optimize(gp, n_trials=N_TRIALS)\n",
    "\n",
    "gp_model=GaussianProcessRegressor(kernel=Matern(length_scale=study_gp.best_params['lenghtscale'], nu=1.5))\n",
    "\n",
    "\n",
    "def boosted(trial):\n",
    "\n",
    "    params = {'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),\n",
    "              'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "              'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "              'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "              #'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
    "              'min_child_samples': trial.suggest_int('min_child_samples', 10, 100)}\n",
    "    \n",
    "    boosted_tree_model=lgbm.LGBMRegressor(**params)\n",
    "    boosted_tree_model.fit(X_train_, y_train_)\n",
    "    y_val_hat_boost=boosted_tree_model.predict(X_val)\n",
    "    RMSE_boost=np.sqrt(np.mean((y_val-y_val_hat_boost)**2))\n",
    "\n",
    "    return RMSE_boost\n",
    "\n",
    "sampler_boost = optuna.samplers.TPESampler(seed=10)\n",
    "study_boost = optuna.create_study(sampler=sampler_boost, direction='minimize')\n",
    "study_boost.optimize(boosted, n_trials=N_TRIALS)\n",
    "\n",
    "boosted_model=lgbm.LGBMRegressor(**study_boost.best_params)\n",
    "\n",
    "\n",
    "def rf(trial):\n",
    "\n",
    "    params = {'boosting_type':\"rf\",\n",
    "              'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "              'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "              'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "              'subsample_freq': trial.suggest_int('subsample_freq', 1, 10),\n",
    "              'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "              #'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
    "              'min_child_samples': trial.suggest_int('min_child_samples', 10, 100)}\n",
    "    \n",
    "    rf_model=lgbm.LGBMRegressor(**params)\n",
    "    rf_model.fit(X_train_, y_train_)\n",
    "    y_val_hat_rf=rf_model.predict(X_val)\n",
    "    RMSE_rf=np.sqrt(np.mean((y_val-y_val_hat_rf)**2))\n",
    "\n",
    "    return RMSE_rf\n",
    "\n",
    "sampler_rf = optuna.samplers.TPESampler(seed=10)\n",
    "study_rf = optuna.create_study(sampler=sampler_rf, direction='minimize')\n",
    "study_rf.optimize(rf, n_trials=N_TRIALS)\n",
    "\n",
    "rf_model=lgbm.LGBMRegressor(**study_rf.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4351\n",
      "[LightGBM] [Info] Number of data points in the train set: 6553, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 88.320464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4351\n",
      "[LightGBM] [Info] Number of data points in the train set: 6553, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 88.320464\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "RMSE linear regression:  62.070783717577555\n",
      "RMSE boosted trees 2.2270184840127323\n",
      "RMSE random forest 5.431531004846616\n",
      "RMSE gaussian process 18.46862292228306\n"
     ]
    }
   ],
   "source": [
    "gp_model.fit(X_train, y_train)\n",
    "y_test_hat_gp=gp_model.predict(X_test)\n",
    "RMSE_gp=np.sqrt(np.mean((y_test-y_test_hat_gp)**2))\n",
    "\n",
    "boosted_model.fit(X_train, y_train)\n",
    "y_test_hat_boosted=boosted_model.predict(X_test)\n",
    "RMSE_boosted=np.sqrt(np.mean((y_test-y_test_hat_boosted)**2))\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_test_hat_rf=rf_model.predict(X_test)\n",
    "RMSE_rf=np.sqrt(np.mean((y_test-y_test_hat_rf)**2))\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_test_hat_linreg=lin_reg.predict(X_test)\n",
    "RMSE_linreg=np.sqrt(np.mean((y_test-y_test_hat_linreg)**2))\n",
    "\n",
    "print(\"RMSE linear regression: \",RMSE_linreg)\n",
    "print(\"RMSE boosted trees\", RMSE_boost)\n",
    "print(\"RMSE random forest\", RMSE_rf)\n",
    "print(\"RMSE gaussian process\", RMSE_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'depth.multivariate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [206], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdepth\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmultivariate\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'depth.multivariate'"
     ]
    }
   ],
   "source": [
    "from depth.multivariate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statdepth import FunctionalDepth, PointcloudDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [225], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bd \u001b[39m=\u001b[39m FunctionalDepth(\u001b[39mlist\u001b[39;49m(np\u001b[39m.\u001b[39;49marray(X)), containment\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msimplex\u001b[39;49m\u001b[39m'\u001b[39;49m, relax\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, quiet\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statdepth\\depth\\depth.py:383\u001b[0m, in \u001b[0;36mFunctionalDepth\u001b[1;34m(data, to_compute, K, J, containment, relax, deep_check, quiet)\u001b[0m\n\u001b[0;32m    372\u001b[0m     depth \u001b[39m=\u001b[39m _samplefunctionaldepth(\n\u001b[0;32m    373\u001b[0m         data\u001b[39m=\u001b[39mdata,\n\u001b[0;32m    374\u001b[0m         to_compute\u001b[39m=\u001b[39mto_compute, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m         quiet\u001b[39m=\u001b[39mquiet\n\u001b[0;32m    381\u001b[0m     )\n\u001b[0;32m    382\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 383\u001b[0m     depth \u001b[39m=\u001b[39m _functionaldepth(\n\u001b[0;32m    384\u001b[0m         data\u001b[39m=\u001b[39;49mdata, \n\u001b[0;32m    385\u001b[0m         to_compute\u001b[39m=\u001b[39;49mto_compute, \n\u001b[0;32m    386\u001b[0m         J\u001b[39m=\u001b[39;49mJ, \n\u001b[0;32m    387\u001b[0m         containment\u001b[39m=\u001b[39;49mcontainment, \n\u001b[0;32m    388\u001b[0m         relax\u001b[39m=\u001b[39;49mrelax, \n\u001b[0;32m    389\u001b[0m         deep_check\u001b[39m=\u001b[39;49mdeep_check,\n\u001b[0;32m    390\u001b[0m         quiet\u001b[39m=\u001b[39;49mquiet\n\u001b[0;32m    391\u001b[0m     )\n\u001b[0;32m    393\u001b[0m \u001b[39m# Return the appropriate class\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(depth, pd\u001b[39m.\u001b[39mDataFrame): \n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statdepth\\depth\\calculations\\_functional.py:56\u001b[0m, in \u001b[0;36m_functionaldepth\u001b[1;34m(data, to_compute, J, containment, relax, deep_check, quiet)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mCalculate the band depth for a set of functional curves.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mpd.Series, pd.DataFrame: Depth values for each function.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m# Handle common errors\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m _handle_depth_errors(data\u001b[39m=\u001b[39;49mdata, J\u001b[39m=\u001b[39;49mJ, containment\u001b[39m=\u001b[39;49mcontainment, relax\u001b[39m=\u001b[39;49mrelax, deep_check\u001b[39m=\u001b[39;49mdeep_check)\n\u001b[0;32m     58\u001b[0m \u001b[39m# Select containment definition\u001b[39;00m\n\u001b[0;32m     59\u001b[0m cdef \u001b[39m=\u001b[39m _select_containment(containment\u001b[39m=\u001b[39mcontainment)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statdepth\\depth\\calculations\\_helper.py:92\u001b[0m, in \u001b[0;36m_handle_depth_errors\u001b[1;34m(data, J, containment, relax, deep_check)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcontainment argument \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mr2\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m is invalid for multivariate data. Use one of [\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mr2_enum\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39msimplex \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m] or a passed containment method. \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[39m# If there is not at least d + 2 functions for our d dimensional data, then for each function\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# We won't have d + 1 vertices to construct a simplex, which means every simplex will be at least one dimensional degenerate\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m# Therefore we say depth is not well defined and error\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m<\u001b[39m data[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m containment \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msimplex\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     93\u001b[0m     \u001b[39mraise\u001b[39;00m DepthDegeneracy(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError: Need at least \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m functions to form non-degenerate simplices in \u001b[39m\u001b[39m{\u001b[39;00mdata[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m dimensional space. Only have \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m deep_check:\n\u001b[0;32m     96\u001b[0m     \u001b[39m# Check dtypes of all columns over all DataFrames. \u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[39m# Optional because this might be computationally expensive for very large datasets. \u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "bd = FunctionalDepth(list(np.array(X)), containment='simplex', relax=True, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model=GaussianProcessRegressor(kernel=Matern(length_scale=study_gp.best_params['lenghtscale'], nu=1.5))\n",
    "boosted_model=lgbm.LGBMRegressor(**study_boost.best_params)\n",
    "rf_model=lgbm.LGBMRegressor(**study_rf.best_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "engressor = engression(torch.Tensor(np.array(X_train)), torch.Tensor(np.array(y_train).reshape(-1,1)), lr=0.01, num_epoches=500, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'depth' has no attribute 'multivariate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [214], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#### Try to use simplicial data depth instead\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#import depth\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m dist_simplical\u001b[39m=\u001b[39mdepth\u001b[39m.\u001b[39;49mmultivariate\u001b[39m.\u001b[39msimplicial(X, X,)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'depth' has no attribute 'multivariate'"
     ]
    }
   ],
   "source": [
    "#### Try to use simplicial data depth instead\n",
    "#import depth\n",
    "dist_simplical=depth.multivariate.simplicial(X, X,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU.\n",
      "\n",
      "Data is standardized for training only; the printed training losses are on the standardized scale. \n",
      "However during evaluation, the predictions, evaluation metrics, and plots will be on the original scale.\n",
      "\n",
      "Training based on mini-batch gradient descent with a batch size of 1000.\n",
      "[Epoch 1 (0%), batch 7] energy-loss: 0.1461,  E(|Y-Yhat|): 0.4062,  E(|Yhat-Yhat'|): 0.5202\n",
      "[Epoch 100 (20%), batch 7] energy-loss: 0.1116,  E(|Y-Yhat|): 0.2282,  E(|Yhat-Yhat'|): 0.2333\n",
      "[Epoch 200 (40%), batch 7] energy-loss: 0.1036,  E(|Y-Yhat|): 0.2071,  E(|Yhat-Yhat'|): 0.2070\n",
      "[Epoch 300 (60%), batch 7] energy-loss: 0.0965,  E(|Y-Yhat|): 0.2011,  E(|Yhat-Yhat'|): 0.2090\n",
      "[Epoch 400 (80%), batch 7] energy-loss: 0.0979,  E(|Y-Yhat|): 0.1921,  E(|Yhat-Yhat'|): 0.1884\n",
      "[Epoch 500 (100%), batch 7] energy-loss: 0.0950,  E(|Y-Yhat|): 0.1873,  E(|Yhat-Yhat'|): 0.1845\n",
      "\n",
      "Training loss on the original (non-standardized) scale:\n",
      "\tEnergy-loss: 1.0691,  E(|Y-Yhat|): 2.2431,  E(|Yhat-Yhat'|): 2.3479\n",
      "\n",
      "Prediction-loss E(|Y-Yhat|) and variance-loss E(|Yhat-Yhat'|) should ideally be equally large\n",
      "-- consider training for more epochs or adjusting hyperparameters if there is a mismatch \n",
      "Engression model with\n",
      "\t number of layers: 2\n",
      "\t hidden dimensions: 100\n",
      "\t noise dimensions: 100\n",
      "\t residual blocks: False\n",
      "\t number of epochs: 500\n",
      "\t batch size: 1000\n",
      "\t learning rate: 0.01\n",
      "\t standardization: True\n",
      "\t training mode: False\n",
      "\t device: cpu\n",
      "\n",
      "Training loss (original scale):\n",
      "\t energy-loss: 1.07, \n",
      "\tE(|Y-Yhat|): 2.24, \n",
      "\tE(|Yhat-Yhat'|): 2.35\n"
     ]
    }
   ],
   "source": [
    "from engression import engression\n",
    "## Fit an engression model\n",
    "engressor = engression(torch.Tensor(np.array(X_train)), torch.Tensor(np.array(y_train).reshape(-1,1)), lr=0.01, num_epoches=500, batch_size=1000)\n",
    "## Summarize model information\n",
    "engressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE engression:  [10.225099]\n"
     ]
    }
   ],
   "source": [
    "y_test_hat_engression=engressor.predict(torch.Tensor(np.array(X_test)), target=\"mean\")\n",
    "RMSE_engression=np.sqrt((((torch.Tensor(np.array(y_test).reshape(-1,1)))-y_test_hat_engression)**2).mean(axis=0))\n",
    "\n",
    "print(\"RMSE engression: \", np.array(RMSE_engression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU.\n",
      "\n",
      "Model 1 training details:\n",
      "\n",
      "Data is standardized for training only; the printed training losses are on the standardized scale. \n",
      "However during evaluation, the predictions, evaluation metrics, and plots will be on the original scale.\n",
      "\n",
      "Training based on mini-batch gradient descent with a batch size of 1000.\n",
      "[Epoch 1 (0%), batch 4] energy-loss: 0.2891,  E(|Y-Yhat|): 0.6057,  E(|Yhat-Yhat'|): 0.6331\n",
      "[Epoch 100 (20%), batch 4] energy-loss: 0.1226,  E(|Y-Yhat|): 0.2563,  E(|Yhat-Yhat'|): 0.2673\n",
      "[Epoch 200 (40%), batch 4] energy-loss: 0.1016,  E(|Y-Yhat|): 0.2203,  E(|Yhat-Yhat'|): 0.2373\n",
      "[Epoch 300 (60%), batch 4] energy-loss: 0.0807,  E(|Y-Yhat|): 0.1956,  E(|Yhat-Yhat'|): 0.2299\n",
      "[Epoch 400 (80%), batch 4] energy-loss: 0.0936,  E(|Y-Yhat|): 0.2121,  E(|Yhat-Yhat'|): 0.2368\n",
      "[Epoch 500 (100%), batch 4] energy-loss: 0.0886,  E(|Y-Yhat|): 0.1997,  E(|Yhat-Yhat'|): 0.2222\n",
      "\n",
      "Training loss on the original (non-standardized) scale:\n",
      "\tEnergy-loss: 1.0920,  E(|Y-Yhat|): 2.2789,  E(|Yhat-Yhat'|): 2.3737\n",
      "\n",
      "Prediction-loss E(|Y-Yhat|) and variance-loss E(|Yhat-Yhat'|) should ideally be equally large\n",
      "-- consider training for more epochs or adjusting hyperparameters if there is a mismatch \n",
      "\n",
      "\n",
      "[Model 1] train_loss: 1.0725, val_loss: 1.1451\n",
      "[Model 2] train_loss: 1.1029, val_loss: 1.2195\n",
      "[Model 3] train_loss: 1.0841, val_loss: 1.1841\n",
      "[Model 4] train_loss: 1.1131, val_loss: 1.2012\n",
      "[Model 5] train_loss: 1.1058, val_loss: 1.1850\n",
      "[Model 6] train_loss: 1.1102, val_loss: 1.1865\n",
      "[Model 7] train_loss: 1.1400, val_loss: 1.1961\n",
      "[Model 8] train_loss: 1.1053, val_loss: 1.1401\n",
      "[Model 9] train_loss: 1.1556, val_loss: 1.1664\n",
      "[Model 10] train_loss: 1.1354, val_loss: 1.1418\n",
      "\n",
      "Validation energy loss of the bagged engression model: 1.1534\n",
      "Engression model with\n",
      "\t number of layers: 2\n",
      "\t hidden dimensions: 100\n",
      "\t noise dimensions: 100\n",
      "\t number of epochs: 500\n",
      "\t batch size: 1000\n",
      "\t learning rate: 0.01\n",
      "\t standardization: True\n",
      "\t training mode: False\n",
      "\t device: cpu\n",
      "\t ensemble size: 10\n",
      "\n",
      "Validation energy loss: 1.1534\n"
     ]
    }
   ],
   "source": [
    "## Fit a bagged engression model\n",
    "from engression import engression_bagged\n",
    "engressor_bagged = engression_bagged(torch.Tensor(np.array(X_train)), torch.Tensor(np.array(y_train).reshape(-1,1)), lr=0.01, num_epoches=500, batch_size=1000)\n",
    "## Summarize model information\n",
    "engressor_bagged.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE engression bagged:  [5.657687]\n"
     ]
    }
   ],
   "source": [
    "y_test_hat_engression_bagged=engressor_bagged.predict(torch.Tensor(np.array(X_test)), target=\"mean\")\n",
    "RMSE_engression_bagged=np.sqrt((((torch.Tensor(np.array(y_test).reshape(-1,1)))-y_test_hat_engression_bagged)**2).mean(axis=0))\n",
    "\n",
    "print(\"RMSE engression bagged: \", np.array(RMSE_engression_bagged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygam\n",
    "gam=pygam.LinearGAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE gam:  26.588899789636343\n"
     ]
    }
   ],
   "source": [
    "gam.fit(X_train,y_train)\n",
    "y_test_hat_gam=gam.predict(X_test)\n",
    "RMSE_gam=np.sqrt(np.mean((y_test-y_test_hat_gam)**2))\n",
    "\n",
    "print(\"RMSE gam: \",RMSE_gam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1639, 1])\n",
      "torch.Size([1639, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y_test_hat_engression.shape)\n",
    "print((torch.Tensor(np.array(y_test).reshape(-1,1))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6553, 21)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6553, 1)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(y_train).reshape(-1,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4351\n",
      "[LightGBM] [Info] Number of data points in the train set: 6553, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 88.320464\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4351\n",
      "[LightGBM] [Info] Number of data points in the train set: 6553, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 88.320464\n",
      "11.097427194996309\n",
      "2.2270184840127323\n",
      "3.9921802093936547\n"
     ]
    }
   ],
   "source": [
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_test_hat_linreg=lin_reg.predict(X_test)\n",
    "RMSE_linreg=np.sqrt(np.mean((y_test-y_test_hat_linreg))**2)\n",
    "\n",
    "boosted_tree_model=lgbm.LGBMRegressor()\n",
    "boosted_tree_model.fit(X_train, y_train)\n",
    "y_test_hat_boost=boosted_tree_model.predict(X_test)\n",
    "RMSE_boost=np.sqrt(np.mean((y_test-y_test_hat_boost))**2)\n",
    "\n",
    "rf=lgbm.LGBMRegressor(boosting_type=\"rf\", subsample_freq=1, subsample=0.5)\n",
    "rf.fit(X_train, y_train)\n",
    "y_test_hat_rf=rf.predict(X_test)\n",
    "RMSE_rf=np.sqrt(np.mean((y_test-y_test_hat_rf))**2)\n",
    "print(RMSE_linreg)\n",
    "print(RMSE_boost)\n",
    "print(RMSE_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2753891877527628e-10\n"
     ]
    }
   ],
   "source": [
    "y_train_hat_boost=boosted_tree_model.predict(X_train)\n",
    "RMSE_boost_train=np.sqrt(np.mean((y_train-y_train_hat_boost))**2)\n",
    "print(RMSE_boost_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_train, y_train_hat_boost, c='r', s=0.1)\n",
    "plt.scatter(y_test, y_test_hat_boost, c='b', s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "x_pca_train = X_train.loc[:, ].values\n",
    "x_pca_train = StandardScaler().fit_transform(x_pca_train) # normalizing the features\n",
    "pca_train = PCA(n_components=2)\n",
    "principalComponents_train = pca_train.fit_transform(x_pca_train)\n",
    "\n",
    "x_pca_test = X_test.loc[:, ].values\n",
    "x_pca_test = StandardScaler().fit_transform(x_pca_test) # normalizing the features\n",
    "pca_test = PCA(n_components=2)\n",
    "principalComponents_test = pca_test.fit_transform(x_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(principalComponents_train[:,0],principalComponents_train[:,1],c='r',s=0.1)\n",
    "plt.scatter(principalComponents_test[:,0],principalComponents_test[:,1],c='b',s=0.1)\n",
    "plt.legend([\"Train\",\"Test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "hyperopt_estimator.__init__() got an unexpected keyword argument 'rstate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [70], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhyperopt\u001b[39;00m \u001b[39mimport\u001b[39;00m tpe\n\u001b[1;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m HyperoptEstimator(regressor\u001b[39m=\u001b[39;49many_regressor(\u001b[39m'\u001b[39;49m\u001b[39mreg\u001b[39;49m\u001b[39m'\u001b[39;49m), preprocessing\u001b[39m=\u001b[39;49many_preprocessing(\u001b[39m'\u001b[39;49m\u001b[39mpre\u001b[39;49m\u001b[39m'\u001b[39;49m), algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest, loss_fn\u001b[39m=\u001b[39;49mmean_absolute_error, max_evals\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, rstate\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mdefault_rng(\u001b[39m3\u001b[39;49m))\n\u001b[0;32m      3\u001b[0m \u001b[39m# perform the search\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mTypeError\u001b[0m: hyperopt_estimator.__init__() got an unexpected keyword argument 'rstate'"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe\n",
    "model = HyperoptEstimator(regressor=any_regressor('reg'), preprocessing=any_preprocessing('pre'), algo=tpe.suggest, loss_fn=mean_absolute_error, max_evals=5, rstate=np.random.default_rng(3))\n",
    "# perform the search\n",
    "model.fit(X_train, y_train)\n",
    "# summarize performance\n",
    "mae = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103257/cpu_act.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103258/pol.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103259/elevators.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103261/wine_quality.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103262/Ailerons.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103263/houses.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103264/house_16H.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103265/diamonds.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103266/Brazilian_houses.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103267/Bike_Sharing_Demand.arff.\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:372: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "WARNING:root:Received uncompressed content from OpenML for https://api.openml.org/data/v1/download/22103268/nyc-taxi-green-dec-2016.arff.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\task.py:157\u001b[0m, in \u001b[0;36mOpenMLTask.download_split\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     split \u001b[39m=\u001b[39m OpenMLSplit\u001b[39m.\u001b[39;49m_from_arff_file(cached_split_file)\n\u001b[0;32m    158\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mIOError\u001b[39;00m):\n\u001b[0;32m    159\u001b[0m     \u001b[39m# Next, download and cache the associated split file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\split.py:87\u001b[0m, in \u001b[0;36mOpenMLSplit._from_arff_file\u001b[1;34m(cls, filename)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(filename):\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSplit arff \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m does not exist!\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m filename)\n\u001b[0;32m     88\u001b[0m file_data \u001b[39m=\u001b[39m arff\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(filename), return_type\u001b[39m=\u001b[39marff\u001b[39m.\u001b[39mDENSE_GEN)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Split arff C:\\Users\\dalma\\.openml\\org\\openml\\www\\tasks\\361083\\datasplits.arff does not exist!",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\task.py:140\u001b[0m, in \u001b[0;36mOpenMLTask._download_split\u001b[1;34m(self, cache_file)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39;49mopen(cache_file, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf8\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[0;32m    141\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\dalma\\\\.openml\\\\org\\\\openml\\\\www\\\\tasks\\\\361083\\\\datasplits.arff'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m benchmark_suite \u001b[39m=\u001b[39m openml\u001b[39m.\u001b[39mstudy\u001b[39m.\u001b[39mget_suite(SUITE_ID)  \u001b[39m# obtain the benchmark suite\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m task_id \u001b[39min\u001b[39;00m benchmark_suite\u001b[39m.\u001b[39mtasks:  \u001b[39m# iterate over all tasks\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     task \u001b[39m=\u001b[39m openml\u001b[39m.\u001b[39;49mtasks\u001b[39m.\u001b[39;49mget_task(task_id)  \u001b[39m# download the OpenML task\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     dataset \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mget_dataset()\n\u001b[0;32m     11\u001b[0m     X, y, categorical_indicator, attribute_names \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_data(\n\u001b[0;32m     12\u001b[0m         dataset_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdataframe\u001b[39m\u001b[39m\"\u001b[39m, target\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mdefault_target_attribute\n\u001b[0;32m     13\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\functions.py:409\u001b[0m, in \u001b[0;36mget_task\u001b[1;34m(task_id, download_splits, *dataset_args, **get_dataset_kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[39mif\u001b[39;00m download_splits:\n\u001b[0;32m    408\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(task, OpenMLSupervisedTask):\n\u001b[1;32m--> 409\u001b[0m             task\u001b[39m.\u001b[39;49mdownload_split()\n\u001b[0;32m    410\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    411\u001b[0m     openml\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_remove_cache_dir_for_id(\n\u001b[0;32m    412\u001b[0m         TASKS_CACHE_DIR_NAME,\n\u001b[0;32m    413\u001b[0m         tid_cache_dir,\n\u001b[0;32m    414\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\task.py:160\u001b[0m, in \u001b[0;36mOpenMLTask.download_split\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    157\u001b[0m     split \u001b[39m=\u001b[39m OpenMLSplit\u001b[39m.\u001b[39m_from_arff_file(cached_split_file)\n\u001b[0;32m    158\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mIOError\u001b[39;00m):\n\u001b[0;32m    159\u001b[0m     \u001b[39m# Next, download and cache the associated split file\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_split(cached_split_file)\n\u001b[0;32m    161\u001b[0m     split \u001b[39m=\u001b[39m OpenMLSplit\u001b[39m.\u001b[39m_from_arff_file(cached_split_file)\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m split\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\tasks\\task.py:144\u001b[0m, in \u001b[0;36mOpenMLTask._download_split\u001b[1;34m(self, cache_file)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mIOError\u001b[39;00m):\n\u001b[0;32m    143\u001b[0m     split_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimation_procedure[\u001b[39m\"\u001b[39m\u001b[39mdata_splits_url\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 144\u001b[0m     openml\u001b[39m.\u001b[39;49m_api_calls\u001b[39m.\u001b[39;49m_download_text_file(\n\u001b[0;32m    145\u001b[0m         source\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(split_url),\n\u001b[0;32m    146\u001b[0m         output_path\u001b[39m=\u001b[39;49mcache_file,\n\u001b[0;32m    147\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\_api_calls.py:239\u001b[0m, in \u001b[0;36m_download_text_file\u001b[1;34m(source, output_path, md5_checksum, exists_ok, encoding)\u001b[0m\n\u001b[0;32m    237\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mStarting [\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m] request for the URL \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, source)\n\u001b[0;32m    238\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 239\u001b[0m response \u001b[39m=\u001b[39m __read_url(source, request_method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, md5_checksum\u001b[39m=\u001b[39;49mmd5_checksum)\n\u001b[0;32m    240\u001b[0m downloaded_file \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtext\n\u001b[0;32m    242\u001b[0m \u001b[39mif\u001b[39;00m output_path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\_api_calls.py:308\u001b[0m, in \u001b[0;36m__read_url\u001b[1;34m(url, request_method, data, md5_checksum)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mapikey:\n\u001b[0;32m    307\u001b[0m     data[\u001b[39m\"\u001b[39m\u001b[39mapi_key\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mapikey\n\u001b[1;32m--> 308\u001b[0m \u001b[39mreturn\u001b[39;00m _send_request(\n\u001b[0;32m    309\u001b[0m     request_method\u001b[39m=\u001b[39;49mrequest_method, url\u001b[39m=\u001b[39;49murl, data\u001b[39m=\u001b[39;49mdata, md5_checksum\u001b[39m=\u001b[39;49mmd5_checksum\n\u001b[0;32m    310\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openml\\_api_calls.py:337\u001b[0m, in \u001b[0;36m_send_request\u001b[1;34m(request_method, url, data, files, md5_checksum)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mif\u001b[39;00m request_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 337\u001b[0m         response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mget(url, params\u001b[39m=\u001b[39;49mdata)\n\u001b[0;32m    338\u001b[0m     \u001b[39melif\u001b[39;00m request_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdelete\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m         response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mdelete(url, params\u001b[39m=\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:600\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \n\u001b[0;32m    594\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    599\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 600\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(\u001b[39m\"\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m\"\u001b[39m, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[1;32m--> 745\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[0;32m    747\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:623\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m    609\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m--> 623\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[0;32m    624\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[0;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:815\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    812\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_chunk_length()\n\u001b[0;32m    816\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    817\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:745\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    744\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline()\n\u001b[0;32m    746\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    747\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1270\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1271\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1272\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1273\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1275\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\dalma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1128\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1129\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1130\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import openml\n",
    "#openml.config.apikey = 'FILL_IN_OPENML_API_KEY'  # set the OpenML Api Key\n",
    "SUITE_ID = 336 # Regression on numerical features\n",
    "#SUITE_ID = 337 # Classification on numerical features\n",
    "#SUITE_ID = 335 # Regression on numerical and categorical features\n",
    "#SUITE_ID = 334 # Classification on numerical and categorical features\n",
    "benchmark_suite = openml.study.get_suite(SUITE_ID)  # obtain the benchmark suite\n",
    "for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
    "    task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "    dataset = task.get_dataset()\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"dataframe\", target=dataset.default_target_attribute\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfcdafd4c2f198e9231774dbaa691ef2a9d56c92dabac0fe3d9f172dfc08608e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
